  /**
   * Split the input using configured pattern
   */
  public Tokenizer create(final Reader in) {
    try {
      return new Tokenizer(in) {
        {init();}

        List<Token> tokens;
        Iterator<Token> iter;

        void init() throws IOException {
          // Read the input into a single string
          String str = IOUtils.toString( input );

          Matcher matcher = pattern.matcher( str );
          tokens = (group < 0 )
                  ? split( matcher, str )
                  : group( matcher, str, group );
          iter = tokens.iterator();
        }

//        @Override
//        public boolean incrementToken() throws IOException {
//          return super.incrementToken();
//        }

        @Override
        public void end() throws IOException {
          super.end();
        }

//        @Override
//        public Token next(Token reusableToken) throws IOException {
//          return super.next(reusableToken);
//        }

        @Override
        public void reset(Reader input) throws IOException {
          super.reset(input);
          init();
        }

        @Override
        public Token next() throws IOException {
          if( iter.hasNext() ) {
            return iter.next();
          }
          return null;
        }
      };
    }
    catch( IOException ex ) {
      throw new SolrException( SolrException.ErrorCode.SERVER_ERROR, ex );
    }
  }

