  public final Token next(final Token reusableToken) throws IOException {
    assert reusableToken != null;
    reusableToken.clear();
    int length = 0;
    int start = bufferIndex;
    char[] buffer = reusableToken.termBuffer();
    while (true) {

      if (bufferIndex >= dataLen) {
        offset += dataLen;
        dataLen = input.read(ioBuffer);
        if (dataLen == -1) {
          if (length > 0)
            break;
          else
            return null;
        }
        bufferIndex = 0;
      }

      final char c = ioBuffer[bufferIndex++];

      if (isTokenChar(c)) {               // if it's a token char

        if (length == 0)                 // start of token
          start = offset + bufferIndex - 1;
        else if (length == buffer.length)
          buffer = reusableToken.resizeTermBuffer(1+length);

        buffer[length++] = normalize(c); // buffer it, normalized

        if (length == MAX_WORD_LEN)      // buffer overflow!
          break;

      } else if (length > 0)             // at non-Letter w/ chars
        break;                           // return 'em
    }

    reusableToken.setTermLength(length);
    // Because of "CharStream aware" tokenizer, using correctOffset() to
    // correct start/end offsets
    reusableToken.setStartOffset(((CharStream)input).correctOffset(start));
    reusableToken.setEndOffset(((CharStream)input).correctOffset(start+length));
    return reusableToken;
  }

