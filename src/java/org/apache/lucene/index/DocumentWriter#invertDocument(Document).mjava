  // Tokenizes the fields of a document into Postings.
  private final void invertDocument(Document doc)
       throws IOException {
    Enumeration fields  = doc.fields();
    while (fields.hasMoreElements()) {
      Field field = (Field)fields.nextElement();
      String fieldName = field.name();
      int fieldNumber = fieldInfos.fieldNumber(fieldName);

      int position = fieldLengths[fieldNumber];	  // position in field

      if (field.isIndexed()) {
	if (!field.isTokenized()) {		  // un-tokenized field
	  addPosition(fieldName, field.stringValue(), position++);
	} else {
	  Reader reader;			  // find or make Reader
	  if (field.readerValue() != null)
	    reader = field.readerValue();
	  else if (field.stringValue() != null)
	    reader = new StringReader(field.stringValue());
	  else
	    throw new IllegalArgumentException
	      ("field must have either String or Reader value");

	  // Tokenize field and add to postingTable
	  TokenStream stream = analyzer.tokenStream(fieldName, reader);
	  try {
	    for (Token t = stream.next(); t != null; t = stream.next()) {
	      addPosition(fieldName, t.termText(), position++);
	      if (position > maxFieldLength) break;
	    }
	  } finally {
	    stream.close();
	  }
	}

	fieldLengths[fieldNumber] = position;	  // save field length
        fieldBoosts[fieldNumber] *= field.getBoost();
      }
    }
  }

