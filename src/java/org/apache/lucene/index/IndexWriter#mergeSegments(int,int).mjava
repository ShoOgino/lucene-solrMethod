  /**
   * Merges the named range of segments, replacing them in the stack with a
   * single segment.
   */

  private final int mergeSegments(int minSegment, int end)
    throws CorruptIndexException, IOException {

    final String mergedName = newSegmentName();
    
    SegmentMerger merger = null;
    SegmentInfo newSegment = null;

    int mergedDocCount = 0;

    // This is try/finally to make sure merger's readers are closed:
    try {

      if (infoStream != null) infoStream.print("merging segments");

      // Check whether this merge will allow us to skip
      // merging the doc stores (stored field & vectors).
      // This is a very substantial optimization (saves tons
      // of IO) that can only be applied with
      // autoCommit=false.

      Directory lastDir = directory;
      String lastDocStoreSegment = null;
      boolean mergeDocStores = false;
      boolean doFlushDocStore = false;
      int next = -1;

      // Test each segment to be merged
      for (int i = minSegment; i < end; i++) {
        SegmentInfo si = segmentInfos.info(i);

        // If it has deletions we must merge the doc stores
        if (si.hasDeletions())
          mergeDocStores = true;

        // If it has its own (private) doc stores we must
        // merge the doc stores
        if (-1 == si.getDocStoreOffset())
          mergeDocStores = true;

        // If it has a different doc store segment than
        // previous segments, we must merge the doc stores
        String docStoreSegment = si.getDocStoreSegment();
        if (docStoreSegment == null)
          mergeDocStores = true;
        else if (lastDocStoreSegment == null)
          lastDocStoreSegment = docStoreSegment;
        else if (!lastDocStoreSegment.equals(docStoreSegment))
          mergeDocStores = true;

        // Segments' docScoreOffsets must be in-order,
        // contiguous.  For the default merge policy now
        // this will always be the case but for an arbitrary
        // merge policy this may not be the case
        if (-1 == next)
          next = si.getDocStoreOffset() + si.docCount;
        else if (next != si.getDocStoreOffset())
          mergeDocStores = true;
        else
          next = si.getDocStoreOffset() + si.docCount;
      
        // If the segment comes from a different directory
        // we must merge
        if (lastDir != si.dir)
          mergeDocStores = true;

        // If the segment is referencing the current "live"
        // doc store outputs then we must merge
        if (si.getDocStoreOffset() != -1 && si.getDocStoreSegment().equals(docWriter.getDocStoreSegment()))
          doFlushDocStore = true;
      }

      final int docStoreOffset;
      final String docStoreSegment;
      final boolean docStoreIsCompoundFile;
      if (mergeDocStores) {
        docStoreOffset = -1;
        docStoreSegment = null;
        docStoreIsCompoundFile = false;
      } else {
        SegmentInfo si = segmentInfos.info(minSegment);        
        docStoreOffset = si.getDocStoreOffset();
        docStoreSegment = si.getDocStoreSegment();
        docStoreIsCompoundFile = si.getDocStoreIsCompoundFile();
      }

      if (mergeDocStores && doFlushDocStore)
        // SegmentMerger intends to merge the doc stores
        // (stored fields, vectors), and at least one of the
        // segments to be merged refers to the currently
        // live doc stores.
        flushDocStores();

      merger = new SegmentMerger(this, mergedName);

      for (int i = minSegment; i < end; i++) {
        SegmentInfo si = segmentInfos.info(i);
        if (infoStream != null)
          infoStream.print(" " + si.name + " (" + si.docCount + " docs)");
        IndexReader reader = SegmentReader.get(si, MERGE_READ_BUFFER_SIZE, mergeDocStores); // no need to set deleter (yet)
        merger.add(reader);
      }

      SegmentInfos rollback = null;
      boolean success = false;

      // This is try/finally to rollback our internal state
      // if we hit exception when doing the merge:
      try {

        mergedDocCount = merger.merge(mergeDocStores);

        if (infoStream != null) {
          infoStream.println(" into "+mergedName+" ("+mergedDocCount+" docs)");
        }

        newSegment = new SegmentInfo(mergedName, mergedDocCount,
                                     directory, false, true,
                                     docStoreOffset,
                                     docStoreSegment,
                                     docStoreIsCompoundFile);
        
        rollback = (SegmentInfos) segmentInfos.clone();

        for (int i = end-1; i > minSegment; i--)     // remove old infos & add new
          segmentInfos.remove(i);

        segmentInfos.set(minSegment, newSegment);

        checkpoint();

        success = true;

      } finally {
        if (!success) {
          if (rollback != null) {
            // Rollback the individual SegmentInfo
            // instances, but keep original SegmentInfos
            // instance (so we don't try to write again the
            // same segments_N file -- write once):
            segmentInfos.clear();
            segmentInfos.addAll(rollback);
          }

          // Delete any partially created and now unreferenced files:
          deleter.refresh();
        }
      }
    } finally {
      // close readers before we attempt to delete now-obsolete segments
      if (merger != null) {
        merger.closeReaders();
      }
    }

    // Give deleter a chance to remove files now.
    deleter.checkpoint(segmentInfos, autoCommit);

    if (useCompoundFile) {

      boolean success = false;

      try {

        merger.createCompoundFile(mergedName + ".cfs");
        newSegment.setUseCompoundFile(true);
        checkpoint();
        success = true;

      } finally {
        if (!success) {  
          // Must rollback:
          newSegment.setUseCompoundFile(false);
          deleter.refresh();
        }
      }
      
      // Give deleter a chance to remove files now.
      deleter.checkpoint(segmentInfos, autoCommit);
    }

    return mergedDocCount;
  }

