  // TODO: this method should not have to be entirely
  // synchronized, ie, merges should be allowed to commit
  // even while a flush is happening
  private synchronized final boolean doFlush(boolean flushDocStores, boolean flushDeletes) throws CorruptIndexException, IOException {

    ensureOpen(false);

    assert testPoint("startDoFlush");

    flushCount++;

    // Make sure no threads are actively adding a document

    flushDeletes |= docWriter.deletesFull();

    // When autoCommit=true we must always flush deletes
    // when flushing a segment; otherwise deletes may become
    // visible before their corresponding added document
    // from an updateDocument call
    flushDeletes |= autoCommit;

    // Returns true if docWriter is currently aborting, in
    // which case we skip flushing this segment
    if (docWriter.pauseAllThreads()) {
      docWriter.resumeAllThreads();
      return false;
    }

    try {

      SegmentInfo newSegment = null;

      final int numDocs = docWriter.getNumDocsInRAM();

      // Always flush docs if there are any
      boolean flushDocs = numDocs > 0;

      // With autoCommit=true we always must flush the doc
      // stores when we flush
      flushDocStores |= autoCommit;
      String docStoreSegment = docWriter.getDocStoreSegment();
      if (docStoreSegment == null)
        flushDocStores = false;

      int docStoreOffset = docWriter.getDocStoreOffset();

      // docStoreOffset should only be non-zero when
      // autoCommit == false
      assert !autoCommit || 0 == docStoreOffset;

      boolean docStoreIsCompoundFile = false;

      if (infoStream != null) {
        message("  flush: segment=" + docWriter.getSegment() +
                " docStoreSegment=" + docWriter.getDocStoreSegment() +
                " docStoreOffset=" + docStoreOffset +
                " flushDocs=" + flushDocs +
                " flushDeletes=" + flushDeletes +
                " flushDocStores=" + flushDocStores +
                " numDocs=" + numDocs +
                " numBufDelTerms=" + docWriter.getNumBufferedDeleteTerms());
        message("  index before flush " + segString());
      }

      // Check if the doc stores must be separately flushed
      // because other segments, besides the one we are about
      // to flush, reference it
      if (flushDocStores && (!flushDocs || !docWriter.getSegment().equals(docWriter.getDocStoreSegment()))) {
        // We must separately flush the doc store
        if (infoStream != null)
          message("  flush shared docStore segment " + docStoreSegment);
      
        docStoreIsCompoundFile = flushDocStores();
        flushDocStores = false;
      }

      String segment = docWriter.getSegment();

      // If we are flushing docs, segment must not be null:
      assert segment != null || !flushDocs;

      if (flushDocs) {

        boolean success = false;
        final int flushedDocCount;

        try {
          flushedDocCount = docWriter.flush(flushDocStores);
          success = true;
        } finally {
          if (!success) {
            if (infoStream != null)
              message("hit exception flushing segment " + segment);
            deleter.refresh(segment);
          }
        }
        
        if (0 == docStoreOffset && flushDocStores) {
          // This means we are flushing private doc stores
          // with this segment, so it will not be shared
          // with other segments
          assert docStoreSegment != null;
          assert docStoreSegment.equals(segment);
          docStoreOffset = -1;
          docStoreIsCompoundFile = false;
          docStoreSegment = null;
        }

        // Create new SegmentInfo, but do not add to our
        // segmentInfos until deletes are flushed
        // successfully.
        newSegment = new SegmentInfo(segment,
                                     flushedDocCount,
                                     directory, false, true,
                                     docStoreOffset, docStoreSegment,
                                     docStoreIsCompoundFile,    
                                     docWriter.hasProx());
      }

      docWriter.pushDeletes();

      if (flushDocs)
        segmentInfos.addElement(newSegment);

      if (flushDeletes) {
        flushDeletesCount++;
        applyDeletes();
      }
      
      doAfterFlush();

      if (flushDocs)
        checkpoint();

      if (flushDocs && mergePolicy.useCompoundFile(segmentInfos, newSegment)) {
        // Now build compound file
        boolean success = false;
        try {
          docWriter.createCompoundFile(segment);
          success = true;
        } finally {
          if (!success) {
            if (infoStream != null)
              message("hit exception creating compound file for newly flushed segment " + segment);
            deleter.deleteFile(segment + "." + IndexFileNames.COMPOUND_FILE_EXTENSION);
          }
        }

        newSegment.setUseCompoundFile(true);
        checkpoint();
      }

      return flushDocs;

    } catch (OutOfMemoryError oom) {
      hitOOM = true;
      throw oom;
    } finally {
      docWriter.clearFlushPending();
      docWriter.resumeAllThreads();
    }
  }

