  // Called during flush to apply any buffered deletes.  If
  // flushedNewSegment is true then a new segment was just
  // created and flushed from the ram segments, so we will
  // selectively apply the deletes to that new segment.
  private final void applyDeletes(SegmentInfo newSegment) throws CorruptIndexException, IOException {

    final HashMap bufferedDeleteTerms = docWriter.getBufferedDeleteTerms();
    final List bufferedDeleteDocIDs = docWriter.getBufferedDeleteDocIDs();

    if (infoStream != null)
      message("flush " + docWriter.getNumBufferedDeleteTerms() + " buffered deleted terms and " +
              bufferedDeleteDocIDs.size() + " deleted docIDs on "
              + segmentInfos.size() + " segments.");

    if (newSegment != null) {
      IndexReader reader = null;
      try {
        // Open readers w/o opening the stored fields /
        // vectors because these files may still be held
        // open for writing by docWriter
        reader = SegmentReader.get(newSegment, false);

        // Apply delete terms to the segment just flushed from ram
        // apply appropriately so that a delete term is only applied to
        // the documents buffered before it, not those buffered after it.
        applyDeletesSelectively(bufferedDeleteTerms, bufferedDeleteDocIDs, reader);
      } finally {
        if (reader != null) {
          try {
            reader.doCommit();
          } finally {
            reader.doClose();
          }
        }
      }
    }

    final int infosEnd = segmentInfos.size();

    for (int i = 0; i < infosEnd; i++) {
      IndexReader reader = null;
      try {
        reader = SegmentReader.get(segmentInfos.info(i), false);

        // Apply delete terms to disk segments
        // except the one just flushed from ram.
        applyDeletes(bufferedDeleteTerms, reader);
      } finally {
        if (reader != null) {
          try {
            reader.doCommit();
          } finally {
            reader.doClose();
          }
        }
      }
    }
  }

