  /**
   * Merges all segments from an array of indexes into this
   * index.
   *
   * <p>This may be used to parallelize batch indexing.  A large document
   * collection can be broken into sub-collections.  Each sub-collection can be
   * indexed in parallel, on a different thread, process or machine.  The
   * complete index can then be created by merging sub-collection indexes
   * with this method.
   *
   * <p><b>NOTE:</b> the index in each Directory must not be
   * changed (opened by a writer) while this method is
   * running.  This method does not acquire a write lock in
   * each input Directory, so it is up to the caller to
   * enforce this.
   *
   * <p><b>NOTE:</b> while this is running, any attempts to
   * add or delete documents (with another thread) will be
   * paused until this method completes.
   *
   * <p>This method is transactional in how Exceptions are
   * handled: it does not commit a new segments_N file until
   * all indexes are added.  This means if an Exception
   * occurs (for example disk full), then either no indexes
   * will have been added or they all will have been.</p>
   *
   * <p>Note that this requires temporary free space in the
   * Directory up to 2X the sum of all input indexes
   * (including the starting index).  If readers/searchers
   * are open against the starting index, then temporary
   * free space required will be higher by the size of the
   * starting index (see {@link #optimize()} for details).
   * </p>
   *
   * <p>Once this completes, the final size of the index
   * will be less than the sum of all input index sizes
   * (including the starting index).  It could be quite a
   * bit smaller (if there were many pending deletes) or
   * just slightly smaller.</p>
   * 
   * <p>
   * This requires this index not be among those to be added.
   *
   * @throws CorruptIndexException if the index is corrupt
   * @throws IOException if there is a low-level IO error
   */
  public void addIndexesNoOptimize(Directory[] dirs)
      throws CorruptIndexException, IOException {

    ensureOpen();

    noDupDirs(dirs);

    // Do not allow add docs or deletes while we are running:
    docWriter.pauseAllThreads();

    try {
      if (infoStream != null)
        message("flush at addIndexesNoOptimize");
      flush(true, false, true);

      boolean success = false;

      startTransaction(false);

      try {

        int docCount = 0;
        synchronized(this) {
          ensureOpen();

          for (int i = 0; i < dirs.length; i++) {
            if (directory == dirs[i]) {
              // cannot add this index: segments may be deleted in merge before added
              throw new IllegalArgumentException("Cannot add this index to itself");
            }

            SegmentInfos sis = new SegmentInfos(); // read infos from dir
            sis.read(dirs[i]);
            for (int j = 0; j < sis.size(); j++) {
              SegmentInfo info = sis.info(j);
              assert !segmentInfos.contains(info): "dup info dir=" + info.dir + " name=" + info.name;
              docCount += info.docCount;
              segmentInfos.add(info); // add each info
            }
          }
        }

        // Notify DocumentsWriter that the flushed count just increased
        docWriter.updateFlushedDocCount(docCount);

        maybeMerge();

        ensureOpen();

        // If after merging there remain segments in the index
        // that are in a different directory, just copy these
        // over into our index.  This is necessary (before
        // finishing the transaction) to avoid leaving the
        // index in an unusable (inconsistent) state.
        resolveExternalSegments();

        ensureOpen();

        success = true;

      } finally {
        if (success) {
          commitTransaction();
        } else {
          rollbackTransaction();
        }
      }
    } catch (OutOfMemoryError oom) {
      hitOOM = true;
      throw oom;
    } finally {
      docWriter.resumeAllThreads();
    }
  }

