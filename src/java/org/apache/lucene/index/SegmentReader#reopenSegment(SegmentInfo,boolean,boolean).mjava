  synchronized SegmentReader reopenSegment(SegmentInfo si, boolean doClone, boolean openReadOnly) throws CorruptIndexException, IOException {
    boolean deletionsUpToDate = (this.si.hasDeletions() == si.hasDeletions()) 
                                  && (!si.hasDeletions() || this.si.getDelFileName().equals(si.getDelFileName()));
    boolean normsUpToDate = true;
    
    boolean[] fieldNormsChanged = new boolean[fieldInfos.size()];
    final int fieldCount = fieldInfos.size();
    for (int i = 0; i < fieldCount; i++) {
      if (!this.si.getNormFileName(i).equals(si.getNormFileName(i))) {
        normsUpToDate = false;
        fieldNormsChanged[i] = true;
      }
    }

    // if we're cloning we need to run through the reopenSegment logic
    // also if both old and new readers aren't readonly, we clone to avoid sharing modifications
    if (normsUpToDate && deletionsUpToDate && !doClone && openReadOnly && readOnly) {
      return this;
    }    

    // When cloning, the incoming SegmentInfos should not
    // have any changes in it:
    assert !doClone || (normsUpToDate && deletionsUpToDate);

    // clone reader
    SegmentReader clone;
    try {
      if (openReadOnly)
        clone = (SegmentReader) READONLY_IMPL.newInstance();
      else
        clone = (SegmentReader) IMPL.newInstance();
    } catch (Exception e) {
      throw new RuntimeException("cannot load SegmentReader class: " + e, e);
    }

    boolean success = false;
    try {
      coreRef.incRef();
      clone.coreRef = coreRef;
      clone.readOnly = openReadOnly;
      clone.directory = directory;
      clone.si = si;
      clone.segment = segment;
      clone.readBufferSize = readBufferSize;
      clone.cfsReader = cfsReader;
      clone.storeCFSReader = storeCFSReader;

      clone.fieldInfos = fieldInfos;
      clone.tis = tis;
      clone.freqStream = freqStream;
      clone.proxStream = proxStream;
      clone.termVectorsReaderOrig = termVectorsReaderOrig;
      clone.fieldsReaderOrig = fieldsReaderOrig;
      
      if (doClone) {
        if (deletedDocs != null) {
          deletedDocsRef.incRef();
          clone.deletedDocs = deletedDocs;
          clone.deletedDocsRef = deletedDocsRef;
        }
      } else {
        if (!deletionsUpToDate) {
          // load deleted docs
          assert clone.deletedDocs == null;
          clone.loadDeletedDocs();
        } else if (deletedDocs != null) {
          deletedDocsRef.incRef();
          clone.deletedDocs = deletedDocs;
          clone.deletedDocsRef = deletedDocsRef;
        }
      }

      clone.setDisableFakeNorms(getDisableFakeNorms());
      clone.norms = new HashMap();

      // Clone norms
      for (int i = 0; i < fieldNormsChanged.length; i++) {

        // Clone unchanged norms to the cloned reader
        if (doClone || !fieldNormsChanged[i]) {
          final String curField = fieldInfos.fieldInfo(i).name;
          Norm norm = (Norm) this.norms.get(curField);
          if (norm != null)
            clone.norms.put(curField, norm.clone());
        }
      }
      
      // If we are not cloning, then this will open anew
      // any norms that have changed:
      clone.openNorms(si.getUseCompoundFile() ? cfsReader : directory(), readBufferSize);

      success = true;
    } finally {
      if (!success) {
        // An exception occured during reopen, we have to decRef the norms
        // that we incRef'ed already and close singleNormsStream and FieldsReader
        clone.decRef();
      }
    }
    
    return clone;
  }

