  public static List<ReplicaPosition> getReplicaLocations(String collName, AutoScalingConfig autoScalingConfig,
                                                          SolrCloudManager cloudManager,
                                                          Map<String, String> optionalPolicyMapping,
                                                          List<String> shardNames,
                                                          int nrtReplicas,
                                                          int tlogReplicas,
                                                          int pullReplicas,
                                                          List<String> nodesList) {
    List<ReplicaPosition> positions = new ArrayList<>();
    ThreadLocal<Map<String, String>> policyMapping = getPolicyMapping(cloudManager);
    ClusterStateProvider stateProvider = new DelegatingClusterStateProvider(cloudManager.getClusterStateProvider()) {
      @Override
      public String getPolicyNameByCollection(String coll) {
        return policyMapping.get() != null && policyMapping.get().containsKey(coll) ?
            optionalPolicyMapping.get(coll) :
            delegate.getPolicyNameByCollection(coll);
      }
    };
    SolrCloudManager delegatingManager = new DelegatingCloudManager(cloudManager) {
      @Override
      public ClusterStateProvider getClusterStateProvider() {
        return stateProvider;
      }

      @Override
      public DistribStateManager getDistribStateManager() {
        if (autoScalingConfig != null) {
          return new DelegatingDistribStateManager(null) {
            @Override
            public AutoScalingConfig getAutoScalingConfig() {
              return autoScalingConfig;
            }
          };
        } else {
          return super.getDistribStateManager();
        }
      }
    };

    policyMapping.set(optionalPolicyMapping);
    SessionWrapper sessionWrapper = null;
    Policy.Session origSession = null;
    try {
      try {
        SESSION_WRAPPPER_REF.set(sessionWrapper = getSession(delegatingManager));
      } catch (Exception e) {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "unable to get autoscaling policy session", e);

      }
      origSession = sessionWrapper.session;
      // new session needs to be created to avoid side-effects from per-collection policies
      Policy.Session session = new Policy.Session(delegatingManager, origSession.policy, origSession.transaction);
      Map<String, Double> diskSpaceReqd = new HashMap<>();
      try {
        DocCollection coll = cloudManager.getClusterStateProvider().getCollection(collName);
        if (coll != null) {
          for (String shardName : shardNames) {
            Replica ldr = coll.getLeader(shardName);
            if (ldr != null && cloudManager.getClusterStateProvider().getLiveNodes().contains(ldr.getNodeName())) {
              Map<String, Map<String, List<ReplicaInfo>>> details = cloudManager.getNodeStateProvider().getReplicaInfo(ldr.getNodeName(),
                  Collections.singleton(FREEDISK.perReplicaValue));
              ReplicaInfo replicaInfo = details.getOrDefault(collName, emptyMap()).getOrDefault(shardName, singletonList(null)).get(0);
              if (replicaInfo != null) {
                Object idxSz = replicaInfo.getVariables().get(FREEDISK.perReplicaValue);
                if (idxSz != null) {
                  diskSpaceReqd.put(shardName, 1.5 * (Double) Variable.Type.FREEDISK.validate(null, idxSz, false));
                }
              }
            }

          }
        }
      } catch (IOException e) {
        log.warn("Exception while reading disk free metric values for nodes to be used for collection: {}", collName, e);
      }


      Map<Replica.Type, Integer> typeVsCount = new EnumMap<>(Replica.Type.class);
      typeVsCount.put(Replica.Type.NRT, nrtReplicas);
      typeVsCount.put(Replica.Type.TLOG, tlogReplicas);
      typeVsCount.put(Replica.Type.PULL, pullReplicas);
      for (String shardName : shardNames) {
        int idx = 0;
        for (Map.Entry<Replica.Type, Integer> e : typeVsCount.entrySet()) {
          for (int i = 0; i < e.getValue(); i++) {
            Suggester suggester = session.getSuggester(ADDREPLICA)
                .hint(Hint.REPLICATYPE, e.getKey())
                .hint(Hint.COLL_SHARD, new Pair<>(collName, shardName));
            if (nodesList != null) {
              for (String nodeName : nodesList) {
                suggester = suggester.hint(Hint.TARGET_NODE, nodeName);
              }
            }
            if (diskSpaceReqd.get(shardName) != null) {
              suggester.hint(Hint.MINFREEDISK, diskSpaceReqd.get(shardName));
            }
            SolrRequest op = suggester.getSuggestion();
            if (op == null) {
              String errorId = "AutoScaling.error.diagnostics." + System.nanoTime();
              Policy.Session sessionCopy = suggester.session;
              log.error("errorId : {} {}", errorId
                  , handleExp(log, "", () -> Utils.writeJson(getDiagnostics(sessionCopy), new StringWriter(), true).toString())
              ); // logOK

              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, " No node can satisfy the rules " +
                  Utils.toJSONString(Utils.getDeepCopy(session.expandedClauses, 4, true) + " More details from logs in node : "
                      + Utils.getMDCNode() + ", errorId : " + errorId));
            }
            session = suggester.getSession();
            positions.add(new ReplicaPosition(shardName, ++idx, e.getKey(), op.getParams().get(NODE)));
          }
        }
      }
    } finally {
      policyMapping.remove();
      if (sessionWrapper != null) {
        sessionWrapper.returnSession(origSession);
      }
    }
    return positions;
  }

