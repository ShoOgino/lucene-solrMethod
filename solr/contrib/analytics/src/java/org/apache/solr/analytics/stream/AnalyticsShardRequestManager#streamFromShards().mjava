  /**
   * Send a shard request to each chosen replica, streaming
   * the responses back to the {@link AnalyticsRequestManager}
   * through the {@link AnalyticsShardResponseParser}.
   * <p>
   * A thread pool is used to send the requests simultaneously,
   * and therefore importing the results is also done in parallel.
   * However the manager can only import one shard response at a time,
   * so the {@link AnalyticsShardResponseParser} is blocked until each import is finished.
   *
   * @throws IOException if an exception occurs while sending requests.
   */
  private void streamFromShards() throws IOException {
    ExecutorService service = ExecutorUtil.newMDCAwareCachedThreadPool(new SolrNamedThreadFactory("SolrAnalyticsStream"));
    List<Future<SolrException>> futures = new ArrayList<>();
    List<AnalyticsShardRequester> openers = new ArrayList<>();
    for (String replicaUrl : replicaUrls) {
      AnalyticsShardRequester opener = new AnalyticsShardRequester(replicaUrl);
      openers.add(opener);
      Future<SolrException> future = service.submit(opener);
      futures.add(future);
    }
    try {
      for (Future<SolrException> f : futures) {
        SolrException e = f.get();
        if (e != null) {
          if (TimeExceededStubException.isIt(e)) {
            manager.setPartialResults(true);
          } else {
            throw e;
          }
        }
      }
    } catch (InterruptedException e1) {
      throw new RuntimeException(e1);
    } catch (ExecutionException e1) {
      throw new RuntimeException(e1);
    } finally {
      service.shutdown();
      for (AnalyticsShardRequester opener : openers) {
        opener.close();
      }
    }
  }

