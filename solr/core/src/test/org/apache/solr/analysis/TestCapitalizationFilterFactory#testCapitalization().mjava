  public void testCapitalization() throws Exception 
  {
    Map<String,String> args = new HashMap<String, String>();
    args.put( CapitalizationFilterFactory.KEEP, "and the it BIG" );
    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, "true" );  
    
    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
    factory.setLuceneMatchVersion(DEFAULT_VERSION);
    factory.init( args );
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.WHITESPACE, false)),
        new String[] { "Kitten" });
    
    factory.forceFirstLetter = true;

    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("and"), MockTokenizer.WHITESPACE, false)),
        new String[] { "And" });

    //first is forced, but it's not a keep word, either
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("AnD"), MockTokenizer.WHITESPACE, false)),
        new String[] { "And" });

    factory.forceFirstLetter = false;

    //first is not forced, but it's not a keep word, either
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("AnD"), MockTokenizer.WHITESPACE, false)),
        new String[] { "And" });

    factory.forceFirstLetter = true;
    
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("big"), MockTokenizer.WHITESPACE, false)),
        new String[] { "Big" });
    
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("BIG"), MockTokenizer.WHITESPACE, false)),
        new String[] { "BIG" });

    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.KEYWORD, false)),
        new String[] { "Hello there my name is ryan" });
        
    // now each token
    factory.onlyFirstWord = false;
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.WHITESPACE, false)),
        new String[] { "Hello", "There", "My", "Name", "Is", "Ryan" });
    
    // now only the long words
    factory.minWordLength = 3;
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.WHITESPACE, false)),
        new String[] { "Hello", "There", "my", "Name", "is", "Ryan" });
    
    // without prefix
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("McKinley"), MockTokenizer.WHITESPACE, false)),
        new String[] { "Mckinley" });
    
    // Now try some prefixes
    factory = new CapitalizationFilterFactory();
    factory.setLuceneMatchVersion(DEFAULT_VERSION);
    args.put( "okPrefix", "McK" );  // all words
    factory.init( args );
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("McKinley"), MockTokenizer.WHITESPACE, false)),
        new String[] { "McKinley" });
    
    // now try some stuff with numbers
    factory.forceFirstLetter = false;
    factory.onlyFirstWord = false;
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("1st 2nd third"), MockTokenizer.WHITESPACE, false)),
        new String[] { "1st", "2nd", "Third" });
    
    factory.forceFirstLetter = true;
    assertTokenStreamContents(factory.create(
        new MockTokenizer(new StringReader("the The the"), MockTokenizer.KEYWORD, false)),
        new String[] { "The The the" });
  }

