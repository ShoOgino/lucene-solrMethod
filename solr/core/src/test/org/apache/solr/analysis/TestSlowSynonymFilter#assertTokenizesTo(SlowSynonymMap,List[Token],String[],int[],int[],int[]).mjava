  static void assertTokenizesTo(SlowSynonymMap dict, List<Token> input,
      String expected[], int startOffsets[], int endOffsets[], int posIncs[])
      throws IOException {
    TokenStream tokenizer = new IterTokenStream(input);
    SlowSynonymFilter stream = new SlowSynonymFilter(tokenizer, dict);
    assertTokenStreamContents(stream, expected, startOffsets, endOffsets,
        posIncs);
  }

