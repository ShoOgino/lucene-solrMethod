  // As of Lucene/Solr 4.9, StandardTokenizer never does this anymore (reported to Lucene dev-list,
  // Jan 26th 2015.  Honestly it's not particularly important to us but it renders this test
  // pointless.
  /** Orig issue https://github.com/OpenSextant/SolrTextTagger/issues/2  related: #13 */
  @Test
  @Ignore
  public void testVeryLongWord() throws Exception {
    String SANFRAN = "San Francisco";
    buildNames(SANFRAN);

    // exceeds default 255 max token length which means it in-effect becomes a stop-word
    StringBuilder STOP = new StringBuilder(260);//>255
    for (int i = 0; i < STOP.capacity(); i++) {
      STOP.append((char) ('0' + (i % 10)));
    }

    String doc = "San " + STOP + " Francisco";
    assertTags(doc);//no match due to default stop word handling
    //and we find it when we ignore stop words
    assertTags(reqDoc(doc, "ignoreStopwords", "true"), new TestTag(0, doc.length(), doc, lookupByName(SANFRAN)));
  }

