  @Test
  public void testHistogramBuilding() throws Exception {
    List<Prefix> prefixes = SplitByPrefixTest.findPrefixes(20, 0, 0x00ffffff);
    List<Prefix> uniquePrefixes = SplitByPrefixTest.removeDups(prefixes);
    assertTrue(prefixes.size() > uniquePrefixes.size());  // make sure we have some duplicates to test hash collisions

    String prefixField = "id_prefix_s";
    String idField = "id";
    DocRouter router = new CompositeIdRouter();


    for (int i=0; i<100; i++) {
      SolrQueryRequest req = req("myquery");
      try {
        // the first time through the loop we do this before adding docs to test an empty index
        Collection<SplitOp.RangeCount> counts1 = SplitOp.getHashHistogram(req.getSearcher(), prefixField, router, null);
        Collection<SplitOp.RangeCount> counts2 = SplitOp.getHashHistogramFromId(req.getSearcher(), idField, router, null);
        assertTrue(eqCount(counts1, counts2));

        if (i>0) {
          assertTrue(counts1.size() > 0);  // make sure we are testing something
        }


        // index a few random documents
        int ndocs = random().nextInt(10) + 1;
        for (int j=0; j<ndocs; j++) {
          String prefix = prefixes.get( random().nextInt(prefixes.size()) ).key;
          if (random().nextBoolean()) {
            prefix = prefix + Integer.toString(random().nextInt(3)) + "!";
          }
          String id = prefix + "doc" + i + "_" + j;
          updateJ(jsonAdd(sdoc(idField, id, prefixField, prefix)), null);
        }

        assertU(commit());


      } finally {
        req.close();
      }

    }

  }

