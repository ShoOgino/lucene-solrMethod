  @Test
  public void testUpdateLogSynchronisation() throws Exception {
    createCollections();
    CdcrTestsUtil.cdcrStart(sourceSolrClient);
    Thread.sleep(2000);

    // index 100 docs
    for (int i = 0; i < 100; i++) {
      // will perform a commit for every document and will create one tlog file per commit
      SolrInputDocument doc = new SolrInputDocument();
      doc.addField("id", "doc_" + i);
      CdcrTestsUtil.index(source, "cdcr-source", doc, true);
    }
    Thread.sleep(2000);

    //verify cdcr has replicated docs
    QueryResponse response = sourceSolrClient.query(new SolrQuery(ALL_Q));
    assertEquals("source docs mismatch", 100, response.getResults().getNumFound());
    assertEquals("target docs mismatch", 100, CdcrTestsUtil.waitForClusterToSync(100, targetSolrClient));

    // Get the number of tlog files on the replicas (should be equal to the number of documents indexed)
    int nTlogs = CdcrTestsUtil.getNumberOfTlogFilesOnReplicas(source);

    // Disable the buffer - ulog synch should start on non-leader nodes
    CdcrTestsUtil.cdcrDisableBuffer(sourceSolrClient);
    Thread.sleep(2000);

    int cnt = 15; // timeout after 15 seconds
    int n = 0;
    while (cnt > 0) {
      // Index a new document with a commit to trigger update log cleaning
      SolrInputDocument doc = new SolrInputDocument();
      doc.addField("id", "doc_" + random().nextLong());
      CdcrTestsUtil.index(source, "cdcr-source", doc, true);

      // Check the update logs on non-leader nodes, the number of tlog files should decrease
      n = CdcrTestsUtil.getNumberOfTlogFilesOnReplicas(source);
      if (n < nTlogs) {
        cnt = Integer.MIN_VALUE;
        break;
      }
      cnt--;
      Thread.sleep(1000);
    }
    if (cnt == 0) {
      throw new AssertionError("Timeout while trying to assert update logs @ source_collection, " + n + " " + nTlogs);
    }

    CdcrTestsUtil.cdcrStop(sourceSolrClient);
    CdcrTestsUtil.cdcrStop(targetSolrClient);

    deleteCollections();
  }

