  @Before
  public void setupSystemCollection() throws Exception {
    ZkController zkController = cluster.getJettySolrRunner(0).getCoreContainer().getZkController();
    cloudManager = zkController.getSolrCloudManager();
    solrClient = new CloudSolrClientBuilder(Collections.singletonList(zkController.getZkServerAddress()),
        Optional.empty()).build();
    CollectionAdminRequest.OverseerStatus status = new CollectionAdminRequest.OverseerStatus();
    CollectionAdminResponse adminResponse = status.process(solrClient);
    String overseerLeader = (String) adminResponse.getResponse().get("leader");
    Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());
    nodes.remove(overseerLeader);
    // put .system replicas on other nodes that the overseer
    CollectionAdminRequest.createCollection(CollectionAdminParams.SYSTEM_COLL, null, 1, 2)
        .setCreateNodeSet(String.join(",", nodes))
        .setMaxShardsPerNode(2)
        .process(cluster.getSolrClient());
    cluster.waitForActiveCollection(CollectionAdminParams.SYSTEM_COLL,  1, 2);
    // send a dummy doc to the .system collection
    SolrInputDocument doc = new SolrInputDocument(
        "id", IdUtils.timeRandomId(),
        CommonParams.TYPE, "dummy");
    doc.addField("time_l", cloudManager.getTimeSource().getEpochTimeNs());
    doc.addField("timestamp", new Date());
    solrClient.add(CollectionAdminParams.SYSTEM_COLL, doc);
    solrClient.commit(CollectionAdminParams.SYSTEM_COLL);

    Map<String, Long> coreStartTimes = new HashMap<>();
    DocCollection coll = cloudManager.getClusterStateProvider().getCollection(CollectionAdminParams.SYSTEM_COLL);
    for (Replica r : coll.getReplicas()) {
      coreStartTimes.put(r.getName(), getCoreStatus(r).getCoreStartTime().getTime());
    }
    // trigger compat report by changing the schema
    SchemaRequest req = new SchemaRequest();
    SchemaResponse rsp = req.process(solrClient, CollectionAdminParams.SYSTEM_COLL);
    Map<String, Object> field = getSchemaField("timestamp", rsp);
    // make some obviously incompatible changes
    field.put("type", "string");
    field.put("docValues", false);
    SchemaRequest.ReplaceField replaceFieldRequest = new SchemaRequest.ReplaceField(field);
    SchemaResponse.UpdateResponse replaceFieldResponse = replaceFieldRequest.process(solrClient, CollectionAdminParams.SYSTEM_COLL);
    assertEquals(replaceFieldResponse.toString(), 0, replaceFieldResponse.getStatus());
    CollectionAdminRequest.Reload reloadRequest = CollectionAdminRequest.reloadCollection(CollectionAdminParams.SYSTEM_COLL);
    CollectionAdminResponse response = reloadRequest.process(solrClient);
    assertEquals(0, response.getStatus());
    assertTrue(response.isSuccess());
    // wait for the reload of all replicas to complete
    RetryUtil.retryUntil("Timed out waiting for core to reload", 30, 1000, TimeUnit.MILLISECONDS, () -> {
      boolean allReloaded = true;
      for (Replica r : coll.getReplicas()) {
        long previousTime = coreStartTimes.get(r.getName());
        try {
          long currentTime = getCoreStatus(r).getCoreStartTime().getTime();
          allReloaded = allReloaded && (previousTime < currentTime);
        } catch (Exception e) {
          log.warn("Error retrieving replica status of {}", Utils.toJSONString(r), e);
          allReloaded = false;
        }
      }
      return allReloaded;
    });
    cluster.waitForActiveCollection(CollectionAdminParams.SYSTEM_COLL,  1, 2);

  }

