  @Test
  public void test() throws Exception {

    sanityCheckAssertNumerics();

    waitForThingsToLevelOut(30000); // TODO: why would we have to wait?
    // 
    handle.clear();
    handle.put("QTime", SKIPVAL);
    handle.put("timestamp", SKIPVAL);
    
    final Set<String> fieldNameSet = new HashSet<>();
    
    // build up a randomized index
    final int numDocs = atLeast(500);
    log.info("numDocs: {}", numDocs);

    for (int i = 1; i <= numDocs; i++) {
      SolrInputDocument doc = buildRandomDocument(i);

      // not efficient, but it guarantees that even if people change buildRandomDocument
      // we'll always have the full list of fields w/o needing to keep code in sync
      fieldNameSet.addAll(doc.getFieldNames());

      cloudClient.add(doc);
    }
    cloudClient.commit();

    fieldNameSet.remove("id");
    assertTrue("WTF, bogus field exists?", fieldNameSet.add("bogus_not_in_any_doc_s"));

    final String[] fieldNames = fieldNameSet.toArray(new String[fieldNameSet.size()]);
    Arrays.sort(fieldNames); // need determinism when picking random fields


    for (int i = 0; i < 5; i++) {

      String q = "*:*";
      if (random().nextBoolean()) {
        q = "id:[* TO " + TestUtil.nextInt(random(),300,numDocs) + "]";
      }
      ModifiableSolrParams baseP = params("rows", "0", "q", q);
      
      if (random().nextBoolean()) {
        baseP.add("fq", "id:[* TO " + TestUtil.nextInt(random(),200,numDocs) + "]");
      }

      final boolean stats = random().nextBoolean();
      if (stats) {
        baseP.add(StatsParams.STATS, "true");
        
        // if we are doing stats, then always generated the same # of STATS_FIELD
        // params, using multiple tags from a fixed set, but with diff fieldName values.
        // later, each pivot will randomly pick a tag.
        baseP.add(StatsParams.STATS_FIELD, "{!key=sk1 tag=st1,st2}" +
                  pickRandomStatsFields(fieldNames));
        baseP.add(StatsParams.STATS_FIELD, "{!key=sk2 tag=st2,st3}" +
                  pickRandomStatsFields(fieldNames));
        baseP.add(StatsParams.STATS_FIELD, "{!key=sk3 tag=st3,st4}" +
                  pickRandomStatsFields(fieldNames));
        // NOTE: there's a chance that some of those stats field names
        // will be the same, but if so, all the better to test that edge case
      }
      
      ModifiableSolrParams pivotP = params(FACET,"true");

      // put our FACET_PIVOT params in a set in case we just happen to pick the same one twice
      LinkedHashSet<String> pivotParamValues = new LinkedHashSet<String>();
      pivotParamValues.add(buildPivotParamValue(buildRandomPivot(fieldNames)));
                 
      if (random().nextBoolean()) {
        pivotParamValues.add(buildPivotParamValue(buildRandomPivot(fieldNames)));
      }
      pivotP.set(FACET_PIVOT, pivotParamValues.toArray(new String[pivotParamValues.size()]));

      // keep limit low - lots of unique values, and lots of depth in pivots
      pivotP.add(FACET_LIMIT, ""+TestUtil.nextInt(random(),1,17));

      // sometimes use an offset
      if (random().nextBoolean()) {
        pivotP.add(FACET_OFFSET, ""+TestUtil.nextInt(random(),0,7));
      }

      if (random().nextBoolean()) {
        String min = ""+TestUtil.nextInt(random(),0,numDocs+10);
        pivotP.add(FACET_PIVOT_MINCOUNT, min);
        // trace param for validation
        baseP.add(TRACE_MIN, min);
      }
      
      if (random().nextBoolean()) {
        pivotP.add(FACET_DISTRIB_MCO, "true");
        // trace param for validation
        baseP.add(TRACE_DISTRIB_MIN, "true");
      }

      if (random().nextBoolean()) {
        String missing = ""+random().nextBoolean();
        pivotP.add(FACET_MISSING, missing);
        // trace param for validation
        baseP.add(TRACE_MISS, missing);
      }

      if (random().nextBoolean()) {
        String sort = random().nextBoolean() ? "index" : "count";
        pivotP.add(FACET_SORT, sort);
        // trace param for validation
        baseP.add(TRACE_SORT, sort);
      }

      // overrequest
      //
      // NOTE: since this test focuses on accuracy of refinement, and doesn't do 
      // control collection comparisons, there isn't a lot of need for excessive
      // overrequesting -- we focus here on trying to exercise the various edge cases
      // involved as different values are used with overrequest
      if (0 == TestUtil.nextInt(random(),0,4)) {
        // we want a decent chance of no overrequest at all
        pivotP.add(FACET_OVERREQUEST_COUNT, "0");
        pivotP.add(FACET_OVERREQUEST_RATIO, "0");
      } else {
        if (random().nextBoolean()) {
          pivotP.add(FACET_OVERREQUEST_COUNT, ""+TestUtil.nextInt(random(),0,5));
        }
        if (random().nextBoolean()) {
          // sometimes give a ratio less then 1, code should be smart enough to deal
          float ratio = 0.5F + random().nextFloat();
          // sometimes go negative
          if (random().nextBoolean()) {
            ratio *= -1;
          }
          pivotP.add(FACET_OVERREQUEST_RATIO, ""+ratio);
        }
      }
      
      assertPivotCountsAreCorrect(baseP, pivotP);
    }
  }

