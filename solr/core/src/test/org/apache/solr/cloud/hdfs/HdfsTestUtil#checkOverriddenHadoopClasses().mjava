  /**
   * Ensure that the tests are picking up the modified Hadoop classes
   */
  private static void checkOverriddenHadoopClasses() {
    List<Class<?>> modifiedHadoopClasses = new ArrayList<>(Arrays.asList(
        DiskChecker.class,
        FileUtil.class,
        HardLink.class,
        HttpServer2.class,
        NameNodeResourceChecker.class,
        RawLocalFileSystem.class));
    // Dodge weird scope errors from the compiler (SOLR-14417)
    try {
      modifiedHadoopClasses.add(
          Class.forName("org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice"));
    } catch (Exception e) {
      throw new RuntimeException(e);
    }

    for (Class<?> clazz : modifiedHadoopClasses) {
      try {
        LuceneTestCase.assertNotNull("Field on " + clazz.getCanonicalName() + " should not have been null",
            clazz.getField(SOLR_HACK_FOR_CLASS_VERIFICATION_FIELD));
      } catch (NoSuchFieldException e) {
        LuceneTestCase.fail("Expected to load Solr modified Hadoop class " + clazz.getCanonicalName() +
            " , but it was not found.");
      }
    }
  }

