  protected void testMinRf() throws Exception {
    // create a collection that has 1 shard and 3 replicas
    String testCollectionName = "collMinRf_1x3";
    createCollection(testCollectionName, "conf1", 1, 3, 1);
    cloudClient.setDefaultCollection(testCollectionName);

    sendDoc(1, 2);

    JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(getShardLeader(testCollectionName, "shard1", 1000)));
    List<Replica> notLeaders =
        ensureAllReplicasAreActive(testCollectionName, "shard1", 1, 3, maxWaitSecsToSeeAllActive);
    assertTrue("Expected 2 non-leader replicas for collection " + testCollectionName
            + " but found " + notLeaders.size() + "; clusterState: "
            + printClusterStateInfo(testCollectionName),
        notLeaders.size() == 2);

    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 1);

    // Now introduce a network partition between the leader and 1 replica, so a minRf of 2 is still achieved
    log.info("partitioning replica :  " + notLeaders.get(0));
    SocketProxy proxy0 = getProxyForReplica(notLeaders.get(0));
    SocketProxy leaderProxy = getProxyForReplica(getShardLeader(testCollectionName, "shard1", 1000));

    proxy0.close();
    // leader still can connect to replica 2, by closing leaderProxy, replica 1 can not do recovery
    leaderProxy.close();

    // indexing during a partition
    int achievedRf = sendDoc(2, 2, leaderJetty);
    assertEquals("Unexpected achieved replication factor", 2, achievedRf);
    try (ZkShardTerms zkShardTerms = new ZkShardTerms(testCollectionName, "shard1", cloudClient.getZkStateReader().getZkClient())) {
      assertFalse(zkShardTerms.canBecomeLeader(notLeaders.get(0).getName()));
    }
    Thread.sleep(sleepMsBeforeHealPartition);
    proxy0.reopen();
    leaderProxy.reopen();

    notLeaders =
        ensureAllReplicasAreActive(testCollectionName, "shard1", 1, 3, maxWaitSecsToSeeAllActive);

    // Since minRf is achieved, we expect recovery, so we expect seeing 2 documents
    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 2);

    // Now introduce a network partition between the leader and both of its replicas, so a minRf of 2 is NOT achieved
    proxy0 = getProxyForReplica(notLeaders.get(0));
    proxy0.close();
    SocketProxy proxy1 = getProxyForReplica(notLeaders.get(1));
    proxy1.close();
    leaderProxy = getProxyForReplica(getShardLeader(testCollectionName, "shard1", 1000));
    leaderProxy.close();

    achievedRf = sendDoc(3, 2, leaderJetty);
    assertEquals("Unexpected achieved replication factor", 1, achievedRf);

    Thread.sleep(sleepMsBeforeHealPartition);

    // Verify that the partitioned replicas are NOT DOWN since minRf wasn't achieved
    ensureAllReplicasAreActive(testCollectionName, "shard1", 1, 3, 1);

    proxy0.reopen();
    proxy1.reopen();
    leaderProxy.reopen();

    notLeaders =
        ensureAllReplicasAreActive(testCollectionName, "shard1", 1, 3, maxWaitSecsToSeeAllActive);

    // Check that doc 3 is on the leader but not on the notLeaders
    Replica leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, "shard1", 10000);
    try (HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName)) {
      assertDocExists(leaderSolr, testCollectionName, "3");
    }

    for (Replica notLeader : notLeaders) {
      try (HttpSolrClient notLeaderSolr = getHttpSolrClient(notLeader, testCollectionName)) {
        assertDocNotExists(notLeaderSolr, testCollectionName, "3");
      }
    }

    // Retry sending doc 3
    achievedRf = sendDoc(3, 2);
    assertEquals("Unexpected achieved replication factor", 3, achievedRf);

    // Now doc 3 should be on all replicas
    assertDocsExistInAllReplicas(notLeaders, testCollectionName, 1, 3);
  }

