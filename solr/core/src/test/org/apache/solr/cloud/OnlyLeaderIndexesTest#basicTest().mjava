  public void basicTest() throws Exception {
    CloudSolrClient cloudClient = cluster.getSolrClient();
    new UpdateRequest()
        .add(sdoc("id", "1"))
        .add(sdoc("id", "2"))
        .add(sdoc("id", "3"))
        .add(sdoc("id", "4"))
        .process(cloudClient, COLLECTION);

    {
      UpdateHandler updateHandler = getSolrCore(true).get(0).getUpdateHandler();
      RefCounted<IndexWriter> iwRef = updateHandler.getSolrCoreState().getIndexWriter(null);
      assertTrue("IndexWriter at leader must see updates ", iwRef.get().hasUncommittedChanges());
      iwRef.decref();
    }

    for (SolrCore solrCore : getSolrCore(false)) {
      RefCounted<IndexWriter> iwRef = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);
      assertFalse("IndexWriter at replicas must not see updates ", iwRef.get().hasUncommittedChanges());
      iwRef.decref();
    }

    checkRTG(1, 4, cluster.getJettySolrRunners());

    new UpdateRequest()
        .deleteById("1")
        .deleteByQuery("id:2")
        .process(cloudClient, COLLECTION);

    // The DBQ is not processed at replicas, so we still can get doc2 and other docs by RTG
    checkRTG(2,4, getSolrRunner(false));

    new UpdateRequest()
        .commit(cloudClient, COLLECTION);

    checkShardConsistency(2, 1);

    // Update log roll over
    for (SolrCore solrCore : getSolrCore(false)) {
      UpdateLog updateLog = solrCore.getUpdateHandler().getUpdateLog();
      assertFalse(updateLog.hasUncommittedChanges());
    }

    // UpdateLog copy over old updates
    for (int i = 15; i <= 150; i++) {
      cloudClient.add(COLLECTION, sdoc("id",String.valueOf(i)));
      if (random().nextInt(100) < 15 & i != 150) {
        cloudClient.commit(COLLECTION);
      }
    }
    checkRTG(120,150, cluster.getJettySolrRunners());
    waitForReplicasCatchUp(20);
  }

