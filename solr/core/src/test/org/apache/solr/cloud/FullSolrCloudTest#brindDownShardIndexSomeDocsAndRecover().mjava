  private void brindDownShardIndexSomeDocsAndRecover() throws Exception,
      SolrServerException, IOException, InterruptedException {
    
    commit();
    query("q", "*:*", "sort", "n_tl1 desc");
    
    // kill a shard
    JettySolrRunner deadShard = chaosMonkey.stopShard(SHARD2, 0);
    cloudClient.connect();
    int tries = 0;
    while (cloudClient.getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {
      if (tries++ == 60) {
        fail("Shard still reported as live in zk");
      }
      Thread.sleep(1000);
    }
	
    // ensure shard is dead
    try {
      // TODO: ignore fail
      index_specific(shardToClient.get(SHARD2).get(0), id, 999, i1, 107, t1,
          "specific doc!");
      fail("This server should be down and this update should have failed");
    } catch (SolrServerException e) {
      // expected..
    }
    
    commit();
    query("q", "*:*", "sort", "n_tl1 desc");
    
    // long cloudClientDocs = cloudClient.query(new
    // SolrQuery("*:*")).getResults().getNumFound();
    // System.out.println("clouddocs:" + cloudClientDocs);
    
    // try to index to a living shard at shard2
    
    // we are careful to make sure the downed node is not longer in the state,
    // because on some systems (especially freebsd w/ blackhole enabled), trying
    // to talk to a downed node causes grief
    tries = 0;
    while (((SolrDispatchFilter) shardToJetty.get(SHARD2).get(1).jetty.getDispatchFilter().getFilter()).getCores().getZkController().getZkStateReader().getCloudState().liveNodesContain(clientToInfo.get(new CloudSolrServerClient(shardToClient.get(SHARD2).get(0))).get(ZkStateReader.NODE_NAME_PROP))) {
      if (tries++ == 60) {
        fail("Shard still reported as live in zk");
      }
      Thread.sleep(1000);
    }
	
    
    index_specific(shardToClient.get(SHARD2).get(1), id, 1000, i1, 108, t1,
        "specific doc!");
    
    commit();
    
    checkShardConsistency(true, false);
    
    query("q", "*:*", "sort", "n_tl1 desc");
    
    // try adding a doc with CloudSolrServer
    cloudClient.setDefaultCollection(DEFAULT_COLLECTION);
    SolrQuery query = new SolrQuery("*:*");
    long numFound1 = cloudClient.query(query).getResults().getNumFound();
    
    SolrInputDocument doc = new SolrInputDocument();
    doc.addField("id", 1001);
    
    controlClient.add(doc);
    
    UpdateRequest ureq = new UpdateRequest();
    ureq.add(doc);
    // ureq.setParam("update.chain", DISTRIB_UPDATE_CHAIN);
    ureq.process(cloudClient);
    
    commit();
    
    query("q", "*:*", "sort", "n_tl1 desc");
    
    long numFound2 = cloudClient.query(query).getResults().getNumFound();
    
    // lets just check that the one doc since last commit made it in...
    assertEquals(numFound1 + 1, numFound2);
    
    // test debugging
    testDebugQueries();
    
    if (VERBOSE) {
      System.out.println(controlClient.query(new SolrQuery("*:*")).getResults()
          .getNumFound());
      
      for (SolrServer client : clients) {
        try {
          System.out.println(client.query(new SolrQuery("*:*")).getResults()
              .getNumFound());
        } catch (Exception e) {
          
        }
      }
    }
    // TODO: This test currently fails because debug info is obtained only
    // on shards with matches.
    // query("q","matchesnothing","fl","*,score", "debugQuery", "true");
    
    // this should trigger a recovery phase on deadShard
    
    deadShard.start(true);
    
    // make sure we have published we are recoverying
    Thread.sleep(1500);
    
    waitForRecoveriesToFinish(false);
    
    List<SolrServer> s2c = shardToClient.get(SHARD2);
    
    // if we properly recovered, we should now have the couple missing docs that
    // came in while shard was down
    assertEquals(s2c.get(0).query(new SolrQuery("*:*")).getResults()
        .getNumFound(), s2c.get(1).query(new SolrQuery("*:*")).getResults()
        .getNumFound());
  }

