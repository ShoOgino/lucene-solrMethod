  @Test
  public void doTest() throws IOException, SolrServerException {
    CollectionAdminRequest
        .createCollection(COLLECTION_NAME, "conf", 1, 1)
        .setMaxShardsPerNode(100)
        .process(cluster.getSolrClient());

    cluster.waitForActiveCollection(COLLECTION_NAME, 1, 1);


    CloudSolrClient client = cluster.getSolrClient();
    client.setDefaultCollection(COLLECTION_NAME);

    // splitting an empty collection by prefix should still work (i.e. fall back to old method of just dividing the hash range

    CollectionAdminRequest.SplitShard splitShard = CollectionAdminRequest.splitShard(COLLECTION_NAME)
        .setNumSubShards(2)
        .setSplitByPrefix(true)
        .setShardName("shard1");
    splitShard.process(client);
    waitForState("Timed out waiting for sub shards to be active.",
        COLLECTION_NAME, activeClusterShape(2, 3));  // expectedReplicas==3 because original replica still exists (just inactive)


    List<Prefix> prefixes = findPrefixes(20, 0, 0x00ffffff);
    List<Prefix> uniquePrefixes = removeDups(prefixes);
    if (uniquePrefixes.size() % 2 == 1) {  // make it an even sized list so we can split it exactly in two
      uniquePrefixes.remove(uniquePrefixes.size()-1);
    }
    log.info("Unique prefixes: " + uniquePrefixes);

    for (Prefix prefix : uniquePrefixes) {
      client.add( getDoc(prefix.key, "doc1") );
      client.add( getDoc(prefix.key, "doc2") );
    }
    client.commit();


    splitShard = CollectionAdminRequest.splitShard(COLLECTION_NAME)
        .setSplitByPrefix(true)
        .setShardName("shard1_1");  // should start out with the range of 0-7fffffff
    splitShard.process(client);
    waitForState("Timed out waiting for sub shards to be active.",
        COLLECTION_NAME, activeClusterShape(3, 5));

    // OK, now let's check that the correct split point was chosen
    // We can use the router to find the shards for the middle prefixes and they should be different.

    DocCollection collection = client.getZkStateReader().getClusterState().getCollection(COLLECTION_NAME);
    Collection<Slice> slices1 = collection.getRouter().getSearchSlicesSingle(uniquePrefixes.get(uniquePrefixes.size()/2 - 1).key, null, collection);
    Collection<Slice> slices2 = collection.getRouter().getSearchSlicesSingle(uniquePrefixes.get(uniquePrefixes.size()/2    ).key, null, collection);

    Slice slice1 = slices1.iterator().next();
    Slice slice2 = slices2.iterator().next();

    assertTrue(slices1.size() == 1 && slices2.size() == 1);
    assertTrue(slice1 != slice2);


    //
    // now lets add enough documents to the first prefix to get it split out on it's own
    //
    for (int i=0; i<uniquePrefixes.size(); i++) {
      client.add(  getDoc(uniquePrefixes.get(0).key, "doc"+(i+100)));
    }
    client.commit();

    splitShard = CollectionAdminRequest.splitShard(COLLECTION_NAME)
        .setSplitByPrefix(true)
        .setShardName(slice1.getName());
    splitShard.process(client);
    waitForState("Timed out waiting for sub shards to be active.",
        COLLECTION_NAME, activeClusterShape(4, 7));

    collection = client.getZkStateReader().getClusterState().getCollection(COLLECTION_NAME);
    slices1 = collection.getRouter().getSearchSlicesSingle(uniquePrefixes.get(0).key, null, collection);
    slices2 = collection.getRouter().getSearchSlicesSingle(uniquePrefixes.get(1).key, null, collection);

    slice1 = slices1.iterator().next();
    slice2 = slices2.iterator().next();

    assertTrue(slices1.size() == 1 && slices2.size() == 1);
    assertTrue(slice1 != slice2);


    // Now if we call split (with splitByPrefix) on a shard that has a single prefix, it should split it in half

    splitShard = CollectionAdminRequest.splitShard(COLLECTION_NAME)
        .setSplitByPrefix(true)
        .setShardName(slice1.getName());
    splitShard.process(client);
    waitForState("Timed out waiting for sub shards to be active.",
        COLLECTION_NAME, activeClusterShape(5, 9));

    collection = client.getZkStateReader().getClusterState().getCollection(COLLECTION_NAME);
    slices1 = collection.getRouter().getSearchSlicesSingle(uniquePrefixes.get(0).key, null, collection);
    slice1 = slices1.iterator().next();

    assertTrue(slices1.size() == 2);

    //
    // split one more time, this time on a partial prefix/bucket
    //
    splitShard = CollectionAdminRequest.splitShard(COLLECTION_NAME)
        .setSplitByPrefix(true)
        .setShardName(slice1.getName());
    splitShard.process(client);
    waitForState("Timed out waiting for sub shards to be active.",
        COLLECTION_NAME, activeClusterShape(6, 11));

    collection = client.getZkStateReader().getClusterState().getCollection(COLLECTION_NAME);
    slices1 = collection.getRouter().getSearchSlicesSingle(uniquePrefixes.get(0).key, null, collection);

    assertTrue(slices1.size() == 3);

    // System.err.println("### STATE=" + cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(COLLECTION_NAME));
    // System.err.println("### getActiveSlices()=" + cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(COLLECTION_NAME).getActiveSlices());
  }

