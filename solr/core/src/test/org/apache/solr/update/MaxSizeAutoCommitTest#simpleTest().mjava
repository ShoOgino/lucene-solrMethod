  @Test
  public void simpleTest() throws Exception {
    int maxFileSizeBound = 1000;
    int maxFileSizeBoundWithBuffer = (int) (maxFileSizeBound * 1.25);
    // Set max size bound
    hardCommitTracker.setTLogFileSizeUpperBound(maxFileSizeBound);

    // Adding these docs will place the tlog size just under the threshold
    int numDocs = 27;
    int batchSize = 3;
    int numBatches = numDocs / batchSize;
    SolrQueryResponse updateResp = new SolrQueryResponse();
    int numTlogs = -1;
    TreeMap<String, Long> tlogsInfo = null;

    for (int batchCounter = 0; batchCounter < numBatches; batchCounter++) {
      int docStartId = batchSize * batchCounter;

      // Send batch update request
      updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);

      // The sleep is to allow existing commits to finish (or at least mostly finish) before querying/submitting more documents
      waitForCommit(200);

      // There should just be 1 tlog and its size should be within the (buffered) file size bound
      tlogsInfo = getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);
      numTlogs = parseTotalNumTlogs(tlogsInfo);
      Assert.assertEquals(1, numTlogs);
    }

    // Now that the core's tlog size is just under the threshold, one more update should induce a commit
    int docStartId = batchSize * numBatches;
    updateRequestHandler.handleRequest(constructBatchAddDocRequest(docStartId, batchSize), updateResp);
    waitForCommit(200);

    // Verify that a commit happened. There should now be 2 tlogs, both of which are < maxFileSizeBound.
    TreeMap<String, Long> tlogsInfoPostCommit = getTlogFileSizes(tlogDirPath, maxFileSizeBoundWithBuffer);
    Assert.assertEquals(2, parseTotalNumTlogs(tlogsInfoPostCommit));

    // And the current tlog's size should be less than the previous tlog's size
    Assert.assertTrue(tlogsInfoPostCommit.lastEntry().getValue() < tlogsInfo.lastEntry().getValue());
  }

