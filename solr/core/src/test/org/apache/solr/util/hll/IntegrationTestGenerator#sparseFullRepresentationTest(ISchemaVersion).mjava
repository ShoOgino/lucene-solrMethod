    /**
     * Cumulatively unions "underpopulated" FULL HLLs into the
     * accumulator to verify the correct behavior from the PostgreSQL implementation.
     * The PostgreSQL implementation's representations of probabilistic HLLs should
     * depend exclusively on the chosen SPARSE-to-FULL cutoff.
     *
     * Format: cumulative union
     * Tests:
     * - EMPTY U "underpopulated" FULL => SPARSE
     * - SPARSE U "underpopulated" FULL => SPARSE
     * - SPARSE U "barely underpopulated" FULL => FULL
     */
    private static void sparseFullRepresentationTest(final ISchemaVersion schemaVersion) throws IOException {
        final FileWriter output = openOutput(schemaVersion, "sparse_full_representation", TestType.UNION);

        final HLL emptyHLL1 = newHLL(HLLType.EMPTY);
        final HLL emptyHLL2 = newHLL(HLLType.EMPTY);

        cumulativeUnionLine(output, emptyHLL1, emptyHLL2, schemaVersion);

        // NOTE:  In this test the sparseReference will be the "expected" value
        //        from the C representation, since it doesn't choose representation
        //        based on original encoding, but rather on the promotion rules
        //        and the declared type of the "receiving" field.
        //        It is the manually-constructed union result.

        // "underpopulated" FULL U EMPTY => SPARSE
        final HLL fullHLL = newHLL(HLLType.FULL);
        fullHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));

        final HLL sparseHLL = newHLL(HLLType.SPARSE);
        sparseHLL.addRaw(constructHLLValue(LOG2M, 0/*ix*/, 1/*val*/));

        output.write(stringCardinality(fullHLL) + "," + toByteA(fullHLL, schemaVersion) + "," + stringCardinality(sparseHLL) + "," + toByteA(sparseHLL, schemaVersion) + "\n");
        output.flush();

        // "underpopulated" FULL (small) U SPARSE (small) => SPARSE
        final HLL fullHLL2 = newHLL(HLLType.FULL);
        fullHLL2.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));

        sparseHLL.addRaw(constructHLLValue(LOG2M, 1/*ix*/, 1/*val*/));

        output.write(stringCardinality(fullHLL2) + "," + toByteA(fullHLL2, schemaVersion) + "," + stringCardinality(sparseHLL) + "," + toByteA(sparseHLL, schemaVersion) + "\n");
        output.flush();

        // "underpopulated" FULL (just on edge) U SPARSE (small) => FULL
        final HLL fullHLL3 = newHLL(HLLType.FULL);
        for(int i=2; i<(SPARSE_THRESHOLD + 1); i++) {
            fullHLL3.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));
            sparseHLL.addRaw(constructHLLValue(LOG2M, i/*ix*/, 1/*val*/));
        }

        output.write(stringCardinality(fullHLL3) + "," + toByteA(fullHLL3, schemaVersion) + "," + stringCardinality(sparseHLL) + "," + toByteA(sparseHLL, schemaVersion) + "\n");
        output.flush();
    }

