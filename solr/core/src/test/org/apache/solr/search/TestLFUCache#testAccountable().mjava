  @Test
  public void testAccountable() throws Exception {
    SolrMetricManager metricManager = new SolrMetricManager();
    Random r = random();
    String registry = TestUtil.randomSimpleString(r, 2, 10);
    String scope = TestUtil.randomSimpleString(r, 2, 10);
    LFUCache lfuCache = new LFUCache();
    SolrMetricsContext solrMetricsContext = new SolrMetricsContext(metricManager, registry, "foo");
    lfuCache.initializeMetrics(solrMetricsContext, scope + ".lfuCache");
    try {
      Map params = new HashMap();
      params.put("size", "100");
      params.put("initialSize", "10");
      params.put("autowarmCount", "25");
      NoOpRegenerator regenerator = new NoOpRegenerator();
      Object initObj = lfuCache.init(params, null, regenerator);
      lfuCache.setState(SolrCache.State.LIVE);

      long initialBytes = lfuCache.ramBytesUsed();
      WildcardQuery q = new WildcardQuery(new Term("foo", "bar"));
      DocSet docSet = new BitDocSet();

      // 1 insert
      lfuCache.put(q, docSet);
      long updatedBytes = lfuCache.ramBytesUsed();
      assertTrue(updatedBytes > initialBytes);
      long estimated = initialBytes + q.ramBytesUsed() + docSet.ramBytesUsed() + ConcurrentLFUCache.CacheEntry.BASE_RAM_BYTES_USED
          + RamUsageEstimator.HASHTABLE_RAM_BYTES_PER_ENTRY;
      assertEquals(estimated, updatedBytes);

      TermQuery tq = new TermQuery(new Term("foo", "bar"));
      lfuCache.put(tq, docSet);
      estimated += RamUsageEstimator.sizeOfObject(tq, RamUsageEstimator.QUERY_DEFAULT_RAM_BYTES_USED) +
          docSet.ramBytesUsed() + ConcurrentLFUCache.CacheEntry.BASE_RAM_BYTES_USED +
          RamUsageEstimator.HASHTABLE_RAM_BYTES_PER_ENTRY;
      updatedBytes = lfuCache.ramBytesUsed();
      assertEquals(estimated, updatedBytes);
      lfuCache.clear();
      long clearedBytes = lfuCache.ramBytesUsed();
      assertEquals(initialBytes, clearedBytes);
    } finally {
      lfuCache.close();
    }

  }

