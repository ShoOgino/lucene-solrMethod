  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {
    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();

    int numBuckets = 0;
    List<Object> bucketVals = null;
    if (freq.numBuckets && fcontext.isShard()) {
      bucketVals = new ArrayList(100);
    }

    int off = fcontext.isShard() ? 0 : (int) freq.offset;
    // add a modest amount of over-request if this is a shard request
    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;

    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);
    maxsize = Math.min(maxsize, nTerms);

    final int sortMul = freq.sortDirection.getMultiplier();
    final SlotAcc sortAcc = this.sortAcc;

    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {
      @Override
      protected boolean lessThan(Slot a, Slot b) {
        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;
        return cmp == 0 ? b.slot < a.slot : cmp < 0;
      }
    };

    Slot bottom = null;
    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {
      if (countAcc.getCount(i) < effectiveMincount) {
        continue;
      }

      numBuckets++;
      if (bucketVals != null && bucketVals.size()<100) {
        int ord = startTermIndex + i;
        BytesRef br = lookupOrd(ord);
        Object val = sf.getType().toObject(sf, br);
        bucketVals.add(val);
      }


      if (bottom != null) {
        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {
          bottom.slot = i;
          bottom = queue.updateTop();
        }
      } else {
        // queue not full
        Slot s = new Slot();
        s.slot = i;
        queue.add(s);
        if (queue.size() >= maxsize) {
          bottom = queue.top();
        }
      }
    }

    if (freq.numBuckets) {
      if (!fcontext.isShard()) {
        res.add("numBuckets", numBuckets);
      } else {
        SimpleOrderedMap map = new SimpleOrderedMap(2);
        map.add("numBuckets", numBuckets);
        map.add("vals", bucketVals);
        res.add("numBuckets", map);
      }
    }

    // if we are deep paging, we don't have to order the highest "offset" counts.
    int collectCount = Math.max(0, queue.size() - off);
    assert collectCount <= lim;
    int[] sortedSlots = new int[collectCount];
    for (int i = collectCount - 1; i >= 0; i--) {
      sortedSlots[i] = queue.pop().slot;
    }

    if (freq.allBuckets) {
      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();
      countAcc.setValues(allBuckets, allBucketsSlot);
      for (SlotAcc acc : accs) {
        acc.setValues(allBuckets, allBucketsSlot);
      }
      res.add("allBuckets", allBuckets);
    }

    ArrayList bucketList = new ArrayList(collectCount);
    res.add("buckets", bucketList);


    for (int slotNum : sortedSlots) {
      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();

      // get the ord of the slot...
      int ord = startTermIndex + slotNum;

      BytesRef br = lookupOrd(ord);
      Object val = sf.getType().toObject(sf, br);

      bucket.add("val", val);
      // add stats for this bucket
      addStats(bucket, slotNum);

      // handle sub-facets for this bucket
      if (freq.getSubFacets().size() > 0) {
        TermQuery filter = new TermQuery(new Term(sf.getName(), br.clone()));
        try {
          processSubs(bucket, filter, fcontext.searcher.getDocSet(filter, fcontext.base) );
        } finally {
          // subContext.base.decref();  // OFF-HEAP
          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)
        }
      }

      bucketList.add(bucket);
    }

    if (freq.missing) {
      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();
      DocSet missingDocSet = null;
      try {
        if (startTermIndex == -1) {
          addStats(missingBucket, 0);
        } else {
          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);
          // an extra slot was added to the end for this missing bucket
          countAcc.incrementCount(nTerms, missingDocSet.size());
          collect(missingDocSet, nTerms);
          addStats(missingBucket, nTerms);
        }

        if (freq.getSubFacets().size() > 0) {
          // TODO: we can do better than this!
          if (missingDocSet == null) {
            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);
          }
          processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);
        }

        res.add("missing", missingBucket);
      } finally {
        if (missingDocSet != null) {
          // missingDocSet.decref(); // OFF-HEAP
          missingDocSet = null;
        }
      }
    }

    return res;
  }

