  public SimpleOrderedMap<Object> calcFacets() throws IOException {


    final FacetRangeProcessor.Calc calc = FacetRangeProcessor.getNumericCalc(sf);


    // TODO: it would be really nice to know the number of unique values!!!!

    int possibleValues = fcontext.base.size();
    // size smaller tables so that no resize will be necessary
    int currHashSize = BitUtil.nextHighestPowerOfTwo((int) (possibleValues * (1 / LongCounts.LOAD_FACTOR) + 1));
    currHashSize = Math.min(currHashSize, MAXIMUM_STARTING_TABLE_SIZE);
    final LongCounts table = new LongCounts(currHashSize) {
      @Override
      protected void rehash() {
        super.rehash();
        doRehash(this);
        oldToNewMapping = null; // allow for gc
      }
    };

    int numSlots = currHashSize;

    int numMissing = 0;

    if (freq.missing) {
      missingSlot = numSlots++;
    }
    if (freq.allBuckets) {
      allBucketsSlot = numSlots++;
    }

    indexOrderAcc = new SlotAcc(fcontext) {
      @Override
      public void collect(int doc, int slot) throws IOException {
      }

      @Override
      public int compare(int slotA, int slotB) {
        long s1 = calc.bitsToSortableBits(table.vals[slotA]);
        long s2 = calc.bitsToSortableBits(table.vals[slotB]);
        return Long.compare(s1, s2);
      }

      @Override
      public Object getValue(int slotNum) throws IOException {
        return null;
      }

      @Override
      public void reset() {
      }

      @Override
      public void resize(Resizer resizer) {
      }
    };

    countAcc = new CountSlotAcc(fcontext) {
      @Override
      public void incrementCount(int slot, int count) {
        throw new UnsupportedOperationException();
      }

      @Override
      public int getCount(int slot) {
        return table.counts[slot];
      }

      @Override
      public Object getValue(int slotNum) {
        return getCount(slotNum);
      }

      @Override
      public void reset() {
        throw new UnsupportedOperationException();
      }

      @Override
      public void collect(int doc, int slot) throws IOException {
        throw new UnsupportedOperationException();
      }

      @Override
      public int compare(int slotA, int slotB) {
        return Integer.compare( table.counts[slotA], table.counts[slotB] );
      }

      @Override
      public void resize(Resizer resizer) {
        throw new UnsupportedOperationException();
      }
    };


    // we set the countAcc first so it won't be created here
    createAccs(fcontext.base.size(), numSlots);
    setSortAcc(numSlots);
    prepareForCollection();


    NumericDocValues values = null;
    Bits docsWithField = null;

    // TODO: factor this code out so it can be shared...
    final List<LeafReaderContext> leaves = fcontext.searcher.getIndexReader().leaves();
    final Iterator<LeafReaderContext> ctxIt = leaves.iterator();
    LeafReaderContext ctx = null;
    int segBase = 0;
    int segMax;
    int adjustedMax = 0;
    for (DocIterator docsIt = fcontext.base.iterator(); docsIt.hasNext(); ) {
      final int doc = docsIt.nextDoc();
      if (doc >= adjustedMax) {
        do {
          ctx = ctxIt.next();
          segBase = ctx.docBase;
          segMax = ctx.reader().maxDoc();
          adjustedMax = segBase + segMax;
        } while (doc >= adjustedMax);
        assert doc >= ctx.docBase;
        setNextReader(ctx);

        values = DocValues.getNumeric(ctx.reader(), sf.getName());
        docsWithField = DocValues.getDocsWithField(ctx.reader(), sf.getName());
      }

      int segDoc = doc - segBase;
      long val = values.get(segDoc);
      if (val == 0 && !docsWithField.get(segDoc)) {
        // missing
        if (missingSlot >= 0) {
          numMissing++;
          collect(segDoc, missingSlot);
        }
      } else {
        int slot = table.add(val);  // this can trigger a rehash rehash

        collect(segDoc, slot);

        if (allBucketsSlot >= 0) {
          collect(segDoc, allBucketsSlot);
        }
      }
    }


    //
    // collection done, time to find the top slots
    //

    int numBuckets = 0;
    List<Object> bucketVals = null;
    if (freq.numBuckets && fcontext.isShard()) {
      bucketVals = new ArrayList(100);
    }

    int off = fcontext.isShard() ? 0 : (int) freq.offset;
    // add a modest amount of over-request if this is a shard request
    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;

    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);
    maxsize = Math.min(maxsize, table.cardinality);

    final int sortMul = freq.sortDirection.getMultiplier();

    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {
      @Override
      protected boolean lessThan(Slot a, Slot b) {
        // TODO: sort-by-index-order
        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;
        return cmp == 0 ? (indexOrderAcc.compare(a.slot, b.slot) > 0) : cmp < 0;
      }
    };

    // TODO: create a countAcc that wrapps the table so we can reuse more code?

    Slot bottom = null;
    for (int i=0; i<table.counts.length; i++) {
      int count = table.counts[i];
      if (count < effectiveMincount) {
        // either not a valid slot, or count not high enough
        continue;
      }
      numBuckets++;  // can be different from the table cardinality if mincount > 1

      long val = table.vals[i];
      if (bucketVals != null && bucketVals.size()<100) {
        bucketVals.add( calc.bitsToValue(val) );
      }

      if (bottom == null) {
        bottom = new Slot();
      }
      bottom.slot = i;

      bottom = queue.insertWithOverflow(bottom);
    }


    SimpleOrderedMap res = new SimpleOrderedMap();
    if (freq.numBuckets) {
      if (!fcontext.isShard()) {
        res.add("numBuckets", numBuckets);
      } else {
        SimpleOrderedMap map = new SimpleOrderedMap(2);
        map.add("numBuckets", numBuckets);
        map.add("vals", bucketVals);
        res.add("numBuckets", map);
      }
    }

    if (freq.allBuckets) {
      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();
      // countAcc.setValues(allBuckets, allBucketsSlot);
      allBuckets.add("count", table.numAdds);
      for (SlotAcc acc : accs) {
        acc.setValues(allBuckets, allBucketsSlot);
      }
      // allBuckets currently doesn't execute sub-facets (because it doesn't change the domain?)
      res.add("allBuckets", allBuckets);
    }

    if (freq.missing) {
      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();
      // countAcc.setValues(missingBucket, missingSlot);
      missingBucket.add("count", numMissing);
      for (SlotAcc acc : accs) {
        acc.setValues(missingBucket, missingSlot);
      }

      if (freq.getSubFacets().size() > 0) {
        // TODO: we can do better than this!
        DocSet missingDocSet = null;
        if (missingDocSet == null) {
          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);
        }
        processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);
      }
      res.add("missing", missingBucket);
    }

    // if we are deep paging, we don't have to order the highest "offset" counts.
    int collectCount = Math.max(0, queue.size() - off);
    assert collectCount <= lim;
    int[] sortedSlots = new int[collectCount];
    for (int i = collectCount - 1; i >= 0; i--) {
      sortedSlots[i] = queue.pop().slot;
    }

    ArrayList bucketList = new ArrayList(collectCount);
    res.add("buckets", bucketList);


    for (int slotNum : sortedSlots) {
      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();
      Comparable val = calc.bitsToValue(table.vals[slotNum]);
      bucket.add("val", val);

      // add stats for this bucket
      // TODO: this gets count from countAcc
      // addStats(bucket, slotNum);
      bucket.add("count", table.counts[slotNum]);

      for (SlotAcc acc : accs) {
        acc.setValues(bucket, slotNum);
      }

      // handle sub-facets for this bucket
      if (freq.getSubFacets().size() > 0) {
        Query filter = sf.getType().getFieldQuery(null, sf, calc.formatValue(val));
        processSubs(bucket, filter, fcontext.searcher.getDocSet(filter, fcontext.base) );
      }

      bucketList.add(bucket);
    }



    return res;
  }

