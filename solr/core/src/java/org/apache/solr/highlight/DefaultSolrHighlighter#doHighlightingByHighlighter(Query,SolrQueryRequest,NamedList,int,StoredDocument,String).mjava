  @SuppressWarnings("unchecked")
  protected void doHighlightingByHighlighter( Query query, SolrQueryRequest req, NamedList docSummaries,
                                              int docId, StoredDocument doc, String fieldName ) throws IOException {
    final SolrIndexSearcher searcher = req.getSearcher();
    final IndexSchema schema = searcher.getSchema();
    final SolrParams params = req.getParams();

    // TODO: highlighting numeric fields is broken (Lucene) - so we disable them until fixed (see LUCENE-3080)!
    // BEGIN: Hack
    final SchemaField schemaField = schema.getFieldOrNull(fieldName);
    if (schemaField != null && schemaField.getType() instanceof org.apache.solr.schema.TrieField) return;
    // END: Hack

    final int mvToExamine =
        req.getParams().getFieldInt(fieldName, HighlightParams.MAX_MULTIVALUED_TO_EXAMINE,
            (schemaField != null && schemaField.multiValued()) ? Integer.MAX_VALUE : 1);
    // Technically this is the max *fragments* (snippets), not max values:
    int mvToMatch =
        req.getParams().getFieldInt(fieldName, HighlightParams.MAX_MULTIVALUED_TO_MATCH, Integer.MAX_VALUE);
    if (mvToExamine <= 0 || mvToMatch <= 0) {
      return;
    }

    int maxCharsToAnalyze = params.getFieldInt(fieldName,
        HighlightParams.MAX_CHARS,
        Highlighter.DEFAULT_MAX_CHARS_TO_ANALYZE);
    if (maxCharsToAnalyze < 0) {//e.g. -1
      maxCharsToAnalyze = Integer.MAX_VALUE;
    }

    List<String> fieldValues = getFieldValues(req, doc, fieldName, mvToExamine, maxCharsToAnalyze);
    if (fieldValues.isEmpty()) {
      return;
    }

    // preserve order of values in a multiValued list
    boolean preserveMulti = params.getFieldBool(fieldName, HighlightParams.PRESERVE_MULTI, false);

    int numFragments = getMaxSnippets(fieldName, params);
    boolean mergeContiguousFragments = isMergeContiguousFragments(fieldName, params);

    List<TextFragment> frags = new ArrayList<>();

    //Try term vectors, which is faster
    final TokenStream tvStream =
        TokenSources.getTokenStreamWithOffsets(searcher.getIndexReader(), docId, fieldName);
    //  We need to wrap in OffsetWindowTokenFilter if multi-valued
    final OffsetWindowTokenFilter tvWindowStream;
    if (tvStream != null && fieldValues.size() > 1) {
      tvWindowStream = new OffsetWindowTokenFilter(tvStream);
    } else {
      tvWindowStream = null;
    }

    for (String thisText : fieldValues) {
      if (mvToMatch <= 0 || maxCharsToAnalyze <= 0) {
        break;
      }

      TokenStream tstream;
      if (tvWindowStream != null) {
        // if we have a multi-valued field with term vectors, then get the next offset window
        tstream = tvWindowStream.advanceToNextWindowOfLength(thisText.length());
      } else if (tvStream != null) {
        tstream = tvStream; // single-valued with term vectors
      } else {
        // fall back to analyzer
        tstream = createAnalyzerTStream(schema, fieldName, thisText);
      }

      Highlighter highlighter;
      if (req.getParams().getFieldBool(fieldName, HighlightParams.USE_PHRASE_HIGHLIGHTER, true)) {
        // We're going to call getPhraseHighlighter and it might consume the tokenStream. If it does, the tokenStream
        // needs to implement reset() efficiently.

        //If the tokenStream is right from the term vectors, then CachingTokenFilter is unnecessary.
        //  It should be okay if OffsetLimit won't get applied in this case.
        final TokenStream tempTokenStream;
        if (tstream != tvStream) {
          if (maxCharsToAnalyze >= thisText.length()) {
            tempTokenStream = new CachingTokenFilter(tstream);
          } else {
            tempTokenStream = new CachingTokenFilter(new OffsetLimitTokenFilter(tstream, maxCharsToAnalyze));
          }
        } else {
          tempTokenStream = tstream;
        }

        // get highlighter
        highlighter = getPhraseHighlighter(query, fieldName, req, tempTokenStream);

        // if the CachingTokenFilter was consumed then use it going forward.
        if (tempTokenStream instanceof CachingTokenFilter && ((CachingTokenFilter)tempTokenStream).isCached()) {
          tstream = tempTokenStream;
        }
        //tstream.reset(); not needed; getBestTextFragments will reset it.
      } else {
        // use "the old way"
        highlighter = getHighlighter(query, fieldName, req);
      }

      highlighter.setMaxDocCharsToAnalyze(maxCharsToAnalyze);
      maxCharsToAnalyze -= thisText.length();

      // Highlight!
      try {
        TextFragment[] bestTextFragments =
            highlighter.getBestTextFragments(tstream, thisText, mergeContiguousFragments, numFragments);
        for (TextFragment bestTextFragment : bestTextFragments) {
          if (bestTextFragment == null)//can happen via mergeContiguousFragments
            continue;
          // normally we want a score (must be highlighted), but if preserveMulti then we return a snippet regardless.
          if (bestTextFragment.getScore() > 0 || preserveMulti) {
            frags.add(bestTextFragment);
            if (bestTextFragment.getScore() > 0)
              --mvToMatch; // note: limits fragments (for multi-valued fields), not quite the number of values
          }
        }
      } catch (InvalidTokenOffsetsException e) {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);
      }
    }//end field value loop

    // Put the fragments onto the Solr response (docSummaries)
    if (frags.size() > 0) {
      // sort such that the fragments with the highest score come first
      if (!preserveMulti) {
        Collections.sort(frags, new Comparator<TextFragment>() {//TODO make TextFragment Comparable
          @Override
          public int compare(TextFragment arg0, TextFragment arg1) {
            return Float.compare(arg1.getScore(), arg0.getScore());
          }
        });
      }

      // Truncate list to hl.snippets, but not when hl.preserveMulti
      if (frags.size() > numFragments && !preserveMulti) {
        frags = frags.subList(0, numFragments);
      }
      docSummaries.add(fieldName, getResponseForFragments(frags, req));
    } else {
      // no summaries made, copy text from alternate field
      alternateField(docSummaries, params, doc, fieldName);
    }
  }

