  /**
   * Simulate an update by modifying replica metrics.
   * The following core metrics are updated:
   * <ul>
   *   <li><code>SEARCHER.searcher.numDocs</code> - increased by added docs, decreased by deleteById and deleteByQuery</li>
   *   <li><code>SEARCHER.searcher.deletedDocs</code> - decreased by deleteById and deleteByQuery by up to <code>numDocs</code></li>
   *   <li><code>SEARCHER.searcher.maxDoc</code> - always increased by the number of added docs.</li>
   * </ul>
   * <p>IMPORTANT limitations:</p>
   * <ul>
   *   <li>document replacements are always counted as new docs</li>
   *   <li>delete by ID always succeeds (unless numDocs == 0)</li>
   *   <li>deleteByQuery is not supported unless the query is <code>*:*</code></li>
   * </ul>
   * @param req update request. This request MUST have the <code>collection</code> param set.
   * @return {@link UpdateResponse}
   * @throws SolrException on errors, such as nonexistent collection or unsupported deleteByQuery
   */
  public UpdateResponse simUpdate(UpdateRequest req) throws SolrException, InterruptedException, IOException {
    ensureNotClosed();
    String collection = req.getCollection();
    if (collection == null) {
      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Collection not set");
    }
    ensureSystemCollection(collection);
    DocCollection coll = getClusterState().getCollection(collection);
    DocRouter router = coll.getRouter();
    List<String> deletes = req.getDeleteById();
    Map<String, AtomicLong> freediskDeltaPerNode = new HashMap<>();
    if (deletes != null && !deletes.isEmpty()) {
      Map<String, AtomicLong> deletesPerShard = new HashMap<>();
      Map<String, Number> indexSizePerShard = new HashMap<>();
      for (String id : deletes) {
        Slice s = router.getTargetSlice(id, null, null, req.getParams(), coll);
        Replica leader = s.getLeader();
        if (leader == null) {
          throw new IOException("-- no leader in " + s);
        }
        cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter("UPDATE./update.requests").inc();
        ReplicaInfo ri = getReplicaInfo(leader);
        Number numDocs = (Number)ri.getVariable("SEARCHER.searcher.numDocs");
        if (numDocs == null || numDocs.intValue() <= 0) {
          if (log.isDebugEnabled()) {
            log.debug("-- attempting to delete nonexistent doc {} from {}", id, s.getLeader());
          }
          continue;
        }

        // this is somewhat wrong - we should wait until buffered updates are applied
        // but this way the freedisk changes are much easier to track
        s.getReplicas().forEach(r ->
            freediskDeltaPerNode.computeIfAbsent(r.getNodeName(), node -> new AtomicLong(0))
                .addAndGet(DEFAULT_DOC_SIZE_BYTES));

        AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);
        if (bufferedUpdates != null) {
          if (bufferedUpdates.get() > 0) {
            bufferedUpdates.decrementAndGet();
          } else {
            if (log.isDebugEnabled()) {
              log.debug("-- attempting to delete nonexistent buffered doc {} from {}", id, s.getLeader());
            }
          }
          continue;
        }
        deletesPerShard.computeIfAbsent(s.getName(), slice -> new AtomicLong(0)).incrementAndGet();
        Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);
        if (indexSize != null) {
          indexSizePerShard.put(s.getName(), indexSize);
        }
      }
      if (!deletesPerShard.isEmpty()) {
        lock.lockInterruptibly();
        try {
          for (Map.Entry<String, AtomicLong> entry : deletesPerShard.entrySet()) {
            String shard = entry.getKey();
            simSetShardValue(collection, shard, "SEARCHER.searcher.deletedDocs", entry.getValue().get(), true, false);
            simSetShardValue(collection, shard, "SEARCHER.searcher.numDocs", -entry.getValue().get(), true, false);
            Number indexSize = indexSizePerShard.get(shard);
            long delSize = DEFAULT_DOC_SIZE_BYTES * entry.getValue().get();
            if (indexSize != null) {
              indexSize = indexSize.longValue() - delSize;
              if (indexSize.longValue() < SimCloudManager.DEFAULT_IDX_SIZE_BYTES) {
                indexSize = SimCloudManager.DEFAULT_IDX_SIZE_BYTES;
              }
              simSetShardValue(collection, shard, Type.CORE_IDX.metricsAttribute,
                  new AtomicLong(indexSize.longValue()), false, false);
              simSetShardValue(collection, shard, Variable.coreidxsize,
                  new AtomicDouble((Double)Type.CORE_IDX.convertVal(indexSize)), false, false);
            } else {
              throw new Exception("unexpected indexSize for collection=" + collection + ", shard=" + shard + ": " + indexSize);
            }
          }
        } catch (Exception e) {
          throw new IOException(e);
        } finally {
          lock.unlock();
        }
      }
    }
    deletes = req.getDeleteQuery();
    if (deletes != null && !deletes.isEmpty()) {
      for (String q : deletes) {
        if (!"*:*".equals(q)) {
          throw new UnsupportedOperationException("Only '*:*' query is supported in deleteByQuery");
        }
        //log.debug("-- req delByQ {}", collection);
        for (Slice s : coll.getSlices()) {
          Replica leader = s.getLeader();
          if (leader == null) {
            throw new IOException("-- no leader in " + s);
          }

          cloudManager.getMetricManager().registry(createRegistryName(collection, s.getName(), leader)).counter("UPDATE./update.requests").inc();
          ReplicaInfo ri = getReplicaInfo(leader);
          Number numDocs = (Number)ri.getVariable("SEARCHER.searcher.numDocs");
          if (numDocs == null || numDocs.intValue() == 0) {
            continue;
          }
          lock.lockInterruptibly();
          try {
            Number indexSize = (Number)ri.getVariable(Type.CORE_IDX.metricsAttribute);
            if (indexSize != null) {
              long delta = indexSize.longValue() < SimCloudManager.DEFAULT_IDX_SIZE_BYTES ? 0 :
                  indexSize.longValue() - SimCloudManager.DEFAULT_IDX_SIZE_BYTES;
              s.getReplicas().forEach(r ->
                  freediskDeltaPerNode.computeIfAbsent(r.getNodeName(), node -> new AtomicLong(0))
                  .addAndGet(delta));
            } else {
              throw new RuntimeException("Missing index size in " + ri);
            }
            simSetShardValue(collection, s.getName(), "SEARCHER.searcher.deletedDocs", new AtomicLong(numDocs.longValue()), false, false);
            simSetShardValue(collection, s.getName(), "SEARCHER.searcher.numDocs", new AtomicLong(0), false, false);
            simSetShardValue(collection, s.getName(), Type.CORE_IDX.metricsAttribute,
                new AtomicLong(SimCloudManager.DEFAULT_IDX_SIZE_BYTES), false, false);
            simSetShardValue(collection, s.getName(), Variable.coreidxsize,
                new AtomicDouble((Double)Type.CORE_IDX.convertVal(SimCloudManager.DEFAULT_IDX_SIZE_BYTES)), false, false);
          } catch (Exception e) {
            throw new IOException(e);
          } finally {
            lock.unlock();
          }
        }
      }
    }
    List<SolrInputDocument> docs = req.getDocuments();
    int docCount = 0;
    Iterator<SolrInputDocument> it = null;
    if (docs != null) {
      docCount = docs.size();
    } else {
      it = req.getDocIterator();
      if (it != null) {
        while (it.hasNext()) {
          it.next();
          docCount++;
        }
      }
    }
    if (docCount > 0) {
      //log.debug("-- req update {}/{}", collection, docCount);
      // this approach to updating counters and metrics drastically increases performance
      // of bulk updates, because simSetShardValue is relatively costly

      Map<String, AtomicLong> docUpdates = new HashMap<>();
      Map<String, Map<String, AtomicLong>> metricUpdates = new HashMap<>();

      // XXX don't add more than 2bln docs in one request
      boolean modified = false;
      lock.lockInterruptibly();
      try {
        coll = getClusterState().getCollection(collection);
        Slice[] slices = coll.getActiveSlicesArr();
        if (slices.length == 0) {
          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Collection without slices");
        }
        int[] perSlice = new int[slices.length];

        if (it != null) {
          // BULK UPDATE: simulate random doc assignment without actually calling DocRouter,
          // which adds significant overhead

          int totalAdded = 0;
          for (int i = 0; i < slices.length; i++) {
            Slice s = slices[i];
            long count = (long) docCount * ((long) s.getRange().max - (long) s.getRange().min) / 0x100000000L;
            perSlice[i] = (int) count;
            totalAdded += perSlice[i];
          }
          // loss of precision due to integer math
          int diff = docCount - totalAdded;
          if (diff > 0) {
            // spread the remainder more or less equally
            int perRemain = diff / slices.length;
            int remainder = diff % slices.length;
            int remainderSlice = slices.length > 1 ? bulkUpdateRandom.nextInt(slices.length) : 0;
            for (int i = 0; i < slices.length; i++) {
              perSlice[i] += perRemain;
              if (i == remainderSlice) {
                perSlice[i] += remainder;
              }
            }
          }
          for (int i = 0; i < slices.length; i++) {
            Slice s = slices[i];
            Replica leader = s.getLeader();
            if (leader == null) {
              throw new IOException("-- no leader in " + s);
            }
            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())
                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())
                .addAndGet(perSlice[i]);
            modified = true;
            long perSliceCount = perSlice[i];
            s.getReplicas().forEach(r ->
                freediskDeltaPerNode.computeIfAbsent(r.getNodeName(), node -> new AtomicLong(0))
                    .addAndGet(-perSliceCount * DEFAULT_DOC_SIZE_BYTES));
            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);
            if (bufferedUpdates != null) {
              bufferedUpdates.addAndGet(perSlice[i]);
              continue;
            }
            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())
                .addAndGet(perSlice[i]);
          }
        } else {
          // SMALL UPDATE: use exact assignment via DocRouter
          for (SolrInputDocument doc : docs) {
            String id = (String) doc.getFieldValue("id");
            if (id == null) {
              throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, "Document without id: " + doc);
            }
            Slice s = coll.getRouter().getTargetSlice(id, doc, null, null, coll);
            Replica leader = s.getLeader();
            if (leader == null) {
              throw new IOException("-- no leader in " + s);
            }
            metricUpdates.computeIfAbsent(s.getName(), sh -> new HashMap<>())
                .computeIfAbsent(leader.getCoreName(), cn -> new AtomicLong())
                .incrementAndGet();
            modified = true;
            s.getReplicas().forEach(r ->
                freediskDeltaPerNode.computeIfAbsent(r.getNodeName(), node -> new AtomicLong())
                    .addAndGet(-DEFAULT_DOC_SIZE_BYTES));
            AtomicLong bufferedUpdates = (AtomicLong)sliceProperties.get(collection).get(s.getName()).get(BUFFERED_UPDATES);
            if (bufferedUpdates != null) {
              bufferedUpdates.incrementAndGet();
              continue;
            }
            docUpdates.computeIfAbsent(s.getName(), sh -> new AtomicLong())
                .incrementAndGet();
          }
        }

        if (modified) {
          docUpdates.forEach((sh, count) -> {
            try {
              simSetShardValue(collection, sh, "SEARCHER.searcher.numDocs", count.get(), true, false);
              simSetShardValue(collection, sh, "SEARCHER.searcher.maxDoc", count.get(), true, false);
              simSetShardValue(collection, sh, "UPDATE./update.requests", count.get(), true, false);
              // for each new document increase the size by DEFAULT_DOC_SIZE_BYTES
              simSetShardValue(collection, sh, Type.CORE_IDX.metricsAttribute,
                  DEFAULT_DOC_SIZE_BYTES * count.get(), true, false);
              simSetShardValue(collection, sh, Variable.coreidxsize,
                  Type.CORE_IDX.convertVal(DEFAULT_DOC_SIZE_BYTES * count.get()), true, false);
            } catch (Exception e) {
              throw new RuntimeException(e);
            }
          });
          metricUpdates.forEach((sh, cores) -> {
            cores.forEach((core, count) -> {
              String registry = SolrMetricManager.getRegistryName(SolrInfoBean.Group.core, collection, sh,
                  Utils.parseMetricsReplicaName(collection, core));
              cloudManager.getMetricManager().registry(registry).counter("UPDATE./update.requests").inc(count.get());
            });
          });
        }
      } finally {
        lock.unlock();
      }
    }
    if (!freediskDeltaPerNode.isEmpty()) {
      SimNodeStateProvider nodeStateProvider = cloudManager.getSimNodeStateProvider();
      freediskDeltaPerNode.forEach((node, delta) -> {
        if (delta.get() == 0) {
          return;
        }
        try {
          // this method does its own locking to prevent races
          nodeStateProvider.simUpdateNodeValue(node, Type.FREEDISK.tagName, val -> {
            if (val == null) {
              throw new RuntimeException("no freedisk for node " + node);
            }
            double freedisk = ((Number) val).doubleValue();
            double deltaGB = (Double) Type.FREEDISK.convertVal(delta.get());
            freedisk += deltaGB;
            if (freedisk < 0) {
              log.warn("-- freedisk={} - ran out of disk space on node {}", freedisk, node);
              freedisk = 0;
            }
            return freedisk;
          });
        } catch (Exception e) {
          throw new RuntimeException(e);
        }
      });
    }
    SolrParams params = req.getParams();
    if (params != null && (params.getBool(UpdateParams.OPTIMIZE, false) || params.getBool(UpdateParams.EXPUNGE_DELETES, false))) {
      lock.lockInterruptibly();
      try {
        coll.getSlices().forEach(s -> {
          Replica leader = s.getLeader();
          ReplicaInfo ri = getReplicaInfo(leader);
          Number numDocs = (Number)ri.getVariable("SEARCHER.searcher.numDocs");
          if (numDocs == null || numDocs.intValue() == 0) {
            numDocs = 0;
          }
          try {
            simSetShardValue(ri.getCollection(), ri.getShard(), "SEARCHER.searcher.maxDoc", numDocs, false, false);
            simSetShardValue(ri.getCollection(), ri.getShard(), "SEARCHER.searcher.deletedDocs", 0, false, false);
          } catch (Exception e) {
            throw new RuntimeException(e);
          }
        });
      } finally {
        lock.unlock();
      }
    }
    return new UpdateResponse();
  }

