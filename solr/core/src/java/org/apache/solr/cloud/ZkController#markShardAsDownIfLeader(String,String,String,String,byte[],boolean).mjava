  /**
   * we use ZK's multi-transactional semantics to ensure that we are able to
   * publish a replica as 'down' only if our leader election node still exists
   * in ZK. This ensures that a long running network partition caused by GC etc
   * doesn't let us mark a node as down *after* we've already lost our session
   */
  private void markShardAsDownIfLeader(String collection, String shardId, String leaderCoreNodeName,
                                       String znodePath, byte[] znodeData,
                                       boolean retryOnConnLoss) throws KeeperException, InterruptedException {
    String leaderSeqPath = getLeaderSeqPath(collection, leaderCoreNodeName);
    if (leaderSeqPath == null) {
      throw new NotLeaderException(ErrorCode.SERVER_ERROR,
          "Failed to update data to 'down' for znode: " + znodePath +
              " because the zookeeper leader sequence for leader: " + leaderCoreNodeName + " is null");
    }
    if (zkClient.exists(znodePath, retryOnConnLoss)) {
      List<Op> ops = new ArrayList<>(2);
      ops.add(Op.check(leaderSeqPath, -1)); // version doesn't matter, the seq path is unique
      ops.add(Op.setData(znodePath, znodeData, -1));
      zkClient.multi(ops, retryOnConnLoss);
    } else {
      String parentZNodePath = getLeaderInitiatedRecoveryZnodePath(collection, shardId);
      try {
        zkClient.makePath(parentZNodePath, retryOnConnLoss);
      } catch (KeeperException.NodeExistsException nee) {
        // if it exists, that's great!
      }
      List<Op> ops = new ArrayList<>(2);
      ops.add(Op.check(leaderSeqPath, -1)); // version doesn't matter, the seq path is unique
      ops.add(Op.create(znodePath, znodeData, zkClient.getZkACLProvider().getACLsToAdd(znodePath),
          CreateMode.PERSISTENT));
      zkClient.multi(ops, retryOnConnLoss);
    }
  }

