  /**
   * 
   * @return the best node to replace the badReplica on or null if there is no
   *         such node
   */
  static String getBestCreateUrl(ZkStateReader zkStateReader, DownReplica badReplica, Integer maxCoreCount) {
    assert badReplica != null;
    assert badReplica.collection != null;
    assert badReplica.slice != null;
    log.debug("getBestCreateUrl for " + badReplica.replica);
    Map<String,Counts> counts = new HashMap<>();
    Set<String> unsuitableHosts = new HashSet<>();
    
    Set<String> liveNodes = new HashSet<>(zkStateReader.getClusterState().getLiveNodes());
    Map<String, Integer> coresPerNode = new HashMap<>();
    
    ClusterState clusterState = zkStateReader.getClusterState();
    if (clusterState != null) {
      Map<String, DocCollection> collections = clusterState.getCollectionsMap();
      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {
        String collection = entry.getKey();
        log.debug("look at collection {} as possible create candidate", collection);
        DocCollection docCollection = entry.getValue();
        // TODO - only operate on collections with sharedfs failover = true ??
        Collection<Slice> slices = docCollection.getSlices();
        for (Slice slice : slices) {
          // only look at active shards
          if (slice.getState() == Slice.State.ACTIVE) {
            log.debug("look at slice {} for collection {} as possible create candidate", slice.getName(), collection); 
            Collection<Replica> replicas = slice.getReplicas();

            for (Replica replica : replicas) {
              liveNodes.remove(replica.getNodeName());
              String baseUrl = replica.getStr(ZkStateReader.BASE_URL_PROP);
              if (coresPerNode.containsKey(baseUrl)) {
                Integer nodeCount = coresPerNode.get(baseUrl);
                coresPerNode.put(baseUrl, nodeCount++);
              } else {
                coresPerNode.put(baseUrl, 1);
              }
              if (baseUrl.equals(badReplica.replica.getStr(ZkStateReader.BASE_URL_PROP))) {
                continue;
              }
              // on a live node?
              log.debug("collection={} nodename={} livenodes={}", collection, replica.getNodeName(), clusterState.getLiveNodes());
              boolean live = clusterState.liveNodesContain(replica.getNodeName());
              log.debug("collection={} look at replica {} as possible create candidate, live={}", collection, replica.getName(), live); 
              if (live) {
                Counts cnt = counts.get(baseUrl);
                if (cnt == null) {
                  cnt = new Counts();
                }
                if (badReplica.collection.getName().equals(collection)) {
                  cnt.negRankingWeight += 3;
                  cnt.collectionShardsOnNode += 1;
                } else {
                  cnt.negRankingWeight += 1;
                }
                if (badReplica.collection.getName().equals(collection) && badReplica.slice.getName().equals(slice.getName())) {
                  cnt.ourReplicas++;
                }

                Integer maxShardsPerNode = badReplica.collection.getMaxShardsPerNode();
                if (maxShardsPerNode == null) {
                  log.warn("maxShardsPerNode is not defined for collection, name=" + badReplica.collection.getName());
                  maxShardsPerNode = Integer.MAX_VALUE;
                }
                log.debug("collection={} node={} maxShardsPerNode={} maxCoresPerNode={} potential hosts={}",
                    collection, baseUrl, maxShardsPerNode, maxCoreCount, cnt);

                Collection<Replica> badSliceReplicas = null;
                DocCollection c = clusterState.getCollection(badReplica.collection.getName());
                if (c != null) {
                  Slice s = c.getSlice(badReplica.slice.getName());
                  if (s != null) {
                    badSliceReplicas = s.getReplicas();
                  }
                }
                boolean alreadyExistsOnNode = replicaAlreadyExistsOnNode(zkStateReader.getClusterState(), badSliceReplicas, badReplica, baseUrl);
                if (unsuitableHosts.contains(baseUrl) || alreadyExistsOnNode || cnt.collectionShardsOnNode >= maxShardsPerNode
                    || (maxCoreCount != null && coresPerNode.get(baseUrl) >= maxCoreCount) ) {
                  counts.remove(baseUrl);
                  unsuitableHosts.add(baseUrl);
                  log.debug("not a candidate node, collection={} node={} max shards per node={} good replicas={}", collection, baseUrl, maxShardsPerNode, cnt);
                } else {
                  counts.put(baseUrl, cnt);
                  log.debug("is a candidate node, collection={} node={} max shards per node={} good replicas={}", collection, baseUrl, maxShardsPerNode, cnt);
                }
              }
            }
          }
        }
      }
    }
    
    for (String node : liveNodes) {
      counts.put(zkStateReader.getBaseUrlForNodeName(node), new Counts(0, 0));
    }
    
    if (counts.size() == 0) {
      log.debug("no suitable hosts found for getBestCreateUrl for collection={}", badReplica.collection.getName());
      return null;
    }
    
    ValueComparator vc = new ValueComparator(counts);
    Map<String,Counts> sortedCounts = new TreeMap<String, Counts>(vc);
    sortedCounts.putAll(counts);
    
    log.debug("empty nodes={} for collection={}", liveNodes, badReplica.collection.getName());
    log.debug("sorted hosts={} for collection={}", sortedCounts, badReplica.collection.getName());
    log.debug("unsuitable hosts={} for collection={}", unsuitableHosts, badReplica.collection.getName());
    
    return sortedCounts.keySet().iterator().next();
  }

