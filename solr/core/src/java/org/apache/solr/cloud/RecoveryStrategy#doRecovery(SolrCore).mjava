  // TODO: perhaps make this grab a new core each time through the loop to handle core reloads?
  public void doRecovery(SolrCore core) throws KeeperException, InterruptedException {
    boolean replayed = false;
    boolean successfulRecovery = false;

    UpdateLog ulog;
    ulog = core.getUpdateHandler().getUpdateLog();
    if (ulog == null) {
      SolrException.log(log, "No UpdateLog found - cannot recover");
      recoveryFailed(core, zkController, baseUrl, coreZkNodeName,
          core.getCoreDescriptor());
      return;
    }


    List<Long> recentVersions;
    UpdateLog.RecentUpdates recentUpdates = ulog.getRecentUpdates();
    try {
      recentVersions = recentUpdates.getVersions(ulog.numRecordsToKeep);
    } catch (Throwable t) {
      SolrException.log(log, "Corrupt tlog - ignoring", t);
      recentVersions = new ArrayList<Long>(0);
    }finally {
      recentUpdates.close();
    }

    List<Long> startingVersions = ulog.getStartingVersions();


    if (startingVersions != null && recoveringAfterStartup) {
      int oldIdx = 0;  // index of the start of the old list in the current list
      long firstStartingVersion = startingVersions.size() > 0 ? startingVersions.get(0) : 0;

      for (; oldIdx<recentVersions.size(); oldIdx++) {
        if (recentVersions.get(oldIdx) == firstStartingVersion) break;
      }

      if (oldIdx > 0) {
        log.info("####### Found new versions added after startup: num=" + oldIdx);
        log.info("###### currentVersions=" + recentVersions);
      }

      log.info("###### startupVersions=" + startingVersions);
    }


    boolean firstTime = true;

    if (recoveringAfterStartup) {
      // if we're recovering after startup (i.e. we have been down), then we need to know what the last versions were
      // when we went down.  We may have received updates since then.
      recentVersions = startingVersions;

      if ((ulog.getStartingOperation() & UpdateLog.FLAG_GAP) != 0) {
        // last operation at the time of startup had the GAP flag set...
        // this means we were previously doing a full index replication
        // that probably didn't complete and buffering updates in the meantime.
        firstTime = false;    // skip peersync
      }
    }

    while (!successfulRecovery && !isClosed() && !isInterrupted()) { // don't use interruption or it will close channels though
      try {
        // first thing we just try to sync
        zkController.publish(core.getCoreDescriptor(), ZkStateReader.RECOVERING);

        CloudDescriptor cloudDesc = core.getCoreDescriptor()
            .getCloudDescriptor();
        ZkNodeProps leaderprops = zkStateReader.getLeaderProps(
            cloudDesc.getCollectionName(), cloudDesc.getShardId());

        String leaderBaseUrl = leaderprops.get(ZkStateReader.BASE_URL_PROP);
        String leaderCoreName = leaderprops.get(ZkStateReader.CORE_NAME_PROP);

        String leaderUrl = ZkCoreNodeProps.getCoreUrl(leaderBaseUrl, leaderCoreName);

        sendPrepRecoveryCmd(leaderBaseUrl, leaderCoreName);


        // first thing we just try to sync
        if (firstTime) {
          firstTime = false; // only try sync the first time through the loop
          log.info("Attempting to PeerSync from " + leaderUrl + " recoveringAfterStartup="+recoveringAfterStartup);
          // System.out.println("Attempting to PeerSync from " + leaderUrl
          // + " i am:" + zkController.getNodeName());
          PeerSync peerSync = new PeerSync(core,
              Collections.singletonList(leaderUrl), ulog.numRecordsToKeep);
          peerSync.setStartingVersions(recentVersions);
          boolean syncSuccess = peerSync.sync();
          if (syncSuccess) {
            SolrQueryRequest req = new LocalSolrQueryRequest(core,
                new ModifiableSolrParams());
            core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));
            log.info("Sync Recovery was successful - registering as Active");
            // System.out
            // .println("Sync Recovery was successful - registering as Active "
            // + zkController.getNodeName());

            // solrcloud_debug
            // try {
            // RefCounted<SolrIndexSearcher> searchHolder =
            // core.getNewestSearcher(false);
            // SolrIndexSearcher searcher = searchHolder.get();
            // try {
            // System.out.println(core.getCoreDescriptor().getCoreContainer().getZkController().getNodeName()
            // + " synched "
            // + searcher.search(new MatchAllDocsQuery(), 1).totalHits);
            // } finally {
            // searchHolder.decref();
            // }
            // } catch (Exception e) {
            //
            // }

            // sync success - register as active and return
            zkController.publish(core.getCoreDescriptor(),
                ZkStateReader.ACTIVE);
            successfulRecovery = true;
            close = true;
            return;
          }

          log.info("Sync Recovery was not successful - trying replication");
        }
        //System.out.println("Sync Recovery was not successful - trying replication");

        log.info("Begin buffering updates");
        ulog.bufferUpdates();
        replayed = false;

        try {

          replicate(zkController.getNodeName(), core,
              leaderprops, leaderUrl);

          replay(ulog);
          replayed = true;

          log.info("Recovery was successful - registering as Active");
          // if there are pending recovery requests, don't advert as active
          zkController.publish(core.getCoreDescriptor(), ZkStateReader.ACTIVE);
          close = true;
          successfulRecovery = true;
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          log.warn("Recovery was interrupted", e);
          retries = INTERRUPTED;
        } catch (Throwable t) {
          log.error("Error while trying to recover", t);
        } finally {
          if (!replayed) {
            try {
              ulog.dropBufferedUpdates();
            } catch (Throwable t) {
              SolrException.log(log, "", t);
            }
          }

        }

      } catch (Throwable t) {
        log.error("Error while trying to recover.", t);
      }

      if (!successfulRecovery) {
        // lets pause for a moment and we need to try again...
        // TODO: we don't want to retry for some problems?
        // Or do a fall off retry...
        try {

          log.error("Recovery failed - trying again...");
          retries++;
          if (retries >= MAX_RETRIES) {
            if (retries == INTERRUPTED) {

            } else {
              log.error("Recovery failed - max retries exceeded.");
              recoveryFailed(core, zkController, baseUrl, coreZkNodeName,
                  core.getCoreDescriptor());
            }
            break;
          }

        } catch (Exception e) {
          log.error("", e);
        }

        try {
          // start at 1 sec and work up to a couple min
          double loopCount = Math.min(Math.pow(2, retries), 600); 
          for (int i = 0; i < loopCount; i++) {
            if (isClosed()) break; // check if someone closed us
            Thread.sleep(STARTING_RECOVERY_DELAY);
          }
        } catch (InterruptedException e) {
          Thread.currentThread().interrupt();
          log.warn("Recovery was interrupted", e);
          retries = INTERRUPTED;
        }
      }

    }
    log.info("Finished recovery process");

  }

