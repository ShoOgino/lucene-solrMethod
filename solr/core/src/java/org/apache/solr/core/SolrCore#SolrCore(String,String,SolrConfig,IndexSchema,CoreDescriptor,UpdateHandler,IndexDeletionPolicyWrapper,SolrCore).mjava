  /**
   * Creates a new core and register it in the list of cores.
   * If a core with the same name already exists, it will be stopped and replaced by this one.
   *@param dataDir the index directory
   *@param config a solr config instance
   *@param schema a solr schema instance
   *
   *@since solr 1.3
   */
  public SolrCore(String name, String dataDir, SolrConfig config, IndexSchema schema, CoreDescriptor cd, UpdateHandler updateHandler, IndexDeletionPolicyWrapper delPolicy, SolrCore prev) {
    coreDescriptor = cd;
    this.setName( name );
    MDCUtils.setCore(name); // show the core name in the error logs
    
    resourceLoader = config.getResourceLoader();
    this.solrConfig = config;

    if (updateHandler == null) {
      initDirectoryFactory();
    }

    if (dataDir == null) {
      if (cd.usingDefaultDataDir()) dataDir = config.getDataDir();
      if (dataDir == null) {
        try {
          dataDir = cd.getDataDir();
          if (!directoryFactory.isAbsolute(dataDir)) {
            dataDir = directoryFactory.getDataHome(cd);
          }
        } catch (IOException e) {
          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, null, e);
        }
      }
    }
    dataDir = SolrResourceLoader.normalizeDir(dataDir);

    String updateLogDir = cd.getUlogDir();
    if (updateLogDir == null) {
      updateLogDir = dataDir;
      if (new File(updateLogDir).isAbsolute() == false) {
        updateLogDir = SolrResourceLoader.normalizeDir(cd.getInstanceDir()) + updateLogDir;
      }
    }
    ulogDir = updateLogDir;


    log.info(logid+"Opening new SolrCore at " + resourceLoader.getInstanceDir() + ", dataDir="+dataDir);

    if (null != cd && null != cd.getCloudDescriptor()) {
      // we are evidently running in cloud mode.  
      //
      // In cloud mode, version field is required for correct consistency
      // ideally this check would be more fine grained, and individual features
      // would assert it when they initialize, but DistributedUpdateProcessor
      // is currently a big ball of wax that does more then just distributing
      // updates (ie: partial document updates), so it needs to work in no cloud
      // mode as well, and can't assert version field support on init.

      try {
        VersionInfo.getAndCheckVersionField(schema);
      } catch (SolrException e) {
        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,
                                "Schema will not work with SolrCloud mode: " +
                                e.getMessage(), e);
      }
    }

    //Initialize JMX
    if (config.jmxConfig.enabled) {
      infoRegistry = new JmxMonitoredMap<String, SolrInfoMBean>(name, String.valueOf(this.hashCode()), config.jmxConfig);
    } else  {
      log.info("JMX monitoring not detected for core: " + name);
      infoRegistry = new ConcurrentHashMap<>();
    }

    infoRegistry.put("fieldCache", new SolrFieldCacheMBean());

    if (schema==null) {
      schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);
    }
    this.schema = schema;
    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();
    if (similarityFactory instanceof SolrCoreAware) {
      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below
      ((SolrCoreAware)similarityFactory).inform(this);
    }

    this.dataDir = dataDir;
    this.startTime = System.currentTimeMillis();
    this.maxWarmingSearchers = config.maxWarmingSearchers;
    this.slowQueryThresholdMillis = config.slowQueryThresholdMillis;

    booleanQueryMaxClauseCount();

    final CountDownLatch latch = new CountDownLatch(1);

    try {

      initListeners();

      if (delPolicy == null) {
        initDeletionPolicy();
      } else {
        this.solrDelPolicy = delPolicy;
      }

      this.codec = initCodec(solrConfig, schema);

      if (updateHandler == null) {
        solrCoreState = new DefaultSolrCoreState(getDirectoryFactory());
      } else {
        solrCoreState = updateHandler.getSolrCoreState();
        directoryFactory = solrCoreState.getDirectoryFactory();
        this.isReloaded = true;
      }
      memClassLoader = new MemClassLoader(PluginBag.RuntimeLib.getLibObjects(this, solrConfig.getPluginInfos(PluginBag.RuntimeLib.class.getName())), getResourceLoader());
      initIndex(prev != null);

      initWriters();
      qParserPlugins.init(createInstances(QParserPlugin.standardPlugins), this);
      valueSourceParsers.init(ValueSourceParser.standardValueSourceParsers, this);
      transformerFactories.init(TransformerFactory.defaultFactories, this);
      loadSearchComponents();
      updateProcessors.init(Collections.EMPTY_MAP, this);

      // Processors initialized before the handlers
      updateProcessorChains = loadUpdateProcessorChains();
      reqHandlers = new RequestHandlers(this);
      reqHandlers.initHandlersFromConfig(solrConfig);

      // Handle things that should eventually go away
      initDeprecatedSupport();

      statsCache = initStatsCache();

      // cause the executor to stall so firstSearcher events won't fire
      // until after inform() has been called for all components.
      // searchExecutor must be single-threaded for this to work
      searcherExecutor.submit(new Callable<Void>() {
        @Override
        public Void call() throws Exception {
          latch.await();
          return null;
        }
      });

      // use the (old) writer to open the first searcher
      RefCounted<IndexWriter> iwRef = null;
      if (prev != null) {
        iwRef = prev.getUpdateHandler().getSolrCoreState().getIndexWriter(null);
        if (iwRef != null) {
          final IndexWriter iw = iwRef.get();
          final SolrCore core = this;
          newReaderCreator = new Callable<DirectoryReader>() {
            // this is used during a core reload

            @Override
            public DirectoryReader call() throws Exception {
              return indexReaderFactory.newReader(iw, core);
            }
          };
        }
      }

      String updateHandlerClass = solrConfig.getUpdateHandlerInfo().className;

      if (updateHandler == null) {
        this.updateHandler = createUpdateHandler(updateHandlerClass == null ? DirectUpdateHandler2.class
            .getName() : updateHandlerClass);
      } else {
        this.updateHandler = createUpdateHandler(
            updateHandlerClass == null ? DirectUpdateHandler2.class.getName()
                : updateHandlerClass, updateHandler);
      }
      infoRegistry.put("updateHandler", this.updateHandler);

      try {
        getSearcher(false, false, null, true);
      } finally {
        newReaderCreator = null;
        if (iwRef != null) iwRef.decref();
      }

      // Initialize the RestManager
      restManager = initRestManager();

      // Finally tell anyone who wants to know
      resourceLoader.inform(resourceLoader);
      resourceLoader.inform(this); // last call before the latch is released.
    } catch (Throwable e) {
      latch.countDown();//release the latch, otherwise we block trying to do the close.  This should be fine, since counting down on a latch of 0 is still fine
      //close down the searcher and any other resources, if it exists, as this is not recoverable
      if (e instanceof OutOfMemoryError) {
        throw (OutOfMemoryError)e;
      }

      try {
       this.close();
      } catch (Throwable t) {
        if (t instanceof OutOfMemoryError) {
          throw (OutOfMemoryError)t;
        }
        log.error("Error while closing", t);
      }

      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,
                              e.getMessage(), e);
    } finally {
      // allow firstSearcher events to fire and make sure it is released
      latch.countDown();
    }

    infoRegistry.put("core", this);

    // register any SolrInfoMBeans SolrResourceLoader initialized
    //
    // this must happen after the latch is released, because a JMX server impl may
    // choose to block on registering until properties can be fetched from an MBean,
    // and a SolrCoreAware MBean may have properties that depend on getting a Searcher
    // from the core.
    resourceLoader.inform(infoRegistry);

    CoreContainer cc = cd.getCoreContainer();

    if (cc != null && cc.isZooKeeperAware()) {
      SolrRequestHandler realtimeGetHandler = reqHandlers.get("/get");
      if (realtimeGetHandler == null) {
        log.warn("WARNING: RealTimeGetHandler is not registered at /get. " +
            "SolrCloud will always use full index replication instead of the more efficient PeerSync method.");
      }

      // ZK pre-Register would have already happened so we read slice properties now
      ClusterState clusterState = cc.getZkController().getClusterState();
      Slice slice = clusterState.getSlice(cd.getCloudDescriptor().getCollectionName(),
          cd.getCloudDescriptor().getShardId());
      if (Slice.CONSTRUCTION.equals(slice.getState())) {
        // set update log to buffer before publishing the core
        getUpdateHandler().getUpdateLog().bufferUpdates();
      }
    }
    // For debugging   
//    numOpens.incrementAndGet();
//    openHandles.put(this, new RuntimeException("unclosed core - name:" + getName() + " refs: " + refCount.get()));

    ruleExpiryLock = new ReentrantLock();
    registerConfListener();
  }

