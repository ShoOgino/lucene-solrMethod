    @Override
    public Boolean call() throws Exception {
      boolean success = false;
      UpdateLog ulog = core.getUpdateHandler().getUpdateLog();
      // we start buffering updates as a safeguard however we do not expect
      // to receive any updates from the source during bootstrap
      ulog.bufferUpdates();
      try {
        commitOnLeader(leaderUrl);
        // use rep handler directly, so we can do this sync rather than async
        SolrRequestHandler handler = core.getRequestHandler(ReplicationHandler.PATH);
        ReplicationHandler replicationHandler = (ReplicationHandler) handler;

        if (replicationHandler == null) {
          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,
              "Skipping recovery, no " + ReplicationHandler.PATH + " handler found");
        }

        ModifiableSolrParams solrParams = new ModifiableSolrParams();
        solrParams.set(ReplicationHandler.LEADER_URL, leaderUrl);
        // we do not want the raw tlog files from the source
        solrParams.set(ReplicationHandler.TLOG_FILES, false);

        success = replicationHandler.doFetch(solrParams, false).getSuccessful();

        Future<UpdateLog.RecoveryInfo> future = ulog.applyBufferedUpdates();
        if (future == null) {
          // no replay needed
          log.info("No replay needed.");
        } else {
          log.info("Replaying buffered documents.");
          // wait for replay
          UpdateLog.RecoveryInfo report = future.get();
          if (report.failed) {
            SolrException.log(log, "Replay failed");
            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, "Replay failed");
          }
        }
        if (success)  {
          ZkController zkController = core.getCoreContainer().getZkController();
          String collectionName = core.getCoreDescriptor().getCollectionName();
          ClusterState clusterState = zkController.getZkStateReader().getClusterState();
          DocCollection collection = clusterState.getCollection(collectionName);
          Slice slice = collection.getSlice(core.getCoreDescriptor().getCloudDescriptor().getShardId());
          ZkShardTerms terms = zkController.getShardTerms(collectionName, slice.getName());
          String coreNodeName = core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName();
          Set<String> allExceptLeader = slice.getReplicas().stream().filter(replica -> !replica.getName().equals(coreNodeName)).map(Replica::getName).collect(Collectors.toSet());
          terms.ensureTermsIsHigher(coreNodeName, allExceptLeader);
        }
        return success;
      } finally {
        if (closed || !success) {
          // we cannot apply the buffer in this case because it will introduce newer versions in the
          // update log and then the source cluster will get those versions via collectioncheckpoint
          // causing the versions in between to be completely missed
          boolean dropped = ulog.dropBufferedUpdates();
          assert dropped;
        }
      }
    }

