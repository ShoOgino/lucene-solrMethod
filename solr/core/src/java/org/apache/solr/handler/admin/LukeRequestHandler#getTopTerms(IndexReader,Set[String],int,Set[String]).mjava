  private static Map<String,TopTermQueue> getTopTerms( IndexReader reader, Set<String> fields, int numTerms, Set<String> junkWords ) throws Exception 
  {
    Map<String,TopTermQueue> info = new HashMap<String, TopTermQueue>();
    final CharsRef spare = new CharsRef();
    Fields fieldsC = MultiFields.getFields(reader);
    if (fieldsC != null) {
      FieldsEnum fieldsEnum = fieldsC.iterator();
      String field;
      while((field = fieldsEnum.next()) != null) {

        Terms terms = fieldsEnum.terms();
        if (terms == null) {
          continue;
        }
        TermsEnum termsEnum = terms.iterator(null);
        BytesRef text;
        while((text = termsEnum.next()) != null) {
          String t = text.utf8ToChars(spare).toString();
  
          // Compute distinct terms for every field
          TopTermQueue tiq = info.get( field );
          if( tiq == null ) {
            tiq = new TopTermQueue( numTerms+1 );
            info.put( field, tiq );
          }

          tiq.distinctTerms++;
          tiq.histogram.add( termsEnum.docFreq() );  // add the term to the histogram
        
          // Only save the distinct terms for fields we worry about
          if (fields != null && fields.size() > 0) {
            if( !fields.contains( field ) ) {
              continue;
            }
          }
          if( junkWords != null && junkWords.contains( t ) ) {
            continue;
          }
        
          if( termsEnum.docFreq() > tiq.minFreq ) {
            tiq.add(new TopTermQueue.TermInfo(new Term(field, t), termsEnum.docFreq()));
            if (tiq.size() > numTerms) { // if tiq full
              tiq.pop(); // remove lowest in tiq
              tiq.minFreq = ((TopTermQueue.TermInfo)tiq.top()).docFreq; // reset minFreq
            }
          }
        }
      }
    }
    return info;
  }

