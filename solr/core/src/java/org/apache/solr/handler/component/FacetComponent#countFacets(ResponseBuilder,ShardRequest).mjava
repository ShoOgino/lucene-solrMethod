  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {
    FacetInfo fi = rb._facetInfo;

    for (ShardResponse srsp: sreq.responses) {
      int shardNum = rb.getShardNum(srsp.getShard());
      NamedList facet_counts = null;
      try {
        facet_counts = (NamedList)srsp.getSolrResponse().getResponse().get("facet_counts");
      }
      catch(Exception ex) {
        if(rb.req.getParams().getBool(ShardParams.SHARDS_TOLERANT, false)) {
          continue; // looks like a shard did not return anything
        }
        throw new SolrException(ErrorCode.SERVER_ERROR, "Unable to read facet info for shard: "+srsp.getShard(), ex);
      }

      // handle facet queries
      NamedList facet_queries = (NamedList)facet_counts.get("facet_queries");
      if (facet_queries != null) {
        for (int i=0; i<facet_queries.size(); i++) {
          String returnedKey = facet_queries.getName(i);
          long count = ((Number)facet_queries.getVal(i)).longValue();
          QueryFacet qf = fi.queryFacets.get(returnedKey);
          qf.count += count;
        }
      }

      // step through each facet.field, adding results from this shard
      NamedList facet_fields = (NamedList)facet_counts.get("facet_fields");
    
      if (facet_fields != null) {
        for (DistribFieldFacet dff : fi.facets.values()) {
          dff.add(shardNum, (NamedList)facet_fields.get(dff.getKey()), dff.initialLimit);
        }
      }

      // Distributed facet_dates
      //
      // The implementation below uses the first encountered shard's 
      // facet_dates as the basis for subsequent shards' data to be merged.
      // (the "NOW" param should ensure consistency)
      @SuppressWarnings("unchecked")
      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_dates = 
        (SimpleOrderedMap<SimpleOrderedMap<Object>>) 
        facet_counts.get("facet_dates");
      
      if (facet_dates != null) {

        // go through each facet_date
        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_dates) {
          final String field = entry.getKey();
          if (fi.dateFacets.get(field) == null) { 
            // first time we've seen this field, no merging
            fi.dateFacets.add(field, entry.getValue());

          } else { 
            // not the first time, merge current field

            SimpleOrderedMap<Object> shardFieldValues 
              = entry.getValue();
            SimpleOrderedMap<Object> existFieldValues 
              = fi.dateFacets.get(field);

            for (Map.Entry<String,Object> existPair : existFieldValues) {
              final String key = existPair.getKey();
              if (key.equals("gap") || 
                  key.equals("end") || 
                  key.equals("start")) {
                // we can skip these, must all be the same across shards
                continue; 
              }
              // can be null if inconsistencies in shards responses
              Integer newValue = (Integer) shardFieldValues.get(key);
              if  (null != newValue) {
                Integer oldValue = ((Integer) existPair.getValue());
                existPair.setValue(oldValue + newValue);
              }
            }
          }
        }
      }

      // Distributed facet_ranges
      //
      // The implementation below uses the first encountered shard's 
      // facet_ranges as the basis for subsequent shards' data to be merged.
      @SuppressWarnings("unchecked")
      SimpleOrderedMap<SimpleOrderedMap<Object>> facet_ranges = 
        (SimpleOrderedMap<SimpleOrderedMap<Object>>) 
        facet_counts.get("facet_ranges");
      
      if (facet_ranges != null) {

        // go through each facet_range
        for (Map.Entry<String,SimpleOrderedMap<Object>> entry : facet_ranges) {
          final String field = entry.getKey();
          if (fi.rangeFacets.get(field) == null) { 
            // first time we've seen this field, no merging
            fi.rangeFacets.add(field, entry.getValue());

          } else { 
            // not the first time, merge current field counts

            @SuppressWarnings("unchecked")
            NamedList<Integer> shardFieldValues 
              = (NamedList<Integer>) entry.getValue().get("counts");

            @SuppressWarnings("unchecked")
            NamedList<Integer> existFieldValues 
              = (NamedList<Integer>) fi.rangeFacets.get(field).get("counts");

            for (Map.Entry<String,Integer> existPair : existFieldValues) {
              final String key = existPair.getKey();
              // can be null if inconsistencies in shards responses
              Integer newValue = shardFieldValues.get(key);
              if  (null != newValue) {
                Integer oldValue = existPair.getValue();
                existPair.setValue(oldValue + newValue);
              }
            }
          }
        }
      }
    }

    //
    // This code currently assumes that there will be only a single
    // request ((with responses from all shards) sent out to get facets...
    // otherwise we would need to wait until all facet responses were received.
    //

    for (DistribFieldFacet dff : fi.facets.values()) {
       // no need to check these facets for refinement
      if (dff.initialLimit <= 0 && dff.initialMincount <= 1) continue;

      // only other case where index-sort doesn't need refinement is if minCount==0
      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;

      @SuppressWarnings("unchecked") // generic array's are annoying
      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];
      dff._toRefine = tmp;

      ShardFacetCount[] counts = dff.getCountSorted();
      int ntop = Math.min(counts.length, dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);
      long smallestCount = counts.length == 0 ? 0 : counts[ntop-1].count;

      for (int i=0; i<counts.length; i++) {
        ShardFacetCount sfc = counts[i];
        boolean needRefinement = false;

        if (i<ntop) {
          // automatically flag the top values for refinement
          // this should always be true for facet.sort=index
          needRefinement = true;
        } else {
          // this logic should only be invoked for facet.sort=index (for now)

          // calculate the maximum value that this term may have
          // and if it is >= smallestCount, then flag for refinement
          long maxCount = sfc.count;
          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {
            OpenBitSet obs = dff.counted[shardNum];
            if (obs!=null && !obs.get(sfc.termNum)) {  // obs can be null if a shard request failed
              // if missing from this shard, add the max it could be
              maxCount += dff.maxPossible(sfc,shardNum);
            }
          }
          if (maxCount >= smallestCount) {
            // TODO: on a tie, we could check the term values
            needRefinement = true;
          }
        }

        if (needRefinement) {
          // add a query for each shard missing the term that needs refinement
          for (int shardNum=0; shardNum<rb.shards.length; shardNum++) {
            OpenBitSet obs = dff.counted[shardNum];
            if(obs!=null && !obs.get(sfc.termNum) && dff.maxPossible(sfc,shardNum)>0) {
              dff.needRefinements = true;
              List<String> lst = dff._toRefine[shardNum];
              if (lst == null) {
                lst = dff._toRefine[shardNum] = new ArrayList<String>();
              }
              lst.add(sfc.name);
            }
          }
        }
      }
    }
  }

