  private void countFacets(ResponseBuilder rb, ShardRequest sreq) {
    FacetInfo fi = rb._facetInfo;
    
    for (ShardResponse srsp : sreq.responses) {
      int shardNum = rb.getShardNum(srsp.getShard());
      NamedList facet_counts = null;
      try {
        facet_counts = (NamedList) srsp.getSolrResponse().getResponse().get("facet_counts");
        if (facet_counts==null) {
          NamedList<?> responseHeader = (NamedList<?>)srsp.getSolrResponse().getResponse().get("responseHeader");
          if (Boolean.TRUE.equals(responseHeader.getBooleanArg(SolrQueryResponse.RESPONSE_HEADER_PARTIAL_RESULTS_KEY))) {
            continue;
          } else {
            log.warn("corrupted response on "+srsp.getShardRequest()+": "+srsp.getSolrResponse());
            throw new SolrException(ErrorCode.SERVER_ERROR,
                "facet_counts is absent in response from " + srsp.getNodeName() +
                ", but "+SolrQueryResponse.RESPONSE_HEADER_PARTIAL_RESULTS_KEY+" hasn't been responded");
          }
        }
      } catch (Exception ex) {
        if (ShardParams.getShardsTolerantAsBool(rb.req.getParams())) {
          continue; // looks like a shard did not return anything
        }
        throw new SolrException(ErrorCode.SERVER_ERROR,
            "Unable to read facet info for shard: " + srsp.getShard(), ex);
      }
      
      // handle facet queries
      NamedList facet_queries = (NamedList) facet_counts.get("facet_queries");
      if (facet_queries != null) {
        for (int i = 0; i < facet_queries.size(); i++) {
          String returnedKey = facet_queries.getName(i);
          long count = ((Number) facet_queries.getVal(i)).longValue();
          QueryFacet qf = fi.queryFacets.get(returnedKey);
          qf.count += count;
        }
      }

      // step through each facet.field, adding results from this shard
      NamedList facet_fields = (NamedList) facet_counts.get("facet_fields");
      
      if (facet_fields != null) {
        for (DistribFieldFacet dff : fi.facets.values()) {
          dff.add(shardNum, (NamedList) facet_fields.get(dff.getKey()), dff.initialLimit);
        }
      }

      // Distributed facet_ranges
      @SuppressWarnings("unchecked")
      SimpleOrderedMap<SimpleOrderedMap<Object>> rangesFromShard = (SimpleOrderedMap<SimpleOrderedMap<Object>>)
          facet_counts.get("facet_ranges");
      if (rangesFromShard != null)  {
        RangeFacetRequest.DistribRangeFacet.mergeFacetRangesFromShardResponse(fi.rangeFacets, rangesFromShard);
      }

      // Distributed facet_intervals
      doDistribIntervals(fi, facet_counts);
      
      // Distributed facet_pivots - this is just the per shard collection,
      // refinement reqs still needed (below) once we've considered every shard
      doDistribPivots(rb, shardNum, facet_counts);

      // Distributed facet_heatmaps
      SpatialHeatmapFacets.distribHandleResponse(fi.heatmapFacets, facet_counts);

    } // end for-each-response-in-shard-request...
    
    // refine each pivot based on the new shard data
    for (Entry<String,PivotFacet> pivotFacet : fi.pivotFacets) {
      pivotFacet.getValue().queuePivotRefinementRequests();
    }
    
    //
    // This code currently assumes that there will be only a single
    // request ((with responses from all shards) sent out to get facets...
    // otherwise we would need to wait until all facet responses were received.
    //
    for (DistribFieldFacet dff : fi.facets.values()) {
      // no need to check these facets for refinement
      if (dff.initialLimit <= 0 && dff.initialMincount <= 1) continue;

      // only other case where index-sort doesn't need refinement is if minCount==0
      if (dff.minCount <= 1 && dff.sort.equals(FacetParams.FACET_SORT_INDEX)) continue;

      @SuppressWarnings("unchecked") // generic array's are annoying
      List<String>[] tmp = (List<String>[]) new List[rb.shards.length];
      dff._toRefine = tmp;

      ShardFacetCount[] counts = dff.getCountSorted();
      int ntop = Math.min(counts.length, 
                          dff.limit >= 0 ? dff.offset + dff.limit : Integer.MAX_VALUE);
      long smallestCount = counts.length == 0 ? 0 : counts[ntop - 1].count;
      
      for (int i = 0; i < counts.length; i++) {
        ShardFacetCount sfc = counts[i];
        boolean needRefinement = false;

        if (i < ntop) {
          // automatically flag the top values for refinement
          // this should always be true for facet.sort=index
          needRefinement = true;
        } else {
          // this logic should only be invoked for facet.sort=index (for now)
          
          // calculate the maximum value that this term may have
          // and if it is >= smallestCount, then flag for refinement
          long maxCount = sfc.count;
          for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {
            FixedBitSet fbs = dff.counted[shardNum];
            // fbs can be null if a shard request failed
            if (fbs != null && (sfc.termNum >= fbs.length() || !fbs.get(sfc.termNum))) {
              // if missing from this shard, add the max it could be
              maxCount += dff.maxPossible(shardNum);
            }
          }
          if (maxCount >= smallestCount) {
            // TODO: on a tie, we could check the term values
            needRefinement = true;
          }
        }

        if (needRefinement) {
          // add a query for each shard missing the term that needs refinement
          for (int shardNum = 0; shardNum < rb.shards.length; shardNum++) {
            FixedBitSet fbs = dff.counted[shardNum];
            // fbs can be null if a shard request failed
            if (fbs != null &&
                (sfc.termNum >= fbs.length() || !fbs.get(sfc.termNum)) &&
                dff.maxPossible(shardNum) > 0) {

              dff.needRefinements = true;
              List<String> lst = dff._toRefine[shardNum];
              if (lst == null) {
                lst = dff._toRefine[shardNum] = new ArrayList<>();
              }
              lst.add(sfc.name);
            }
          }
        }
      }
    }
    removeFieldFacetsUnderLimits(rb);
    removeRangeFacetsUnderLimits(rb);
    removeQueryFacetsUnderLimits(rb);

  }

