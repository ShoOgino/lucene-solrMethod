  /**
   * <p> Collects unique keys of all Solr documents for whom one or more source tables have been changed since the last
   * indexed time. </p> <p> Note: In our definition, unique key of Solr document is the primary key of the top level
   * entity (unless skipped using docRoot=false) in the Solr document in data-config.xml </p>
   *
   * @return an iterator to the list of keys for which Solr documents should be updated.
   */
  @SuppressWarnings("unchecked")
  public Set<Map<String, Object>> collectDelta(DataConfig.Entity entity,
                                               DataConfig.Entity parentEntity, VariableResolverImpl resolver,
                                               DataImporter context, Set<Map<String, Object>> deletedRows) {
    //someone called abort
    if (stop.get())
      return new HashSet();

    Set<Map<String, Object>> myModifiedPks = new HashSet<Map<String, Object>>();

    if (entity.entities != null) {

      for (DataConfig.Entity entity1 : entity.entities) {
        //this ensures that we start from the leaf nodes
        myModifiedPks.addAll(collectDelta(entity1, entity, resolver, context,
                deletedRows));
      }

    }
    // identifying the modified rows for this entities

    Set<Map<String, Object>> deltaSet = new HashSet<Map<String, Object>>();
    resolver.addNamespace(null, (Map) entity.allAttributes);
    EntityProcessor entityProcessor = getEntityProcessor(entity, context.getCore());
    entityProcessor.init(new ContextImpl(entity, resolver, null,
            Context.FIND_DELTA, session, null, this));
    LOG.info("Running ModifiedRowKey() for Entity: " + entity.name);
    int count = 0;
    //get the modified rows in this entity
    while (true) {
      Map<String, Object> row = entityProcessor.nextModifiedRowKey();

      if (row == null)
        break;

      deltaSet.add(row);
      count++;
      importStatistics.rowsCount.incrementAndGet();
    }
    LOG.info("Completed ModifiedRowKey for Entity: " + entity.name
            + " rows obtained : " + count);
    count = 0;
    // identifying the deleted rows from this entities
    LOG.info("Running DeletedRowKey() for Entity: " + entity.name);
    //get the deleted rows for this entity
    Set<Map<String, Object>> deletedSet = new HashSet<Map<String, Object>>();
    while (true) {
      Map<String, Object> row = entityProcessor.nextDeletedRowKey();
      if (row == null)
        break;

      deletedSet.add(row);
      count++;
      importStatistics.rowsCount.incrementAndGet();
    }
    LOG.info("Completed DeletedRowKey for Entity: " + entity.name
            + " rows obtained : " + count);

    myModifiedPks.addAll(deltaSet);
    Set<Map<String, Object>> parentKeyList = new HashSet<Map<String, Object>>();
    //all that we have captured is useless (in a sub-entity) if no rows in the parent is modified because of these
    //so propogate up the changes in the chain
    if (parentEntity != null && parentEntity.isDocRoot) {
      EntityProcessor parentEntityProcessor = getEntityProcessor(parentEntity, context.getCore());
      parentEntityProcessor.init(new ContextImpl(parentEntity, resolver, null, Context.FIND_DELTA, session, null, this));
      // identifying deleted rows with deltas

      for (Map<String, Object> row : myModifiedPks)
        getModifiedParentRows(resolver.addNamespace(entity.name, row),
                entity.name, parentEntityProcessor, parentKeyList);
      // running the same for deletedrows
      for (Map<String, Object> row : deletedSet) {
        getModifiedParentRows(resolver.addNamespace(entity.name, row),
                entity.name, parentEntityProcessor, parentKeyList);
      }
    }
    LOG.info("Completed parentDeltaQuery for Entity: " + entity.name);
    if (entity.isDocRoot)
      deletedRows.addAll(deletedSet);

    return entity.isDocRoot ? myModifiedPks : new HashSet<Map<String, Object>>(
            parentKeyList);
  }

