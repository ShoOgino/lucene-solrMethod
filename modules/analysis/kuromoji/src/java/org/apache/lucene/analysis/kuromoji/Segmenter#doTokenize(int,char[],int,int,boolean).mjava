  /**
   * Tokenize input sentence.
   * @param offset offset of sentence in original input text
   * @param sentence sentence to tokenize
   * @return list of Token
   */
  public List<Token> doTokenize(int offset, char[] sentence, int sentenceOffset, int sentenceLength, boolean discardPunctuation) {
    ArrayList<Token> result = new ArrayList<Token>();
    
    ViterbiNode[][][] lattice;
    try {
      lattice = viterbi.build(sentence, sentenceOffset, sentenceLength);
    } catch (IOException impossible) {
      throw new RuntimeException(impossible);
    }
    List<ViterbiNode> bestPath = viterbi.search(lattice);
    for (ViterbiNode node : bestPath) {
      int wordId = node.getWordId();
      if (node.getType() == Type.KNOWN && wordId == -1){ // Do not include BOS/EOS 
        continue;
      } else if (discardPunctuation && node.getLength() > 0 && isPunctuation(node.getSurfaceForm()[node.getOffset()])) {
        continue; // Do not emit punctuation
      }
      Token token = new Token(wordId, node.getSurfaceForm(), node.getOffset(), node.getLength(), node.getType(), offset + node.getStartIndex(), dictionaryMap.get(node.getType()));	// Pass different dictionary based on the type of node
      result.add(token);
    }
    
    return result;
  }

