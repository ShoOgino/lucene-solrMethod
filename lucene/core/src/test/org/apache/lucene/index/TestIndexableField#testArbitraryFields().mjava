  // Silly test showing how to index documents w/o using Lucene's core
  // Document nor Field class
  public void testArbitraryFields() throws Exception {

    final Directory dir = newDirectory();
    final RandomIndexWriter w = new RandomIndexWriter(random(), dir);

    final int NUM_DOCS = atLeast(27);
    if (VERBOSE) {
      System.out.println("TEST: " + NUM_DOCS + " docs");
    }
    final int[] fieldsPerDoc = new int[NUM_DOCS];
    int baseCount = 0;

    for(int docCount=0;docCount<NUM_DOCS;docCount++) {
      final int fieldCount = _TestUtil.nextInt(random(), 1, 17);
      fieldsPerDoc[docCount] = fieldCount-1;

      final int finalDocCount = docCount;
      if (VERBOSE) {
        System.out.println("TEST: " + fieldCount + " fields in doc " + docCount);
      }

      final int finalBaseCount = baseCount;
      baseCount += fieldCount-1;

      IndexDocument d = new IndexDocument() {
        @Override
        public Iterable<IndexableField> indexableFields() {
          return new Iterable<IndexableField>() {
            @Override
            public Iterator<IndexableField> iterator() {
              return new Iterator<IndexableField>() {
                int fieldUpto = 0;
                private IndexableField next;

                @Override
                public boolean hasNext() {
                  if (fieldUpto >= fieldCount) return false;

                  next = null;
                  if (fieldUpto == 0) {
                    fieldUpto = 1;
                    next = newStringField("id", ""+finalDocCount, Field.Store.YES);
                  } else {
                    next = new MyField(finalBaseCount + (fieldUpto++-1));
                  }
                  
                  if (next != null && next.fieldType().indexed()) return true;
                  else return this.hasNext();
                }

                @Override
                public IndexableField next() {
                  assert fieldUpto <= fieldCount;
                  if (next == null && !hasNext()) {
                    return null;
                  }
                  else {
                    return next;
                  }
                }

                @Override
                public void remove() {
                  throw new UnsupportedOperationException();
                }
              };
            }
          };
        }

        @Override
        public Iterable<StorableField> storableFields() {
          return new Iterable<StorableField>() {
            @Override
            public Iterator<StorableField> iterator() {
              return new Iterator<StorableField>() {
                int fieldUpto = 0;
                private StorableField next = null;

                @Override
                public boolean hasNext() {

                  if (fieldUpto == fieldCount) return false;
                  
                  next = null;
                  if (fieldUpto == 0) {
                    fieldUpto = 1;
                    next = newStringField("id", ""+finalDocCount, Field.Store.YES);
                  } else {
                    next = new MyField(finalBaseCount + (fieldUpto++-1));
                  }
                  
                  if (next != null && next.fieldType().stored()) return true;
                  else return this.hasNext();
                }

                @Override
                public StorableField next() {
                  assert fieldUpto <= fieldCount;
                  if (next == null && !hasNext()) {
                    return null;
                  }
                  else {
                    return next;
                  }
                }

                @Override
                public void remove() {
                  throw new UnsupportedOperationException();
                }
              };
            }
          };
        }
      };
      
      w.addDocument(d);
    }

    final IndexReader r = w.getReader();
    w.close();

    final IndexSearcher s = newSearcher(r);
    int counter = 0;
    for(int id=0;id<NUM_DOCS;id++) {
      if (VERBOSE) {
        System.out.println("TEST: verify doc id=" + id + " (" + fieldsPerDoc[id] + " fields) counter=" + counter);
      }

      final TopDocs hits = s.search(new TermQuery(new Term("id", ""+id)), 1);
      assertEquals(1, hits.totalHits);
      final int docID = hits.scoreDocs[0].doc;
      final StoredDocument doc = s.doc(docID);
      final int endCounter = counter + fieldsPerDoc[id];
      while(counter < endCounter) {
        final String name = "f" + counter;
        final int fieldID = counter % 10;

        final boolean stored = (counter&1) == 0 || fieldID == 3;
        final boolean binary = fieldID == 3;
        final boolean indexed = fieldID != 3;

        final String stringValue;
        if (fieldID != 3 && fieldID != 9) {
          stringValue = "text " + counter;
        } else {
          stringValue = null;
        }

        // stored:
        if (stored) {
          StorableField f = doc.getField(name);
          assertNotNull("doc " + id + " doesn't have field f" + counter, f);
          if (binary) {
            assertNotNull("doc " + id + " doesn't have field f" + counter, f);
            final BytesRef b = f.binaryValue();
            assertNotNull(b);
            assertEquals(10, b.length);
            for(int idx=0;idx<10;idx++) {
              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);
            }
          } else {
            assert stringValue != null;
            assertEquals(stringValue, f.stringValue());
          }
        }
        
        if (indexed) {
          final boolean tv = counter % 2 == 1 && fieldID != 9;
          if (tv) {
            final Terms tfv = r.getTermVectors(docID).terms(name);
            assertNotNull(tfv);
            TermsEnum termsEnum = tfv.iterator(null);
            assertEquals(new BytesRef(""+counter), termsEnum.next());
            assertEquals(1, termsEnum.totalTermFreq());
            DocsAndPositionsEnum dpEnum = termsEnum.docsAndPositions(null, null);
            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
            assertEquals(1, dpEnum.freq());
            assertEquals(1, dpEnum.nextPosition());

            assertEquals(new BytesRef("text"), termsEnum.next());
            assertEquals(1, termsEnum.totalTermFreq());
            dpEnum = termsEnum.docsAndPositions(null, dpEnum);
            assertTrue(dpEnum.nextDoc() != DocIdSetIterator.NO_MORE_DOCS);
            assertEquals(1, dpEnum.freq());
            assertEquals(0, dpEnum.nextPosition());

            assertNull(termsEnum.next());

            // TODO: offsets
            
          } else {
            Fields vectors = r.getTermVectors(docID);
            assertTrue(vectors == null || vectors.terms(name) == null);
          }

          BooleanQuery bq = new BooleanQuery();
          bq.add(new TermQuery(new Term("id", ""+id)), BooleanClause.Occur.MUST);
          bq.add(new TermQuery(new Term(name, "text")), BooleanClause.Occur.MUST);
          final TopDocs hits2 = s.search(bq, 1);
          assertEquals(1, hits2.totalHits);
          assertEquals(docID, hits2.scoreDocs[0].doc);

          bq = new BooleanQuery();
          bq.add(new TermQuery(new Term("id", ""+id)), BooleanClause.Occur.MUST);
          bq.add(new TermQuery(new Term(name, ""+counter)), BooleanClause.Occur.MUST);
          final TopDocs hits3 = s.search(bq, 1);
          assertEquals(1, hits3.totalHits);
          assertEquals(docID, hits3.scoreDocs[0].doc);
        }

        counter++;
      }
    }

    r.close();
    dir.close();
  }

