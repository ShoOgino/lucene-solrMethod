    @Override
    protected Object createValue(AtomicReader reader, CacheKey key, boolean setDocsWithField /* ignored */)
        throws IOException {

      final int maxDoc = reader.maxDoc();
      SortedDocValues valuesIn = reader.getSortedDocValues(key.field);
      if (valuesIn != null) {
        final SortedDocValues ramInstance = valuesIn.newRAMInstance();
        return new DocTermsIndex() {

          @Override
          public BytesRef lookup(int ord, BytesRef reuse) {
            ramInstance.lookupOrd(ord, reuse);
            return reuse;
          }

          @Override
          public int getOrd(int docID) {
            return ramInstance.getOrd(docID);
          }

          @Override
          public int numOrd() {
            return ramInstance.getValueCount();
          }

          @Override
          public int size() {
            return ramInstance.size();
          }

          @Override
          public TermsEnum getTermsEnum() {
            // nocommit: to the codec api? or can that termsenum just use this thing?
            return null;
          }

          @Override
          public Reader getDocToOrd() {
            // nocommit: add this to the codec api!
            return null;
          }
        };
      } else {

        Terms terms = reader.terms(key.field);

        final float acceptableOverheadRatio = ((Float) key.custom).floatValue();

        final PagedBytes bytes = new PagedBytes(15);

        int startBytesBPV;
        int startTermsBPV;
        int startNumUniqueTerms;

        final int termCountHardLimit;
        if (maxDoc == Integer.MAX_VALUE) {
          termCountHardLimit = Integer.MAX_VALUE;
        } else {
          termCountHardLimit = maxDoc+1;
        }

        if (terms != null) {
          // Try for coarse estimate for number of bits; this
          // should be an underestimate most of the time, which
          // is fine -- GrowableWriter will reallocate as needed
          long numUniqueTerms = terms.size();
          if (numUniqueTerms != -1L) {
            if (numUniqueTerms > termCountHardLimit) {
              // app is misusing the API (there is more than
              // one term per doc); in this case we make best
              // effort to load what we can (see LUCENE-2142)
              numUniqueTerms = termCountHardLimit;
            }

            startBytesBPV = PackedInts.bitsRequired(numUniqueTerms*4);
            startTermsBPV = PackedInts.bitsRequired(numUniqueTerms);

            startNumUniqueTerms = (int) numUniqueTerms;
          } else {
            startBytesBPV = 1;
            startTermsBPV = 1;
            startNumUniqueTerms = 1;
          }
        } else {
          startBytesBPV = 1;
          startTermsBPV = 1;
          startNumUniqueTerms = 1;
        }

        GrowableWriter termOrdToBytesOffset = new GrowableWriter(startBytesBPV, 1+startNumUniqueTerms, acceptableOverheadRatio);
        final GrowableWriter docToTermOrd = new GrowableWriter(startTermsBPV, maxDoc, acceptableOverheadRatio);

        // 0 is reserved for "unset"
        bytes.copyUsingLengthPrefix(new BytesRef());
        int termOrd = 1;

        if (terms != null) {
          final TermsEnum termsEnum = terms.iterator(null);
          DocsEnum docs = null;

          while(true) {
            final BytesRef term = termsEnum.next();
            if (term == null) {
              break;
            }
            if (termOrd >= termCountHardLimit) {
              break;
            }

            if (termOrd == termOrdToBytesOffset.size()) {
              // NOTE: this code only runs if the incoming
              // reader impl doesn't implement
              // size (which should be uncommon)
              termOrdToBytesOffset = termOrdToBytesOffset.resize(ArrayUtil.oversize(1+termOrd, 1));
            }
            termOrdToBytesOffset.set(termOrd, bytes.copyUsingLengthPrefix(term));
            docs = termsEnum.docs(null, docs, 0);
            while (true) {
              final int docID = docs.nextDoc();
              if (docID == DocIdSetIterator.NO_MORE_DOCS) {
                break;
              }
              docToTermOrd.set(docID, termOrd);
            }
            termOrd++;
          }

          if (termOrdToBytesOffset.size() > termOrd) {
            termOrdToBytesOffset = termOrdToBytesOffset.resize(termOrd);
          }
        }

        // maybe an int-only impl?
        return new DocTermsIndexImpl(bytes.freeze(true), termOrdToBytesOffset.getMutable(), docToTermOrd.getMutable(), termOrd);
      }
    }

