    @Override
    protected Object createValue(AtomicReader reader, CacheKey key, boolean setDocsWithField /* ignored */)
        throws IOException {

      final int maxDoc = reader.maxDoc();
      SortedDocValues valuesIn = reader.getSortedDocValues(key.field);
      if (valuesIn != null) {
        // nocommit we need thread DV test that would
        // uncover this bug!!
        // nocommit we should not cache in this case?
        return valuesIn;
      } else {

        Terms terms = reader.terms(key.field);

        final float acceptableOverheadRatio = ((Float) key.custom).floatValue();

        final PagedBytes bytes = new PagedBytes(15);

        int startBytesBPV;
        int startTermsBPV;
        int startNumUniqueTerms;

        final int termCountHardLimit;
        if (maxDoc == Integer.MAX_VALUE) {
          termCountHardLimit = Integer.MAX_VALUE;
        } else {
          termCountHardLimit = maxDoc+1;
        }

        // TODO: use Uninvert?
        if (terms != null) {
          // Try for coarse estimate for number of bits; this
          // should be an underestimate most of the time, which
          // is fine -- GrowableWriter will reallocate as needed
          long numUniqueTerms = terms.size();
          if (numUniqueTerms != -1L) {
            if (numUniqueTerms > termCountHardLimit) {
              // app is misusing the API (there is more than
              // one term per doc); in this case we make best
              // effort to load what we can (see LUCENE-2142)
              numUniqueTerms = termCountHardLimit;
            }

            startBytesBPV = PackedInts.bitsRequired(numUniqueTerms*4);
            startTermsBPV = PackedInts.bitsRequired(numUniqueTerms);

            startNumUniqueTerms = (int) numUniqueTerms;
          } else {
            startBytesBPV = 1;
            startTermsBPV = 1;
            startNumUniqueTerms = 1;
          }
        } else {
          startBytesBPV = 1;
          startTermsBPV = 1;
          startNumUniqueTerms = 1;
        }

        GrowableWriter termOrdToBytesOffset = new GrowableWriter(startBytesBPV, 1+startNumUniqueTerms, acceptableOverheadRatio);
        final GrowableWriter docToTermOrd = new GrowableWriter(startTermsBPV, maxDoc, acceptableOverheadRatio);

        int termOrd = 0;

        // TODO: use Uninvert?

        if (terms != null) {
          final TermsEnum termsEnum = terms.iterator(null);
          DocsEnum docs = null;

          while(true) {
            final BytesRef term = termsEnum.next();
            if (term == null) {
              break;
            }
            if (termOrd >= termCountHardLimit) {
              break;
            }

            if (termOrd == termOrdToBytesOffset.size()) {
              // NOTE: this code only runs if the incoming
              // reader impl doesn't implement
              // size (which should be uncommon)
              termOrdToBytesOffset = termOrdToBytesOffset.resize(ArrayUtil.oversize(1+termOrd, 1));
            }
            termOrdToBytesOffset.set(termOrd, bytes.copyUsingLengthPrefix(term));
            docs = termsEnum.docs(null, docs, DocsEnum.FLAG_NONE);
            while (true) {
              final int docID = docs.nextDoc();
              if (docID == DocIdSetIterator.NO_MORE_DOCS) {
                break;
              }
              // Store 1+ ord into packed bits
              docToTermOrd.set(docID, 1+termOrd);
            }
            termOrd++;
          }

          if (termOrdToBytesOffset.size() > termOrd) {
            termOrdToBytesOffset = termOrdToBytesOffset.resize(termOrd);
          }
        }

        // maybe an int-only impl?
        return new SortedDocValuesImpl(bytes.freeze(true), termOrdToBytesOffset.getMutable(), docToTermOrd.getMutable(), termOrd);
      }
    }

