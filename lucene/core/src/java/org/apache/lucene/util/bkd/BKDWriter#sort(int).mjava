  private PointWriter sort(int dim) throws IOException {

    if (heapPointWriter != null) {

      assert tempInput == null;

      // We never spilled the incoming points to disk, so now we sort in heap:
      HeapPointWriter sorted;

      if (dim == 0) {
        // First dim can re-use the current heap writer
        sorted = heapPointWriter;
      } else {
        // Subsequent dims need a private copy
        sorted = new HeapPointWriter((int) pointCount, (int) pointCount, packedBytesLength, longOrds, singleValuePerDoc);
        sorted.copyFrom(heapPointWriter);
      }

      //long t0 = System.nanoTime();
      sortHeapPointWriter(sorted, dim);
      //long t1 = System.nanoTime();
      //System.out.println("BKD: sort took " + ((t1-t0)/1000000.0) + " msec");

      sorted.close();
      return sorted;
    } else {

      // Offline sort:
      assert tempInput != null;

      Comparator<BytesRef> cmp = new Comparator<BytesRef>() {
 
        final ByteArrayDataInput reader = new ByteArrayDataInput();

        @Override
        public int compare(BytesRef a, BytesRef b) {

          // First compare the bytes on the dimension we are sorting on:
          int cmp = StringHelper.compare(bytesPerDim, a.bytes, a.offset + bytesPerDim*dim, b.bytes, b.offset + bytesPerDim*dim);

          if (cmp != 0) {
            return cmp;
          }

          // Tie-break by docID:
          int offset;
          if (singleValuePerDoc) {
            offset = 0;
          } else if (longOrds) {
            offset = Long.BYTES;
          } else {
            offset = Integer.BYTES;
          }
          reader.reset(a.bytes, a.offset + packedBytesLength + offset, a.length);
          final int docIDA = reader.readInt();

          reader.reset(b.bytes, b.offset + packedBytesLength + offset, b.length);
          final int docIDB = reader.readInt();

          // No need to tie break on ord, for the case where the same doc has the same value in a given dimension indexed more than once: it
          // can't matter at search time since we don't write ords into the index:
          return Integer.compare(docIDA, docIDB);
        }
      };

      // TODO: this is sort of sneaky way to get the final OfflinePointWriter from OfflineSorter:
      IndexOutput[] lastWriter = new IndexOutput[1];

      OfflineSorter sorter = new OfflineSorter(tempDir, tempFileNamePrefix + "_bkd" + dim, cmp, OfflineSorter.BufferSize.megabytes(Math.max(1, (long) maxMBSortInHeap)), OfflineSorter.MAX_TEMPFILES) {

          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */
          @Override
          protected ByteSequencesWriter getWriter(IndexOutput out) {
            lastWriter[0] = out;
            return new ByteSequencesWriter(out) {
              @Override
              public void write(byte[] bytes, int off, int len) throws IOException {
                assert len == bytesPerDoc: "len=" + len + " bytesPerDoc=" + bytesPerDoc;
                out.writeBytes(bytes, off, len);
              }
            };
          }

          /** We write/read fixed-byte-width file that {@link OfflinePointReader} can read. */
          @Override
          protected ByteSequencesReader getReader(ChecksumIndexInput in, String name) throws IOException {
            return new ByteSequencesReader(in, name) {
              @Override
              public boolean read(BytesRefBuilder ref) throws IOException {
                if (in.getFilePointer() >= end) {
                  return false;
                }
                ref.grow(bytesPerDoc);
                in.readBytes(ref.bytes(), 0, bytesPerDoc);
                ref.setLength(bytesPerDoc);
                return true;
              }
            };
          }
        };
      sorter.sort(tempInput.getName());

      assert lastWriter[0] != null;

      return new OfflinePointWriter(tempDir, lastWriter[0], packedBytesLength, pointCount, longOrds, singleValuePerDoc);
    }
  }

