  @Override
  public void flush(SegmentWriteState state) throws IOException {

    Map<String,DocFieldConsumerPerField> childFields = new HashMap<String,DocFieldConsumerPerField>();
    Collection<DocFieldConsumerPerField> fields = fields();
    for (DocFieldConsumerPerField f : fields) {
      childFields.put(f.getFieldInfo().name, f);
    }

    SimpleDVConsumer dvConsumer = null;

    for(int i=0;i<fieldHash.length;i++) {
      DocFieldProcessorPerField field = fieldHash[i];
      while(field != null) {
        // nocommit maybe we should sort by .... somethign?
        // field name?  field number?  else this is hash order!!
        if (field.bytesDVWriter != null || field.numberDVWriter != null || field.sortedBytesDVWriter != null) {

          if (dvConsumer == null) {
            SimpleDocValuesFormat fmt =  state.segmentInfo.getCodec().simpleDocValuesFormat();
            // nocommit once we make
            // Codec.simpleDocValuesFormat abstract, change
            // this to assert dvConsumer != null!
            if (fmt == null) {
              field = field.next;
              continue;
            }

            dvConsumer = fmt.fieldsConsumer(state);
          }

          if (field.bytesDVWriter != null) {
            field.bytesDVWriter.flush(field.fieldInfo, state,
                                      dvConsumer.addBinaryField(field.fieldInfo,
                                                                field.bytesDVWriter.fixedLength >= 0,
                                                                field.bytesDVWriter.maxLength));
            // nocommit must null it out now else next seg
            // will flush even if no docs had DV...?
          }
          if (field.sortedBytesDVWriter != null) {
            field.sortedBytesDVWriter.flush(field.fieldInfo, state,
                                            dvConsumer.addSortedField(field.fieldInfo,
                                                                      field.sortedBytesDVWriter.hash.size(),
                                                                      field.sortedBytesDVWriter.fixedLength >= 0,
                                                                      field.sortedBytesDVWriter.maxLength));
            // nocommit must null it out now else next seg
            // will flush even if no docs had DV...?
          }
          if (field.numberDVWriter != null) {
            field.numberDVWriter.flush(field.fieldInfo, state,
                                       dvConsumer.addNumericField(field.fieldInfo,
                                                                  field.numberDVWriter.minValue,
                                                                  field.numberDVWriter.maxValue));
            // nocommit must null it out now else next seg
            // will flush even if no docs had DV...?
          }
        }
        field = field.next;
      }
    }

    assert fields.size() == totalFieldCount;


    fieldsWriter.flush(state);
    consumer.flush(childFields, state);

    for (DocValuesConsumerHolder consumer : docValues.values()) {
      consumer.docValuesConsumer.finish(state.segmentInfo.getDocCount());
    }
    
    // close perDocConsumer during flush to ensure all files are flushed due to PerCodec CFS
    IOUtils.close(perDocConsumer);

    // Important to save after asking consumer to flush so
    // consumer can alter the FieldInfo* if necessary.  EG,
    // FreqProxTermsWriter does this with
    // FieldInfo.storePayload.
    FieldInfosWriter infosWriter = codec.fieldInfosFormat().getFieldInfosWriter();
    infosWriter.write(state.directory, state.segmentInfo.name, state.fieldInfos, IOContext.DEFAULT);
  }

