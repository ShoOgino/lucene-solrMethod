  private long applyTermDeletes(BufferedUpdatesStream.SegmentState[] segStates) throws IOException {

    if (deleteTerms.size() == 0) {
      return 0;
    }

    // We apply segment-private deletes on flush:
    assert privateSegment == null;

    try {
      long startNS = System.nanoTime();

      long delCount = 0;

      for (BufferedUpdatesStream.SegmentState segState : segStates) {
        assert segState.delGen != delGen: "segState.delGen=" + segState.delGen + " vs this.gen=" + delGen;
        if (segState.delGen > delGen) {
          // our deletes don't apply to this segment
          continue;
        }
        if (segState.rld.refCount() == 1) {
          // This means we are the only remaining reference to this segment, meaning
          // it was merged away while we were running, so we can safely skip running
          // because we will run on the newly merged segment next:
          continue;
        }

        FieldTermIterator iter = deleteTerms.iterator();

        BytesRef delTerm;
        String field = null;
        TermsEnum termsEnum = null;
        BytesRef readerTerm = null;
        PostingsEnum postingsEnum = null;
        while ((delTerm = iter.next()) != null) {

          if (iter.field() != field) {
            // field changed
            field = iter.field();
            Terms terms = segState.reader.terms(field);
            if (terms != null) {
              termsEnum = terms.iterator();
              readerTerm = termsEnum.next();
            } else {
              termsEnum = null;
            }
          }

          if (termsEnum != null) {
            int cmp = delTerm.compareTo(readerTerm);
            if (cmp < 0) {
              // TODO: can we advance across del terms here?
              // move to next del term
              continue;
            } else if (cmp == 0) {
              // fall through
            } else if (cmp > 0) {
              TermsEnum.SeekStatus status = termsEnum.seekCeil(delTerm);
              if (status == TermsEnum.SeekStatus.FOUND) {
                // fall through
              } else if (status == TermsEnum.SeekStatus.NOT_FOUND) {
                readerTerm = termsEnum.term();
                continue;
              } else {
                // TODO: can we advance to next field in deleted terms?
                // no more terms in this segment
                termsEnum = null;
                continue;
              }
            }

            // we don't need term frequencies for this
            postingsEnum = termsEnum.postings(postingsEnum, PostingsEnum.NONE);

            assert postingsEnum != null;

            int docID;
            while ((docID = postingsEnum.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {

              // NOTE: there is no limit check on the docID
              // when deleting by Term (unlike by Query)
              // because on flush we apply all Term deletes to
              // each segment.  So all Term deleting here is
              // against prior segments:
              if (segState.rld.delete(docID)) {
                delCount++;
              }
            }
          }
        }
      }

      if (infoStream.isEnabled("BD")) {
        infoStream.message("BD",
                           String.format(Locale.ROOT, "applyTermDeletes took %.2f msec for %d segments and %d del terms; %d new deletions",
                                         (System.nanoTime()-startNS)/1000000.,
                                         segStates.length,
                                         deleteTerms.size(),
                                         delCount));
      }

      return delCount;

    } catch (Throwable t) {
      throw IOUtils.rethrowAlways(t);
    }
  }

