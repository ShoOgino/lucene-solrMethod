  private long prepareCommitInternal() throws IOException {
    startCommitTime = System.nanoTime();
    synchronized(commitLock) {
      ensureOpen(false);
      if (infoStream.isEnabled("IW")) {
        infoStream.message("IW", "prepareCommit: flush");
        infoStream.message("IW", "  index before flush " + segString());
      }

      if (tragedy.get() != null) {
        throw new IllegalStateException("this writer hit an unrecoverable error; cannot commit", tragedy.get());
      }

      if (pendingCommit != null) {
        throw new IllegalStateException("prepareCommit was already called with no corresponding call to commit");
      }

      doBeforeFlush();
      testPoint("startDoFlush");
      SegmentInfos toCommit = null;
      boolean anyChanges = false;
      long seqNo;
      MergePolicy.MergeSpecification onCommitMerges = null;
      AtomicBoolean includeInCommit = new AtomicBoolean(true);
      final long maxCommitMergeWaitSeconds = config.getMaxCommitMergeWaitSeconds();
      // This is copied from doFlush, except it's modified to
      // clone & incRef the flushed SegmentInfos inside the
      // sync block:

      try {

        synchronized (fullFlushLock) {
          boolean flushSuccess = false;
          boolean success = false;
          try {
            seqNo = docWriter.flushAllThreads();
            if (seqNo < 0) {
              anyChanges = true;
              seqNo = -seqNo;
            }
            if (anyChanges == false) {
              // prevent double increment since docWriter#doFlush increments the flushcount
              // if we flushed anything.
              flushCount.incrementAndGet();
            }
            publishFlushedSegments(true);
            // cannot pass triggerMerges=true here else it can lead to deadlock:
            processEvents(false);
            
            flushSuccess = true;

            applyAllDeletesAndUpdates();
            synchronized(this) {
              writeReaderPool(true);
              if (changeCount.get() != lastCommitChangeCount) {
                // There are changes to commit, so we will write a new segments_N in startCommit.
                // The act of committing is itself an NRT-visible change (an NRT reader that was
                // just opened before this should see it on reopen) so we increment changeCount
                // and segments version so a future NRT reopen will see the change:
                changeCount.incrementAndGet();
                segmentInfos.changed();
              }

              if (commitUserData != null) {
                Map<String,String> userData = new HashMap<>();
                for(Map.Entry<String,String> ent : commitUserData) {
                  userData.put(ent.getKey(), ent.getValue());
                }
                segmentInfos.setUserData(userData, false);
              }

              // Must clone the segmentInfos while we still
              // hold fullFlushLock and while sync'd so that
              // no partial changes (eg a delete w/o
              // corresponding add from an updateDocument) can
              // sneak into the commit point:
              toCommit = segmentInfos.clone();

              if (anyChanges && maxCommitMergeWaitSeconds > 0) {
                SegmentInfos committingSegmentInfos = toCommit;
                onCommitMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->
                    new MergePolicy.OneMerge(toWrap.segments) {
                      @Override
                      public void mergeFinished(boolean committed) throws IOException {
                        assert Thread.holdsLock(IndexWriter.this);
                        if (committed && includeInCommit.get()) {
                          deleter.incRef(info.files());
                          Set<String> mergedSegmentNames = new HashSet<>();
                          for (SegmentCommitInfo sci : segments) {
                            mergedSegmentNames.add(sci.info.name);
                          }
                          List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();
                          for (SegmentCommitInfo sci : committingSegmentInfos) {
                            if (mergedSegmentNames.contains(sci.info.name)) {
                              toCommitMergedAwaySegments.add(sci);
                              deleter.decRef(sci.files());
                            }
                          }
                          // Construct a OneMerge that applies to toCommit
                          MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);
                          applicableMerge.info = info.clone();
                          long segmentCounter = Long.parseLong(info.info.name.substring(1), Character.MAX_RADIX);
                          committingSegmentInfos.counter = Math.max(committingSegmentInfos.counter, segmentCounter + 1);
                          committingSegmentInfos.applyMergeChanges(applicableMerge, false);
                        }
                        toWrap.mergeFinished(committed);
                        super.mergeFinished(committed);
                      }

                      @Override
                      public CodecReader wrapForMerge(CodecReader reader) throws IOException {
                        return toWrap.wrapForMerge(reader);
                      }
                    }
                ), MergeTrigger.COMMIT, UNBOUNDED_MAX_MERGE_SEGMENTS);
              }

              pendingCommitChangeCount = changeCount.get();

              // This protects the segmentInfos we are now going
              // to commit.  This is important in case, eg, while
              // we are trying to sync all referenced files, a
              // merge completes which would otherwise have
              // removed the files we are now syncing.    
              deleter.incRef(toCommit.files(false));
            }
            success = true;
          } finally {
            if (!success) {
              if (infoStream.isEnabled("IW")) {
                infoStream.message("IW", "hit exception during prepareCommit");
              }
            }
            assert Thread.holdsLock(fullFlushLock);
            // Done: finish the full flush!
            docWriter.finishFullFlush(flushSuccess);
            doAfterFlush();
          }
        }
      } catch (VirtualMachineError tragedy) {
        tragicEvent(tragedy, "prepareCommit");
        throw tragedy;
      } finally {
        maybeCloseOnTragicEvent();
      }

      if (onCommitMerges != null) {
        mergeScheduler.merge(mergeSource, MergeTrigger.COMMIT);
        onCommitMerges.await(maxCommitMergeWaitSeconds, TimeUnit.SECONDS);
        synchronized (this) {
          // we need to call this under lock since mergeFinished above is also called under the IW lock
          includeInCommit.set(false);
        }
      }
      filesToCommit = toCommit.files(false);
      try {
        if (anyChanges) {
          maybeMerge.set(true);
        }
        startCommit(toCommit);
        if (pendingCommit == null) {
          return -1;
        } else {
          return seqNo;
        }
      } catch (Throwable t) {
        synchronized (this) {
          if (filesToCommit != null) {
            try {
              deleter.decRef(filesToCommit);
            } catch (Throwable t1) {
              t.addSuppressed(t1);
            } finally {
              filesToCommit = null;
            }
          }
        }
        throw t;
      }
    }
  }

