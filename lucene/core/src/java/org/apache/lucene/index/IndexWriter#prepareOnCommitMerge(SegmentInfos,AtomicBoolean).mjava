  /**
   * This optimization allows a commit to wait for merges on smallish segments to
   * reduce the eventual number of tiny segments in the commit point.  We wrap a {@code OneMerge} to
   * update the {@code committingSegmentInfos} once the merge has finished.  We replace the source segments
   * in the SIS that we are going to commit with the freshly merged segment, but ignore all deletions and updates
   * that are made to documents in the merged segment while it was merging.  The updates that are made do not belong to
   * the point-in-time commit point and should therefore not be included. See the clone call in {@code onMergeComplete}
   * below.  We also ensure that we pull the merge readers while holding {@code IndexWriter}'s lock.  Otherwise
   * we could see concurrent deletions/updates applied that do not belong to the segment.
   */
  private MergePolicy.MergeSpecification prepareOnCommitMerge(SegmentInfos committingSegmentInfos, AtomicBoolean includeInCommit) throws IOException {
    assert Thread.holdsLock(this);
    MergePolicy.MergeSpecification onCommitMerges = updatePendingMerges(new OneMergeWrappingMergePolicy(config.getMergePolicy(), toWrap ->
        new MergePolicy.OneMerge(toWrap.segments) {
          SegmentCommitInfo origInfo;
          AtomicBoolean onlyOnce = new AtomicBoolean(false);

          @Override
          public void mergeFinished(boolean committed, boolean segmentDropped) throws IOException {
            assert Thread.holdsLock(IndexWriter.this);

            // includedInCommit will be set (above, by our caller) to false if the allowed max wall clock
            // time (IWC.getMaxCommitMergeWaitMillis()) has elapsed, which means we did not make the timeout
            // and will not commit our merge to the to-be-commited SegmentInfos
            
            if (segmentDropped == false
                && committed
                && includeInCommit.get()) {

              if (infoStream.isEnabled("IW")) {
                infoStream.message("IW", "now apply merge during commit: " + toWrap.segString());
              }

              // make sure onMergeComplete really was called:
              assert origInfo != null;

              deleter.incRef(origInfo.files());
              Set<String> mergedSegmentNames = new HashSet<>();
              for (SegmentCommitInfo sci : segments) {
                mergedSegmentNames.add(sci.info.name);
              }
              List<SegmentCommitInfo> toCommitMergedAwaySegments = new ArrayList<>();
              for (SegmentCommitInfo sci : committingSegmentInfos) {
                if (mergedSegmentNames.contains(sci.info.name)) {
                  toCommitMergedAwaySegments.add(sci);
                  deleter.decRef(sci.files());
                }
              }
              // Construct a OneMerge that applies to toCommit
              MergePolicy.OneMerge applicableMerge = new MergePolicy.OneMerge(toCommitMergedAwaySegments);
              applicableMerge.info = origInfo;
              long segmentCounter = Long.parseLong(origInfo.info.name.substring(1), Character.MAX_RADIX);
              committingSegmentInfos.counter = Math.max(committingSegmentInfos.counter, segmentCounter + 1);
              committingSegmentInfos.applyMergeChanges(applicableMerge, false);
            } else {
              if (infoStream.isEnabled("IW")) {
                infoStream.message("IW", "skip apply merge during commit: " + toWrap.segString());
              }
            }
            toWrap.mergeFinished(committed, false);
            super.mergeFinished(committed, segmentDropped);
          }

          @Override
          void onMergeComplete() {
            // clone the target info to make sure we have the original info without the updated del and update gens
            origInfo = info.clone();
          }

          @Override
          void initMergeReaders(IOUtils.IOFunction<SegmentCommitInfo, MergePolicy.MergeReader> readerFactory) throws IOException {
            if (onlyOnce.compareAndSet(false, true)) {
              // we do this only once below to pull readers as point in time readers with respect to the commit point
              // we try to update
              super.initMergeReaders(readerFactory);
            }
          }

          @Override
          public CodecReader wrapForMerge(CodecReader reader) throws IOException {
            return toWrap.wrapForMerge(reader); // must delegate
          }
        }
    ), MergeTrigger.COMMIT, UNBOUNDED_MAX_MERGE_SEGMENTS);
    if (onCommitMerges != null) {
      boolean closeReaders = true;
      try {
        for (MergePolicy.OneMerge merge : onCommitMerges.merges) {
          IOContext context = new IOContext(merge.getStoreMergeInfo());
          merge.initMergeReaders(
              sci -> {
                final ReadersAndUpdates rld = getPooledInstance(sci, true);
                // calling setIsMerging is important since it causes the RaU to record all DV updates
                // in a separate map in order to be applied to the merged segment after it's done
                rld.setIsMerging();
                return rld.getReaderForMerge(context);
              });
        }
        closeReaders = false;
      } finally {
        if (closeReaders) {
          IOUtils.applyToAll(onCommitMerges.merges, merge -> {
            // that merge is broken we need to clean up after it - it's fine we still have the IW lock to do this
            boolean removed = pendingMerges.remove(merge);
            assert removed: "merge should be pending but isn't: " + merge.segString();
            abortOneMerge(merge);
            mergeFinish(merge);
          });
        }
      }
    }
    return onCommitMerges;
  }

