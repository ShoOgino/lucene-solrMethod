  /**
   * Test term vectors for a segment.
   */
  private Status.TermVectorStatus testTermVectors(SegmentInfo info, SegmentReader reader, NumberFormat format) {
    final Status.TermVectorStatus status = new Status.TermVectorStatus();
    
    // TODO: in theory we could test that term vectors have
    // same terms/pos/offsets as the postings, but it'd be
    // very slow...

    try {
      if (infoStream != null) {
        infoStream.print("    test: term vectors........");
      }

      // TODO: maybe we can factor out testTermIndex and reuse here?
      DocsEnum docs = null;
      DocsAndPositionsEnum postings = null;

      // Only used if crossCheckTermVectors is true:
      DocsEnum postingsDocs = null;
      DocsAndPositionsEnum postingsPostings = null;

      final Bits liveDocs = reader.getLiveDocs();

      final Fields postingsFields;
      // TODO: testTermsIndex
      if (crossCheckTermVectors) {
        postingsFields = reader.fields();
      } else {
        postingsFields = null;
      }

      TermsEnum termsEnum = null;
      TermsEnum postingsTermsEnum = null;

      for (int j = 0; j < info.docCount; ++j) {
        if (liveDocs == null || liveDocs.get(j)) {
          status.docCount++;
          Fields tfv = reader.getTermVectors(j);
          if (tfv != null) {
            int tfvComputedFieldCount = 0;
            long tfvComputedTermCount = 0;

            FieldsEnum fieldsEnum = tfv.iterator();
            String field = null;
            String lastField = null;
            while((field = fieldsEnum.next()) != null) {
              status.totVectors++;
              tfvComputedFieldCount++;

              if (lastField == null) {
                lastField = field;
              } else if (lastField.compareTo(field) > 0) {
                throw new RuntimeException("vector fields are out of order: lastField=" + lastField + " field=" + field + " doc=" + j);
              }
              
              Terms terms = tfv.terms(field);
              termsEnum = terms.iterator(termsEnum);

              if (crossCheckTermVectors) {
                Terms postingsTerms = postingsFields.terms(field);
                if (postingsTerms == null) {
                  throw new RuntimeException("vector field=" + field + " does not exist in postings; doc=" + j);
                }
                postingsTermsEnum = postingsTerms.iterator(postingsTermsEnum);
              } else {
                postingsTermsEnum = null;
              }
              
              long tfvComputedTermCountForField = 0;
              long tfvComputedSumTotalTermFreq = 0;
              
              BytesRef lastTerm = null;
              Comparator<BytesRef> termComp = terms.getComparator();
              BytesRef term = null;
              while ((term = termsEnum.next()) != null) {
                tfvComputedTermCountForField++;
                
                // make sure terms arrive in order according to
                // the comp
                if (lastTerm == null) {
                  lastTerm = BytesRef.deepCopyOf(term);
                } else {
                  if (termComp.compare(lastTerm, term) >= 0) {
                    throw new RuntimeException("vector terms out of order for doc " + j + ": lastTerm=" + lastTerm + " term=" + term);
                  }
                  lastTerm.copyBytes(term);
                }
                
                if (termsEnum.docFreq() != 1) {
                  throw new RuntimeException("vector docFreq for doc " + j + ", field " + field + ", term" + term + " != 1");
                }
                
                long totalTermFreq = termsEnum.totalTermFreq();
                
                if (totalTermFreq != -1 && totalTermFreq <= 0) {
                  throw new RuntimeException("totalTermFreq: " + totalTermFreq + " is out of bounds");
                }

                final boolean hasPositions;
                final boolean hasOffsets;
                final boolean hasFreqs;

                // TODO: really we need a reflection/query
                // API so we can just ask what was indexed
                // instead of "probing"...

                // Try offsets:
                postings = termsEnum.docsAndPositions(null, postings, true);
                if (postings == null) {
                  hasOffsets = false;
                  // Try only positions:
                  postings = termsEnum.docsAndPositions(null, postings, false);
                  if (postings == null) {
                    hasPositions = false;
                    // Try docIDs & freqs:
                    docs = termsEnum.docs(null, docs, true);
                    if (docs == null) {
                      // OK, only docIDs:
                      hasFreqs = false;
                      docs = termsEnum.docs(null, docs, false);
                    } else {
                      hasFreqs = true;
                    }
                  } else {
                    hasPositions = true;
                    hasFreqs = true;
                  }
                } else {
                  hasOffsets = true;
                  // NOTE: may be a lie... but we accept -1 below
                  hasPositions = true;
                  hasFreqs = true;
                }

                final DocsEnum docs2;
                if (hasPositions || hasOffsets) {
                  assert postings != null;
                  docs2 = postings;
                } else {
                  assert docs != null;
                  docs2 = docs;
                }

                final DocsEnum postingsDocs2;
                final boolean postingsHasFreq;
                if (crossCheckTermVectors) {
                  if (!postingsTermsEnum.seekExact(term, true)) {
                    throw new RuntimeException("vector term=" + term + " field=" + field + " does not exist in postings; doc=" + j);
                  }
                  postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, true);
                  if (postingsPostings == null) {
                    // Term vectors were indexed w/ offsets but postings were not
                    postingsPostings = postingsTermsEnum.docsAndPositions(null, postingsPostings, false);
                    if (postingsPostings == null) {
                      postingsDocs = postingsTermsEnum.docs(null, postingsDocs, true);
                      if (postingsDocs == null) {
                        postingsHasFreq = false;
                        postingsDocs = postingsTermsEnum.docs(null, postingsDocs, false);
                        if (postingsDocs == null) {
                          throw new RuntimeException("vector term=" + term + " field=" + field + " does not exist in postings; doc=" + j);
                        }
                      } else {
                        postingsHasFreq = true;
                      }
                    } else {
                      postingsHasFreq = true;
                    }
                  } else {
                    postingsHasFreq = true;
                  }

                  if (postingsPostings != null) {
                    postingsDocs2 = postingsPostings;
                  } else {
                    postingsDocs2 = postingsDocs;
                  }
                  
                  final int advanceDoc = postingsDocs2.advance(j);
                  if (advanceDoc != j) {
                    throw new RuntimeException("vector term=" + term + " field=" + field + ": doc=" + j + " was not found in postings (got: " + advanceDoc + ")");
                  }
                } else {
                  postingsDocs2 = null;
                  postingsHasFreq = false;
                }

                final int doc = docs2.nextDoc();
                  
                if (doc != 0) {
                  throw new RuntimeException("vector for doc " + j + " didn't return docID=0: got docID=" + doc);
                }

                if (hasFreqs) {
                  final int tf = docs2.freq();
                  if (tf <= 0) {
                    throw new RuntimeException("vector freq " + tf + " is out of bounds");
                  }
                  if (totalTermFreq != -1 && totalTermFreq != tf) {
                    throw new RuntimeException("vector totalTermFreq " + totalTermFreq + " != tf " + tf);
                  }
                  if (crossCheckTermVectors && postingsHasFreq) {
                    if (postingsDocs2.freq() != tf) {
                      throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": freq=" + tf + " differs from postings freq=" + postingsDocs2.freq());
                    }
                  }
                  tfvComputedSumTotalTermFreq += tf;
                
                  if (hasPositions || hasOffsets) {
                    int lastPosition = -1;
                    //int lastStartOffset = -1;
                    for (int i = 0; i < tf; i++) {
                      int pos = postings.nextPosition();
                      if (hasPositions) {
                        if (pos != -1 && pos < 0) {
                          throw new RuntimeException("vector position " + pos + " is out of bounds");
                        }
                        if (pos < lastPosition) {
                          throw new RuntimeException("vector position " + pos + " < lastPos " + lastPosition);
                        }
                    
                        lastPosition = pos;
                      }

                      if (crossCheckTermVectors && postingsPostings != null) {
                        int postingsPos = postingsPostings.nextPosition();
                        if (pos != -1 && postingsPos != -1 && pos != postingsPos) {
                          throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": pos=" + pos + " differs from postings pos=" + postingsPos);
                        }
                      }

                      if (hasOffsets) {
                        // Call the methods to at least make
                        // sure they don't throw exc:
                        final int startOffset = postings.startOffset();
                        final int endOffset = postings.endOffset();
                        // TODO: these are too anal...?
                        /*
                        if (endOffset < startOffset) {
                          throw new RuntimeException("vector startOffset=" + startOffset + " is > endOffset=" + endOffset);
                        }
                        if (startOffset < lastStartOffset) {
                          throw new RuntimeException("vector startOffset=" + startOffset + " is < prior startOffset=" + lastStartOffset);
                        }
                        lastStartOffset = startOffset;
                        */

                        if (crossCheckTermVectors && postingsPostings != null) {
                          final int postingsStartOffset = postingsPostings.startOffset();

                          final int postingsEndOffset = postingsPostings.endOffset();
                          if (startOffset != -1 && postingsStartOffset != -1 && startOffset != postingsStartOffset) {
                            throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": startOffset=" + startOffset + " differs from postings startOffset=" + postingsStartOffset);
                          }
                          if (endOffset != -1 && postingsEndOffset != -1 && endOffset != postingsEndOffset) {
                            throw new RuntimeException("vector term=" + term + " field=" + field + " doc=" + j + ": endOffset=" + endOffset + " differs from postings endOffset=" + postingsEndOffset);
                          }
                        }
                      }
                    }
                  }
                }
                  
                if (docs2.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {
                  throw new RuntimeException("vector for doc " + j + " references multiple documents!");
                }
              }
              
              long uniqueTermCount = terms.getUniqueTermCount();
              if (uniqueTermCount != -1 && uniqueTermCount != tfvComputedTermCountForField) {
                throw new RuntimeException("vector term count for doc " + j + ", field " + field + " = " + uniqueTermCount + " != recomputed term count=" + tfvComputedTermCountForField);
              }
              
              int docCount = terms.getDocCount();
              if (docCount != -1 && docCount != 1) {
                throw new RuntimeException("vector doc count for doc " + j + ", field " + field + " = " + docCount + " != 1");
              }
              
              long sumDocFreq = terms.getSumDocFreq();
              if (sumDocFreq != -1 && sumDocFreq != tfvComputedTermCountForField) {
                throw new RuntimeException("vector postings count for doc " + j + ", field " + field + " = " + sumDocFreq + " != recomputed postings count=" + tfvComputedTermCountForField);
              }
              
              long sumTotalTermFreq = terms.getSumTotalTermFreq();
              if (sumTotalTermFreq != -1 && sumTotalTermFreq != tfvComputedSumTotalTermFreq) {
                throw new RuntimeException("vector sumTotalTermFreq for doc " + j + ", field " + field + " = " + sumTotalTermFreq + " != recomputed sumTotalTermFreq=" + tfvComputedSumTotalTermFreq);
              }
              
              tfvComputedTermCount += tfvComputedTermCountForField;
            }
            
            int tfvUniqueFieldCount = tfv.getUniqueFieldCount();
            if (tfvUniqueFieldCount != -1 && tfvUniqueFieldCount != tfvComputedFieldCount) {
              throw new RuntimeException("vector field count for doc " + j + "=" + tfvUniqueFieldCount + " != recomputed uniqueFieldCount=" + tfvComputedFieldCount);
            }
            
            long tfvUniqueTermCount = tfv.getUniqueTermCount();
            if (tfvUniqueTermCount != -1 && tfvUniqueTermCount != tfvComputedTermCount) {
              throw new RuntimeException("vector term count for doc " + j + "=" + tfvUniqueTermCount + " != recomputed uniqueTermCount=" + tfvComputedTermCount);
            }
          }
        }
      }
      
      msg("OK [" + status.totVectors + " total vector count; avg " + 
          format.format((((float) status.totVectors) / status.docCount)) + " term/freq vector fields per doc]");
    } catch (Throwable e) {
      msg("ERROR [" + String.valueOf(e.getMessage()) + "]");
      status.error = e;
      if (infoStream != null) {
        e.printStackTrace(infoStream);
      }
    }
    
    return status;
  }

