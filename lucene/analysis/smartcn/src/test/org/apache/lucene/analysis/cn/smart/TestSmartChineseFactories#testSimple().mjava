  /** Test showing the behavior with whitespace */
  public void testSimple() throws Exception {
    Reader reader = new StringReader("我购买了道具和服装。");
    TokenStream stream = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
    SmartChineseWordTokenFilterFactory factory = new SmartChineseWordTokenFilterFactory(new HashMap<String,String>());
    stream = factory.create(stream);
    // TODO: fix smart chinese to not emit punctuation tokens
    // at the moment: you have to clean up with WDF, or use the stoplist, etc
    assertTokenStreamContents(stream, 
       new String[] { "我", "购买", "了", "道具", "和", "服装", "," });
  }

