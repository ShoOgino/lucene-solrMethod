  /**
   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix
   * and dictionary files.
   * You have to close the provided InputStreams yourself.
   *
   * @param affix InputStream for reading the hunspell affix file (won't be closed).
   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).
   * @throws IOException Can be thrown while reading from the InputStreams
   * @throws ParseException Can be thrown if the content of the files does not meet expected formats
   */
  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {
    this.ignoreCase = ignoreCase;
    this.needsInputCleaning = ignoreCase;
    this.needsOutputCleaning = false; // set if we have an OCONV
    // TODO: we really need to probably buffer this on disk since so many newer dictionaries
    // (en_GB, hu_HU, etc) now have tons of AM lines (morph metadata) etc before they finally declare 
    // their encoding... but for now this large buffer is a workaround
    BufferedInputStream buffered = new BufferedInputStream(affix, 65536);
    buffered.mark(65536);
    String encoding = getDictionaryEncoding(buffered);
    buffered.reset();
    CharsetDecoder decoder = getJavaEncoding(encoding);
    readAffixFile(buffered, decoder);
    flagLookup.add(new BytesRef()); // no flags -> ord 0
    stripLookup.add(new BytesRef()); // no strip -> ord 0
    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();
    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);
    readDictionaryFiles(dictionaries, decoder, b);
    words = b.finish();
  }

