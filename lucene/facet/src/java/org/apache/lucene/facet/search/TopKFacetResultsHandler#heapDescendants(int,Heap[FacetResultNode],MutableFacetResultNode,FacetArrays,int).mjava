  /**
   * Finds the top K descendants of ordinal, which are at most facetRequest.getDepth()
   * deeper than facetRequest.getCategoryPath (whose ordinal is input parameter ordinal). 
   * Candidates are restricted to current "counting list" and current "partition",
   * they join the overall priority queue pq of size K.  
   * @return total number of descendants considered here by pq, excluding ordinal itself.
   */
  private int heapDescendants(int ordinal, Heap<FacetResultNode> pq,
      MutableFacetResultNode parentResultNode, FacetArrays facetArrays, int offset) throws IOException {
    int partitionSize = facetArrays.getArraysLength();
    int endOffset = offset + partitionSize;
    ParallelTaxonomyArrays childrenArray = taxonomyReader.getParallelTaxonomyArrays();
    int[] children = childrenArray.children();
    int[] siblings = childrenArray.siblings();
    FacetResultNode reusable = null;
    int localDepth = 0;
    int depth = facetRequest.getDepth();
    int[] ordinalStack = new int[2+Math.min(Short.MAX_VALUE, depth)];
    int childrenCounter = 0;
    
    int tosOrdinal; // top of stack element
    
    int yc = children[ordinal];
    while (yc >= endOffset) {
      yc = siblings[yc];
    }
    // make use of the fact that TaxonomyReader.INVALID_ORDINAL == -1, < endOffset
    // and it, too, can stop the loop.
    ordinalStack[++localDepth] = yc;
    
    /*
     * stack holds input parameter ordinal in position 0.
     * Other elements are < endoffset.
     * Only top of stack can be TaxonomyReader.INVALID_ORDINAL, and this if and only if
     * the element below it exhausted all its children: has them all processed.
     * 
     * stack elements are processed (counted and accumulated) only if they 
     * belong to current partition (between offset and endoffset) and first time
     * they are on top of stack 
     * 
     * loop as long as stack is not empty of elements other than input ordinal, or for a little while -- it sibling
     */
    while (localDepth > 0) {
      tosOrdinal = ordinalStack[localDepth];
      if (tosOrdinal == TaxonomyReader.INVALID_ORDINAL) {
        // element below tos has all its children, and itself, all processed
        // need to proceed to its sibling
        localDepth--;
        // change element now on top of stack to its sibling.
        ordinalStack[localDepth] = siblings[ordinalStack[localDepth]];
        continue;
      }
      // top of stack is not invalid, this is the first time we see it on top of stack.
      // collect it, if belongs to current partition, and then push its kids on itself, if applicable
      if (tosOrdinal >= offset) { // tosOrdinal resides in current partition
        int relativeOrdinal = tosOrdinal % partitionSize;
        double value = facetRequest.getValueOf(facetArrays, relativeOrdinal);
        if (value != 0 && !Double.isNaN(value)) {
          // Count current ordinal -- the TOS
          if (reusable == null) {
            reusable = new MutableFacetResultNode(tosOrdinal, value);
          } else {
            // it is safe to cast since reusable was created here.
            ((MutableFacetResultNode)reusable).reset(tosOrdinal, value);
          }
          ++childrenCounter;
          reusable = pq.insertWithOverflow(reusable);
          if (reusable != null) {
            // TODO (Facet): is other logic (not add) needed, per aggregator?
            parentResultNode.increaseResidue(reusable.getValue());
          }
        }
      }
      if (localDepth < depth) {
        // push kid of current tos
        yc = children[tosOrdinal];
        while (yc >= endOffset) {
          yc = siblings[yc];
        }
        ordinalStack[++localDepth] = yc;
      } else { // localDepth == depth; current tos exhausted its possible children, mark this by pushing INVALID_ORDINAL
        ordinalStack[++localDepth] = TaxonomyReader.INVALID_ORDINAL;
      }
    } // endof while stack is not empty
    
    return childrenCounter; // we're done
  }

