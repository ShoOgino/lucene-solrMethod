  @Override
  public List<FacetResult> accumulate(ScoredDocIDs docids) throws IOException {
    // Replacing the original searchParams with the over-sampled (and without statistics-compute)
    FacetSearchParams original = delegee.searchParams;
    boolean shouldOversample = sampler.samplingParams.shouldOverSample();
   
    if (shouldOversample) {
      delegee.searchParams = sampler.overSampledSearchParams(original);
    }
    
    SampleResult sampleSet = sampler.getSampleSet(docids);

    List<FacetResult> sampleRes = delegee.accumulate(sampleSet.docids);

    List<FacetResult> results = new ArrayList<FacetResult>();
    SampleFixer sampleFixer = sampler.samplingParams.getSampleFixer();
    
    for (FacetResult fres : sampleRes) {
      // for sure fres is not null because this is guaranteed by the delegee.
      FacetRequest fr = fres.getFacetRequest();
      PartitionsFacetResultsHandler frh = createFacetResultsHandler(fr, createOrdinalValueResolver(fr));
      if (sampleFixer != null) {
        // fix the result of current request
        sampleFixer.fixResult(docids, fres, sampleSet.actualSampleRatio); 
        fres = frh.rearrangeFacetResult(fres); // let delegee's handler do any
      }
      
      if (shouldOversample) {
        // Using the sampler to trim the extra (over-sampled) results
        fres = sampler.trimResult(fres);
      }
      
      // final labeling if allowed (because labeling is a costly operation)
      if (fres.getFacetResultNode().ordinal == TaxonomyReader.INVALID_ORDINAL) {
        // category does not exist, add an empty result
        results.add(emptyResult(fres.getFacetResultNode().ordinal, fr));
      } else {
        frh.labelResult(fres);
        results.add(fres);
      }
    }

    if (shouldOversample) {
      delegee.searchParams = original; // Back to original params
    }
    
    return results; 
  }

