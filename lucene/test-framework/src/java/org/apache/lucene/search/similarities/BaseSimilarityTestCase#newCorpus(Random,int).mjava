  /**
   * returns a random corpus that is at least possible given
   * the norm value for a single document.
   */
  static CollectionStatistics newCorpus(Random random, int norm) {
    // lower bound of tokens in the collection (you produced this norm somehow)
    final int lowerBound;
    if (norm == 0) {
      // norms are omitted, but there must have been at least one token to produce that norm
      lowerBound = 1;    
    } else {
      // minimum value that would decode to such a norm
      lowerBound = SmallFloat.byte4ToInt((byte) norm);
    }
    final long maxDoc;
    if (random.nextBoolean()) {
      // small collection
      maxDoc = TestUtil.nextLong(random, 1, 100000);
    } else {
      // yuge collection
      maxDoc = TestUtil.nextLong(random, 1, MAXDOC_FORTESTING);
    }
    final long docCount;
    if (random.nextBoolean()) {
      // sparse field
      docCount = TestUtil.nextLong(random, 1, maxDoc);
    } else {
      // fully populated
      docCount = maxDoc;
    }
    // random docsize: but can't require docs to have > 2B tokens
    long upperBound;
    try {
      upperBound = Math.min(MAXTOKENS_FORTESTING, Math.multiplyExact(docCount, Integer.MAX_VALUE));
    } catch (ArithmeticException overflow) {
      upperBound = MAXTOKENS_FORTESTING;
    }
    final long sumDocFreq;
    if (random.nextBoolean()) {
      // shortest possible docs
      sumDocFreq = docCount;
    } else {
      // random docsize
      sumDocFreq = TestUtil.nextLong(random, docCount, upperBound + 1 - lowerBound);
    }
    final long sumTotalTermFreq;
    switch (random.nextInt(3)) {
      case 0:
        // term frequencies were omitted
        sumTotalTermFreq = sumDocFreq;
        break;
      case 1:
        // no repetition of terms (except to satisfy this norm)
        sumTotalTermFreq = sumDocFreq - 1 + lowerBound;
        break;
      default:
        // random repetition
        assert sumDocFreq - 1 + lowerBound <= upperBound;
        sumTotalTermFreq = TestUtil.nextLong(random, sumDocFreq - 1 + lowerBound, upperBound);
        break;
    }
    return new CollectionStatistics("field", maxDoc, docCount, sumTotalTermFreq, sumDocFreq);
  }

