  private TokenLL[] initTokenBucketsArray() throws IOException {
    // Estimate the number of non-empty positions (number of tokens, excluding same-position synonyms).
    int positionsEstimate;
    if (offsetLength == -1) { // no clue what the char length is.
      // Estimate the number of position slots we need from term stats based on Wikipedia.
      int sumTotalTermFreq = (int) vector.getSumTotalTermFreq();
      if (sumTotalTermFreq == -1) {//unfortunately term vectors seem to not have this stat
        int size = (int) vector.size();
        if (size == -1) {//doesn't happen with term vectors, it seems, but pick a default any way
          size = 128;
        }
        sumTotalTermFreq = (int) (size * 2.4);
      }
      positionsEstimate = (int) (sumTotalTermFreq * 1.5);//less than 1 in 10 docs exceed this
    } else {
      // guess number of token positions by this factor.
      positionsEstimate = (int) (offsetLength / AVG_CHARS_PER_POSITION);
    }
    // apply the load factor.
    return new TokenLL[Math.max(1, (int) (positionsEstimate * loadFactor))];
  }

