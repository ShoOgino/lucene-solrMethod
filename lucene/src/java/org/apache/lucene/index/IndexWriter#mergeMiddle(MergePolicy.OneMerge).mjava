  /** Does the actual (time-consuming) work of the merge,
   *  but without holding synchronized lock on IndexWriter
   *  instance */
  private int mergeMiddle(MergePolicy.OneMerge merge)
    throws CorruptIndexException, IOException {

    merge.checkAborted(directory);

    final String mergedName = merge.info.name;

    int mergedDocCount = 0;

    List<SegmentInfo> sourceSegments = merge.segments;
    
    IOContext context = new IOContext(merge.getMergeInfo());

    final MergeState.CheckAbort checkAbort = new MergeState.CheckAbort(merge, directory);
    SegmentMerger merger = new SegmentMerger(infoStream, directory, config.getTermIndexInterval(), mergedName, checkAbort,
                                             payloadProcessorProvider, merge.info.getFieldInfos(), codec, context);

    if (infoStream.isEnabled("IW")) {
      infoStream.message("IW", "merging " + segString(merge.segments) + " mergeVectors=" + merge.info.getFieldInfos().hasVectors());
    }

    merge.readers = new ArrayList<SegmentReader>();
    merge.readerLiveDocs = new ArrayList<Bits>();

    // This is try/finally to make sure merger's readers are
    // closed:
    boolean success = false;
    try {
      int segUpto = 0;
      while(segUpto < sourceSegments.size()) {

        final SegmentInfo info = sourceSegments.get(segUpto);

        // Hold onto the "live" reader; we will use this to
        // commit merged deletes
        final ReadersAndLiveDocs rld = readerPool.get(info, true);
        final SegmentReader reader = rld.getMergeReader(context);
        assert reader != null;

        // Carefully pull the most recent live docs:
        final Bits liveDocs;
        synchronized(this) {
          // Must sync to ensure BufferedDeletesStream
          // cannot change liveDocs/pendingDeleteCount while
          // we pull a copy:
          liveDocs = rld.getReadOnlyLiveDocs();

          assert rld.verifyDocCounts();

          if (infoStream.isEnabled("IW")) {
            if (rld.pendingDeleteCount != 0) {
              infoStream.message("IW", "seg=" + info + " delCount=" + info.getDelCount() + " pendingDelCount=" + rld.pendingDeleteCount);
            } else if (info.getDelCount() != 0) {
              infoStream.message("IW", "seg=" + info + " delCount=" + info.getDelCount());
            } else {
              infoStream.message("IW", "seg=" + info + " no deletes");
            }
          }
        }
        merge.readerLiveDocs.add(liveDocs);
        merge.readers.add(reader);
        final int delCount = rld.pendingDeleteCount + info.getDelCount();
        assert delCount <= info.docCount;
        if (delCount < info.docCount) {
          merger.add(reader, liveDocs);
        }
        segUpto++;
      }

      merge.checkAborted(directory);

      // This is where all the work happens:
      MergeState mergeState = merger.merge();
      mergedDocCount = merge.info.docCount = mergeState.mergedDocCount;

      // Record which codec was used to write the segment
      merge.info.setCodec(codec);

      if (infoStream.isEnabled("IW")) {
        infoStream.message("IW", "merge codec=" + codec + " docCount=" + mergedDocCount);
      }

      // Very important to do this before opening the reader
      // because codec must know if prox was written for
      // this segment:
      //System.out.println("merger set hasProx=" + merger.hasProx() + " seg=" + merge.info.name);
      boolean useCompoundFile;
      synchronized (this) { // Guard segmentInfos
        useCompoundFile = mergePolicy.useCompoundFile(segmentInfos, merge.info);
      }
      
      if (useCompoundFile) {
        success = false;
        final String compoundFileName = IndexFileNames.segmentFileName(mergedName, "", IndexFileNames.COMPOUND_FILE_EXTENSION);

        try {
          if (infoStream.isEnabled("IW")) {
            infoStream.message("IW", "create compound file " + compoundFileName);
          }
          createCompoundFile(directory, compoundFileName, checkAbort, merge.info, new IOContext(merge.getMergeInfo()));
          success = true;
        } catch (IOException ioe) {
          synchronized(this) {
            if (merge.isAborted()) {
              // This can happen if rollback or close(false)
              // is called -- fall through to logic below to
              // remove the partially created CFS:
            } else {
              handleMergeException(ioe, merge);
            }
          }
        } catch (Throwable t) {
          handleMergeException(t, merge);
        } finally {
          if (!success) {
            if (infoStream.isEnabled("IW")) {
              infoStream.message("IW", "hit exception creating compound file during merge");
            }

            synchronized(this) {
              deleter.deleteFile(compoundFileName);
              deleter.deleteFile(IndexFileNames.segmentFileName(mergedName, "", IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION));
              deleter.deleteNewFiles(merge.info.files());
            }
          }
        }

        success = false;

        synchronized(this) {

          // delete new non cfs files directly: they were never
          // registered with IFD
          deleter.deleteNewFiles(merge.info.files());

          if (merge.isAborted()) {
            if (infoStream.isEnabled("IW")) {
              infoStream.message("IW", "abort merge after building CFS");
            }
            deleter.deleteFile(compoundFileName);
            return 0;
          }
        }

        merge.info.setUseCompoundFile(true);
      }

      if (infoStream.isEnabled("IW")) {
        infoStream.message("IW", String.format("merged segment size=%.3f MB vs estimate=%.3f MB", merge.info.sizeInBytes()/1024./1024., merge.estimatedMergeBytes/1024/1024.));
      }

      final IndexReaderWarmer mergedSegmentWarmer = config.getMergedSegmentWarmer();

      if (poolReaders && mergedSegmentWarmer != null) {
        final ReadersAndLiveDocs rld = readerPool.get(merge.info, true);
        final SegmentReader sr = rld.getReader(IOContext.READ);
        try {
          mergedSegmentWarmer.warm(sr);
        } finally {
          synchronized(this) {
            readerPool.release(sr, false);
          }
        }
      }

      // Force READ context because we merge deletes onto
      // this reader:
      if (!commitMerge(merge)) {
        // commitMerge will return false if this merge was aborted
        return 0;
      }

      success = true;

    } finally {
      // Readers are already closed in commitMerge if we didn't hit
      // an exc:
      if (!success) {
        closeMergeReaders(merge, true);
      }
    }

    return mergedDocCount;
  }

