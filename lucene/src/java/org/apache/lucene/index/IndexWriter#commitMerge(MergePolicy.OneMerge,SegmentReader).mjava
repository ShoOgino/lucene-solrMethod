  synchronized private boolean commitMerge(MergePolicy.OneMerge merge, SegmentReader mergedReader) throws IOException {

    assert testPoint("startCommitMerge");

    if (hitOOM) {
      throw new IllegalStateException("this writer hit an OutOfMemoryError; cannot complete merge");
    }

    if (infoStream != null)
      message("commitMerge: " + merge.segString(directory) + " index=" + segString());

    assert merge.registerDone;

    // If merge was explicitly aborted, or, if rollback() or
    // rollbackTransaction() had been called since our merge
    // started (which results in an unqualified
    // deleter.refresh() call that will remove any index
    // file that current segments does not reference), we
    // abort this merge
    if (merge.isAborted()) {
      if (infoStream != null)
        message("commitMerge: skipping merge " + merge.segString(directory) + ": it was aborted");
      return false;
    }

    ensureValidMerge(merge);

    commitMergedDeletes(merge, mergedReader);
      
    // If the doc store we are using has been closed and
    // is in now compound format (but wasn't when we
    // started), then we will switch to the compound
    // format as well:
    setMergeDocStoreIsCompoundFile(merge);

    assert !segmentInfos.contains(merge.info);

    final Set mergedAway = new HashSet<SegmentInfo>(merge.segments);
    int segIdx = 0;
    int newSegIdx = 0;
    boolean inserted = false;
    final int curSegCount = segmentInfos.size();
    while(segIdx < curSegCount) {
      final SegmentInfo info = segmentInfos.info(segIdx++);
      if (mergedAway.contains(info)) {
        if (!inserted) {
          segmentInfos.set(segIdx-1, merge.info);
          inserted = true;
          newSegIdx++;
        }
      } else {
        segmentInfos.set(newSegIdx++, info);
      }
    }
    assert newSegIdx == curSegCount - merge.segments.size() + 1;
    segmentInfos.subList(newSegIdx, segmentInfos.size()).clear();

    if (infoStream != null) {
      message("after commit: " + segString());
    }

    closeMergeReaders(merge, false);

    // Must note the change to segmentInfos so any commits
    // in-flight don't lose it:
    checkpoint();

    // If the merged segments had pending changes, clear
    // them so that they don't bother writing them to
    // disk, updating SegmentInfo, etc.:
    readerPool.clear(merge.segments);
    
    if (merge.optimize) {
      // cascade the optimize:
      segmentsToOptimize.add(merge.info);
    }

    
    return true;
  }

