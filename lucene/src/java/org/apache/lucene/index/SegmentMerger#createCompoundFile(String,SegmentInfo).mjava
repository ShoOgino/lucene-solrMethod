  final List<String> createCompoundFile(String fileName, final SegmentInfo info)
          throws IOException {
    CompoundFileWriter cfsWriter = new CompoundFileWriter(directory, fileName, checkAbort);

    Set<String> fileSet = new HashSet<String>();

    // Basic files
    for (String ext : IndexFileNames.COMPOUND_EXTENSIONS_NOT_CODEC) {
      if (mergeDocStores || (!ext.equals(IndexFileNames.FIELDS_EXTENSION) &&
                             !ext.equals(IndexFileNames.FIELDS_INDEX_EXTENSION)))
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
    }
    codec.files(directory, info, fileSet);
    
    // Fieldable norm files
    final int numFIs = fieldInfos.size();
    for (int i = 0; i < numFIs; i++) {
      final FieldInfo fi = fieldInfos.fieldInfo(i);
      // Index Values aka. CSF
      if (fi.indexValues != null) {
        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer
            .toString(fi.number), IndexFileNames.CSF_DATA_EXTENSION), directory);
        addIfExists(fileSet, IndexFileNames.segmentFileName(segment, Integer
            .toString(fi.number), IndexFileNames.CSF_INDEX_EXTENSION),
            directory);
      }
      if (fi.isIndexed && !fi.omitNorms) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", IndexFileNames.NORMS_EXTENSION));
        break;
      }
    }

    // Vector files
    if (fieldInfos.hasVectors() && mergeDocStores) {
      for (String ext : IndexFileNames.VECTOR_EXTENSIONS) {
        fileSet.add(IndexFileNames.segmentFileName(segment, "", ext));
      }
    }

    // Now merge all added files
    for (String file : fileSet) {
      cfsWriter.addFile(file);
    }
    
    // Perform the merge
    cfsWriter.close();
   
    return new ArrayList<String>(fileSet);
  }

