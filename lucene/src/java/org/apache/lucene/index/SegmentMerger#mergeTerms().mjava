  private final void mergeTerms() throws CorruptIndexException, IOException {

    // Let CodecProvider decide which codec will be used to write
    // the new segment:

    int docBase = 0;
    
    final List<Fields> fields = new ArrayList<Fields>();
    final List<ReaderUtil.Slice> slices = new ArrayList<ReaderUtil.Slice>();

    for(MergeState.IndexReaderAndLiveDocs r : readers) {
      final Fields f = r.reader.fields();
      final int maxDoc = r.reader.maxDoc();
      if (f != null) {
        slices.add(new ReaderUtil.Slice(docBase, maxDoc, fields.size()));
        fields.add(f);
      }
      docBase += maxDoc;
    }

    // we may gather more readers than mergeState.readerCount
    mergeState = new MergeState();
    mergeState.readers = readers;
    mergeState.readerCount = readers.size();
    mergeState.fieldInfos = fieldInfos;
    mergeState.mergedDocCount = mergedDocs;

    // Remap docIDs
    mergeState.docMaps = new int[mergeState.readerCount][];
    mergeState.docBase = new int[mergeState.readerCount];
    mergeState.hasPayloadProcessorProvider = payloadProcessorProvider != null;
    mergeState.dirPayloadProcessor = new PayloadProcessorProvider.DirPayloadProcessor[mergeState.readerCount];
    mergeState.currentPayloadProcessor = new PayloadProcessorProvider.PayloadProcessor[mergeState.readerCount];
    mergeState.checkAbort = checkAbort;

    docBase = 0;
    int inputDocBase = 0;

    for(int i=0;i<mergeState.readerCount;i++) {

      final MergeState.IndexReaderAndLiveDocs reader = readers.get(i);

      mergeState.docBase[i] = docBase;
      inputDocBase += reader.reader.maxDoc();
      final int maxDoc = reader.reader.maxDoc();
      if (reader.liveDocs != null) {
        int delCount = 0;
        final Bits liveDocs = reader.liveDocs;
        assert liveDocs != null;
        final int[] docMap = mergeState.docMaps[i] = new int[maxDoc];
        int newDocID = 0;
        for(int j=0;j<maxDoc;j++) {
          if (!liveDocs.get(j)) {
            docMap[j] = -1;
            delCount++;
          } else {
            docMap[j] = newDocID++;
          }
        }
        docBase += maxDoc - delCount;
      } else {
        docBase += maxDoc;
      }

      if (payloadProcessorProvider != null) {
        mergeState.dirPayloadProcessor[i] = payloadProcessorProvider.getDirProcessor(reader.reader.directory());
      }
    }
    codec = segmentWriteState.segmentCodecs.codec();
    final FieldsConsumer consumer = codec.fieldsConsumer(segmentWriteState);
    boolean success = false;
    try {
      consumer.merge(mergeState,
                     new MultiFields(fields.toArray(Fields.EMPTY_ARRAY),
                                     slices.toArray(ReaderUtil.Slice.EMPTY_ARRAY)));
      success = true;
    } finally {
      if (success) {
        IOUtils.close(consumer);
      } else {
        IOUtils.closeWhileHandlingException(consumer);
      }
    }
  }

