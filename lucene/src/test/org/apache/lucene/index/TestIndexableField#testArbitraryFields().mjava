  // Silly test showing how to index documents w/o using Lucene's core
  // Document nor Field class
  public void testArbitraryFields() throws Exception {

    final Directory dir = newDirectory();
    final RandomIndexWriter w = new RandomIndexWriter(random, dir);

    final int NUM_DOCS = atLeast(27);
    if (VERBOSE) {
      System.out.println("TEST: " + NUM_DOCS + " docs");
    }
    final int[] fieldsPerDoc = new int[NUM_DOCS];
    int baseCount = 0;

    for(int docCount=0;docCount<NUM_DOCS;docCount++) {
      final int fieldCount = _TestUtil.nextInt(random, 1, 17);
      fieldsPerDoc[docCount] = fieldCount-1;

      final int finalDocCount = docCount;
      if (VERBOSE) {
        System.out.println("TEST: " + fieldCount + " fields in doc " + docCount);
      }

      final int finalBaseCount = baseCount;
      baseCount += fieldCount-1;

      w.addDocument(new Iterable<IndexableField>() {
        @Override
        public Iterator<IndexableField> iterator() {
          return new Iterator<IndexableField>() {
            int fieldUpto;

            @Override
            public boolean hasNext() {
              return fieldUpto < fieldCount;
            }

            @Override
            public IndexableField next() {
              assert fieldUpto < fieldCount;
              if (fieldUpto == 0) {
                fieldUpto = 1;
                return newField("id", ""+finalDocCount, StringField.TYPE_STORED);
              } else {
                return new MyField(finalBaseCount + (fieldUpto++-1));
              }
            }

            @Override
            public void remove() {
              throw new UnsupportedOperationException();
            }
          };
        }
        });
    }

    final IndexReader r = w.getReader();
    w.close();

    final IndexSearcher s = new IndexSearcher(r);
    int counter = 0;
    for(int id=0;id<NUM_DOCS;id++) {
      if (VERBOSE) {
        System.out.println("TEST: verify doc id=" + id + " (" + fieldsPerDoc[id] + " fields) counter=" + counter);
      }
      final TopDocs hits = s.search(new TermQuery(new Term("id", ""+id)), 1);
      assertEquals(1, hits.totalHits);
      final int docID = hits.scoreDocs[0].doc;
      final Document doc = s.doc(docID);
      final int endCounter = counter + fieldsPerDoc[id];
      while(counter < endCounter) {
        final String name = "f" + counter;
        final int fieldID = counter % 10;

        final boolean stored = (counter&1) == 0 || fieldID == 3;
        final boolean binary = fieldID == 3;
        final boolean indexed = fieldID != 3;
        final boolean numeric = fieldID == 9;

        final String stringValue;
        if (fieldID != 3 && fieldID != 9) {
          stringValue = "text " + counter;
        } else {
          stringValue = null;
        }

        // stored:
        if (stored) {
          IndexableField f = doc.getField(name);
          assertNotNull("doc " + id + " doesn't have field f" + counter, f);
          if (binary) {
            assertNotNull("doc " + id + " doesn't have field f" + counter, f);
            final BytesRef b = f.binaryValue();
            assertNotNull(b);
            assertEquals(10, b.length);
            for(int idx=0;idx<10;idx++) {
              assertEquals((byte) (idx+counter), b.bytes[b.offset+idx]);
            }
          } else if (numeric) {
            assertTrue(f instanceof NumericField);
            final NumericField nf = (NumericField) f;
            assertEquals(NumericField.DataType.INT, nf.numericDataType());
            assertEquals(counter, nf.numericValue().intValue());
          } else {
            assert stringValue != null;
            assertEquals(stringValue, f.stringValue());
          }
        }
        
        if (indexed) {
          final boolean tv = counter % 2 == 1 && fieldID != 9;
          final TermFreqVector tfv = r.getTermFreqVector(docID, name);
          if (tv) {
            assertNotNull(tfv);
            assertTrue(tfv instanceof TermPositionVector);
            final TermPositionVector tpv = (TermPositionVector) tfv;
            final BytesRef[] terms = tpv.getTerms();
            assertEquals(2, terms.length);
            assertEquals(new BytesRef(""+counter), terms[0]);
            assertEquals(new BytesRef("text"), terms[1]);

            final int[] freqs = tpv.getTermFrequencies();
            assertEquals(2, freqs.length);
            assertEquals(1, freqs[0]);
            assertEquals(1, freqs[1]);

            int[] positions = tpv.getTermPositions(0);
            assertEquals(1, positions.length);
            assertEquals(1, positions[0]);

            positions = tpv.getTermPositions(1);
            assertEquals(1, positions.length);
            assertEquals(0, positions[0]);

            // TODO: offsets
            
          } else {
            assertNull(tfv);
          }

          if (numeric) {
            NumericRangeQuery nrq = NumericRangeQuery.newIntRange(name, counter, counter, true, true);
            final TopDocs hits2 = s.search(nrq, 1);
            assertEquals(1, hits2.totalHits);
            assertEquals(docID, hits2.scoreDocs[0].doc);
          } else {
            BooleanQuery bq = new BooleanQuery();
            bq.add(new TermQuery(new Term("id", ""+id)), BooleanClause.Occur.MUST);
            bq.add(new TermQuery(new Term(name, "text")), BooleanClause.Occur.MUST);
            final TopDocs hits2 = s.search(bq, 1);
            assertEquals(1, hits2.totalHits);
            assertEquals(docID, hits2.scoreDocs[0].doc);

            bq = new BooleanQuery();
            bq.add(new TermQuery(new Term("id", ""+id)), BooleanClause.Occur.MUST);
            bq.add(new TermQuery(new Term(name, ""+counter)), BooleanClause.Occur.MUST);
            final TopDocs hits3 = s.search(bq, 1);
            assertEquals(1, hits3.totalHits);
            assertEquals(docID, hits3.scoreDocs[0].doc);
          }
        }

        counter++;
      }
    }

    r.close();
    dir.close();
  }

