  private void consumeToken(State state) {
    int copied = 0;
    boolean escaped = false;
    boolean prefix = false;
    boolean fuzzy = false;

    while (state.index < state.length) {
      if (!escaped) {
        if (state.data[state.index] == '\\' && (flags & ESCAPE_OPERATOR) != 0) {
          // an escape character has been found so
          // whatever character is next will become
          // part of the term unless the escape
          // character is the last one in the data
          escaped = true;
          prefix = false;
          ++state.index;

          continue;
        } else if (tokenFinished(state)) {
          // this should be the end of the term
          // all characters found will used for
          // creating the term query
          break;
        } else if (copied > 0 && state.data[state.index] == '~' && (flags & FUZZY_OPERATOR) != 0) {
          fuzzy = true;
          break;
        }

        // wildcard tracks whether or not the last character
        // was a '*' operator that hasn't been escaped
        // there must be at least one valid character before
        // searching for a prefixed set of terms
        prefix = copied > 0 && state.data[state.index] == '*' && (flags & PREFIX_OPERATOR) != 0;
      }

      escaped = false;
      state.buffer[copied++] = state.data[state.index++];
    }

    if (copied > 0) {
      final Query branch;

      if (fuzzy && (flags & FUZZY_OPERATOR) != 0) {
        String token = new String(state.buffer, 0, copied);
        int fuzziness = parseFuzziness(state);
        // edit distance has a maximum, limit to the maximum supported
        fuzziness = Math.min(fuzziness, LevenshteinAutomata.MAXIMUM_SUPPORTED_DISTANCE);
        if (fuzziness == 0) {
          branch = newDefaultQuery(token);
        } else {
          branch = newFuzzyQuery(token, fuzziness);
        }
      } else if (prefix) {
        // if a term is found with a closing '*' it is considered to be a prefix query
        // and will have prefix added as an option
        String token = new String(state.buffer, 0, copied - 1);
        branch = newPrefixQuery(token);
      } else {
        // a standard term has been found so it will be run through
        // the entire analysis chain from the specified schema field
        String token = new String(state.buffer, 0, copied);
        branch = newDefaultQuery(token);
      }

      buildQueryTree(state, branch);
    }
  }

