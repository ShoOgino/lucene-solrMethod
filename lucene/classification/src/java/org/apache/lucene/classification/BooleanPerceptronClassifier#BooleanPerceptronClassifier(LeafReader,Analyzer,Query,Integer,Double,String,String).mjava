  /**
   * Creates a {@link BooleanPerceptronClassifier}
   *
   * @param leafReader     the reader on the index to be used for classification
   * @param analyzer       an {@link Analyzer} used to analyze unseen text
   * @param query          a {@link Query} to eventually filter the docs used for training the classifier, or {@code null}
   *                       if all the indexed docs should be used
   * @param batchSize      the size of the batch of docs to use for updating the perceptron weights
   * @param threshold      the threshold used for class separation
   * @param classFieldName the name of the field used as the output for the classifier
   * @param textFieldName  the name of the field used as input for the classifier
   * @throws IOException if the building of the underlying {@link FST} fails and / or {@link TermsEnum} for the text field
   *                     cannot be found
   */
  public BooleanPerceptronClassifier(LeafReader leafReader, Analyzer analyzer, Query query, Integer batchSize,
                                     Double threshold, String classFieldName, String textFieldName) throws IOException {
    this.textTerms = MultiFields.getTerms(leafReader, textFieldName);

    if (textTerms == null) {
      throw new IOException("term vectors need to be available for field " + textFieldName);
    }

    this.analyzer = analyzer;
    this.textFieldName = textFieldName;

    if (threshold == null || threshold == 0d) {
      // automatic assign a threshold
      long sumDocFreq = leafReader.getSumDocFreq(textFieldName);
      if (sumDocFreq != -1) {
        this.threshold = (double) sumDocFreq / 2d;
      } else {
        throw new IOException(
                "threshold cannot be assigned since term vectors for field "
                        + textFieldName + " do not exist");
      }
    } else {
      this.threshold = threshold;
    }

    // TODO : remove this map as soon as we have a writable FST
    SortedMap<String, Double> weights = new ConcurrentSkipListMap<>();

    TermsEnum termsEnum = textTerms.iterator();
    BytesRef textTerm;
    while ((textTerm = termsEnum.next()) != null) {
      weights.put(textTerm.utf8ToString(), (double) termsEnum.totalTermFreq());
    }
    updateFST(weights);

    IndexSearcher indexSearcher = new IndexSearcher(leafReader);

    int batchCount = 0;

    BooleanQuery.Builder q = new BooleanQuery.Builder();
    q.add(new BooleanClause(new WildcardQuery(new Term(classFieldName, "*")), BooleanClause.Occur.MUST));
    if (query != null) {
      q.add(new BooleanClause(query, BooleanClause.Occur.MUST));
    }
    // run the search and use stored field values
    for (ScoreDoc scoreDoc : indexSearcher.search(q.build(),
            Integer.MAX_VALUE).scoreDocs) {
      StoredDocument doc = indexSearcher.doc(scoreDoc.doc);

      StorableField textField = doc.getField(textFieldName);

      // get the expected result
      StorableField classField = doc.getField(classFieldName);

      if (textField != null && classField != null) {
        // assign class to the doc
        ClassificationResult<Boolean> classificationResult = assignClass(textField.stringValue());
        Boolean assignedClass = classificationResult.getAssignedClass();

        Boolean correctClass = Boolean.valueOf(classField.stringValue());
        long modifier = correctClass.compareTo(assignedClass);
        if (modifier != 0) {
          updateWeights(leafReader, scoreDoc.doc, assignedClass,
                  weights, modifier, batchCount % batchSize == 0);
        }
        batchCount++;
      }
    }
    weights.clear(); // free memory while waiting for GC
  }

