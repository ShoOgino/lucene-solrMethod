    /**
     * initializes all classes and registers anonymous adapter classes as
     * listeners for fetcher events.
     *
     * @param nrThreads  number of fetcher threads to be created
     */
    public FetcherMain(int nrThreads, String hostResolverFile) throws Exception
    {
        // to make things clear, this method is commented a bit better than
        // the rest of the program...

        // this is the main message queue. handlers are registered with
        // the queue, and whenever a message is put in it, the message is passed to the
        // filters in a "chain of responibility" manner. Every listener can decide
        // to throw the message away
        messageHandler = new MessageHandler();

        // the storage is the class which saves a WebDocument somewhere, no
        // matter how it does it, whether it's in a file, in a database or
        // whatever

        // example for the (very slow) SQL Server storage:
        // this.storage = new SQLServerStorage("sun.jdbc.odbc.JdbcOdbcDriver","jdbc:odbc:search","sa","...",nrThreads);

        // the LogStorage used here does extensive logging. It logs all links and
        // document information.
        // it also saves all documents to page files.
        File logsDir = new File("logs");
        logsDir.mkdir();    // ensure log directory exists

        // in this experimental implementation, the crawler is pretty verbose
        // the SimpleLogger, however, is a FlyWeight logger which is buffered and
        // not thread safe by default
        SimpleLogger storeLog = new SimpleLogger("store", /* add date/time? */ false);
        SimpleLogger visitedLog = new SimpleLogger("URLVisitedFilter", /* add date/time? */ false);
        SimpleLogger scopeLog = new SimpleLogger("URLScopeFilter", /* add date/time? */ false);
        SimpleLogger pathsLog = new SimpleLogger("KnownPathsFilter", /* add date/time? */ false);
        SimpleLogger linksLog = new SimpleLogger("links", /* add date/time? */ false);
        SimpleLogger lengthLog = new SimpleLogger("length", /* add date/time? */ false);

        StoragePipeline storage = new StoragePipeline();


        // in the default configuration, the crawler will only save the document
        // information to store.log and the link information to links.log
        // The contents of the files are _not_ saved. If you set
        // "save in page files" to "true", they will be saved in "page files",
        // binary files each containing a set of documents. Here, the
        // maximum file size is ~50 MB (crawled files won't be split up into different
        // files). The logs/store.log file contains pointers to these files: a page
        // file number, the offset within that file, and the document's length

        // FIXME: default constructor for all storages + bean access methods
        storage.addDocStorage(new LogStorage(storeLog, /* save in page files? */ true,
                                             /* page file prefix */ "logs/pagefile"));
        storage.addLinkStorage(new LinkLogStorage(linksLog));
        storage.addLinkStorage(messageHandler);
        /*
        // experimental Lucene storage. will slow the crawler down *a lot*
        LuceneStorage luceneStorage = new LuceneStorage();
        luceneStorage.setAnalyzer(new org.apache.lucene.analysis.de.GermanAnalyzer());
        luceneStorage.setCreate(true);
	// FIXME: index name and path need to be configurable
        luceneStorage.setIndexName("luceneIndex");
        // the field names come from URLMessage.java and WebDocument.java. See
        // LuceneStorage source for details
        luceneStorage.setFieldInfo("url", LuceneStorage.INDEX | LuceneStorage.STORE);
        luceneStorage.setFieldInfo("content", LuceneStorage.INDEX | LuceneStorage.STORE | LuceneStorage.TOKEN);
        storage.addDocStorage(luceneStorage);
        */

        storage.open();

        //storage.addStorage(new JMSStorage(...));

        // create the filters and add them to the message queue
        urlScopeFilter = new URLScopeFilter(scopeLog);

        // dnsResolver = new DNSResolver();
        hostManager = new HostManager(1000);
        hostResolver = new HostResolver();
        if(hostResolverFile != null && !"".equals(hostResolverFile))
        {
            hostResolver.initFromFile(hostResolverFile);
        }
        hostManager.setHostResolver(hostResolver);

//        hostManager.addSynonym("www.fachsprachen.uni-muenchen.de", "www.fremdsprachen.uni-muenchen.de");
//        hostManager.addSynonym("www.uni-muenchen.de", "www.lmu.de");
//        hostManager.addSynonym("www.uni-muenchen.de", "uni-muenchen.de");
//        hostManager.addSynonym("webinfo.uni-muenchen.de", "www.webinfo.uni-muenchen.de");
//        hostManager.addSynonym("webinfo.uni-muenchen.de", "webinfo.campus.lmu.de");
//        hostManager.addSynonym("www.s-a.uni-muenchen.de", "s-a.uni-muenchen.de");

        reFilter = new RobotExclusionFilter(hostManager);

        fetcher = new Fetcher(nrThreads, storage, storage, hostManager);

        urlLengthFilter = new URLLengthFilter(500, lengthLog);
        
        //knownPathsFilter = new KnownPathsFilter()
        
        // prevent message box popups
        HTTPConnection.setDefaultAllowUserInteraction(false);

        // prevent GZipped files from being decoded
        HTTPConnection.removeDefaultModule(HTTPClient.ContentEncodingModule.class);

        urlVisitedFilter = new URLVisitedFilter(visitedLog, 100000);

        // initialize the threads
        fetcher.init();

        // the thread monitor watches the thread pool.

        monitor = new ThreadMonitor(urlLengthFilter,
                urlVisitedFilter,
                urlScopeFilter,
                /*dnsResolver,*/
                reFilter,
                messageHandler,
                fetcher.getThreadPool(),
                hostManager,
                5000        // wake up every 5 seconds
                );


        // add all filters to the handler.
        messageHandler.addListener(urlLengthFilter);
        messageHandler.addListener(urlScopeFilter);
        messageHandler.addListener(reFilter);
        messageHandler.addListener(urlVisitedFilter);
        //messageHandler.addListener(knownPathsFilter);

        messageHandler.addListener(fetcher);

         //uncomment this to enable HTTPClient logging
        /*
        try
        {
            HTTPClient.Log.setLogWriter(new java.io.OutputStreamWriter(System.out) //new java.io.FileWriter("logs/HttpClient.log")
            ,false);
            HTTPClient.Log.setLogging(HTTPClient.Log.ALL, true);
        }
        catch (Exception e)
        {
            e.printStackTrace();
        }
        */

    }

